{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Start Here This is the Cleura Beta documentation web site. What does \u201cBeta\u201d mean? The fact that this site is in a Beta stage means that any information you find here should be reliable and accurate for Cleura products and services. If you find any published documentation that is inaccurate or not in line with functionality as you observe it on Cleura Cloud, we would very much appreciate if you filed a documentation bug . However, the documentation on this site may be incomplete, meaning that it does not yet cover all functionality available in Cleura Cloud. In addition, page paths (URLs) are not yet stable. In other words, content may move from one path to another between visits. If you are looking for content that may have moved, please use the Search function. We are currently in the process of migrating our Knowledge Base and other documentation to this site. If you want to help, here\u2019s how! Site analytics and cookies This site does not set cookies, which is why we also don\u2019t need to annoy you with a cookie consent banner. We use cookie-free site analytics from Plausible .","title":"Start Here"},{"location":"#start-here","text":"This is the Cleura Beta documentation web site.","title":"Start Here"},{"location":"#what-does-beta-mean","text":"The fact that this site is in a Beta stage means that any information you find here should be reliable and accurate for Cleura products and services. If you find any published documentation that is inaccurate or not in line with functionality as you observe it on Cleura Cloud, we would very much appreciate if you filed a documentation bug . However, the documentation on this site may be incomplete, meaning that it does not yet cover all functionality available in Cleura Cloud. In addition, page paths (URLs) are not yet stable. In other words, content may move from one path to another between visits. If you are looking for content that may have moved, please use the Search function. We are currently in the process of migrating our Knowledge Base and other documentation to this site. If you want to help, here\u2019s how!","title":"What does \"Beta\" mean?"},{"location":"#site-analytics-and-cookies","text":"This site does not set cookies, which is why we also don\u2019t need to annoy you with a cookie consent banner. We use cookie-free site analytics from Plausible .","title":"Site analytics and cookies"},{"location":"concepts/","text":"Concepts and Background This section contains conceptual and background information about Cleura Cloud and the services we support. This is not so much about how you do something (for that, please see our How-To Guides ), more about why things work in a certain way, or why we have implemented them in a particular way in Cleura Cloud.","title":"Concepts and Background"},{"location":"concepts/#concepts-and-background","text":"This section contains conceptual and background information about Cleura Cloud and the services we support. This is not so much about how you do something (for that, please see our How-To Guides ), more about why things work in a certain way, or why we have implemented them in a particular way in Cleura Cloud.","title":"Concepts and Background"},{"location":"contrib/","text":"Contribution Guide See something on this site that is inaccurate, missing, or that could simply be improved? There are multiple ways for you to help make this site better, and we welcome all of them. You can make modifications and contributions using Git , and we apply certain checks to ensure consistent documentation quality. Technical Writing Resources Whether you are an experienced technical writer, a regular (or not-so-regular) open source contributor, or you\u2019re making your very first writing contribution, there are a ton of helpful resources on technical writing. Here are a few: Digital Ocean \u2019s Technical Writing Guidelines Red Hat \u2019s Writing Style Guide Gareth Dwyer \u2019s Technical Writing repository Bolaji Ayodeji \u2019s Awesome Technical Writing collection Markdown The documentation on this site uses Markdown . Markdown is a documentation format that is rich enough to be useful for good technical documentation, and yet simpler and easier to learn than other formats like reStructuredText or DocBook XML. If you\u2019re unfamiliar with Markdown, you can read up on its basics in this classic article by John Gruber if you\u2019re interested, but chances are that you\u2019ll also find all the information you\u2019ll need in this cheat sheet by Adam Pritchard , or the Start Writing guide from GitHub . Or you simply look at the source of one of the pages on this site (try the Edit button on this one!) and figure it out as you go along \u2014 it\u2019s really pretty straightforward. License With the sole exception of trademarks like \u201cCleura\u201d and the Cleura logo, the content on this site is available under the Creative Commons Attribution-ShareAlike 4.0 International license , as you can see from the icon at the bottom of each page. Please keep in mind that you are making your contribution under those terms.","title":"Contribution Guide"},{"location":"contrib/#contribution-guide","text":"See something on this site that is inaccurate, missing, or that could simply be improved? There are multiple ways for you to help make this site better, and we welcome all of them. You can make modifications and contributions using Git , and we apply certain checks to ensure consistent documentation quality.","title":"Contribution Guide"},{"location":"contrib/#technical-writing-resources","text":"Whether you are an experienced technical writer, a regular (or not-so-regular) open source contributor, or you\u2019re making your very first writing contribution, there are a ton of helpful resources on technical writing. Here are a few: Digital Ocean \u2019s Technical Writing Guidelines Red Hat \u2019s Writing Style Guide Gareth Dwyer \u2019s Technical Writing repository Bolaji Ayodeji \u2019s Awesome Technical Writing collection","title":"Technical Writing Resources"},{"location":"contrib/#markdown","text":"The documentation on this site uses Markdown . Markdown is a documentation format that is rich enough to be useful for good technical documentation, and yet simpler and easier to learn than other formats like reStructuredText or DocBook XML. If you\u2019re unfamiliar with Markdown, you can read up on its basics in this classic article by John Gruber if you\u2019re interested, but chances are that you\u2019ll also find all the information you\u2019ll need in this cheat sheet by Adam Pritchard , or the Start Writing guide from GitHub . Or you simply look at the source of one of the pages on this site (try the Edit button on this one!) and figure it out as you go along \u2014 it\u2019s really pretty straightforward.","title":"Markdown"},{"location":"contrib/#license","text":"With the sole exception of trademarks like \u201cCleura\u201d and the Cleura logo, the content on this site is available under the Creative Commons Attribution-ShareAlike 4.0 International license , as you can see from the icon at the bottom of each page. Please keep in mind that you are making your contribution under those terms.","title":"License"},{"location":"contrib/modifications/","text":"Modifying content on this site You have two options for editing content: directly in your browser using GitHub, or using a Git-based workflow from your local work environment. Notes on content additions Sections: Generally, content additions should fit somewhere within the existing top-level and second-level sections. Try not to introduce a new top-level or second-level section. Screenshots: If you are contributing a change that contains screenshots from Cleura Cloud Management Panel, they should use a resolution of 1920\u00d71080 pixels (1080p). If your screen uses a larger resolution, use Firefox Responsive Design Mode or Chrome/Chromium Device Mode to configure your browser with 1080p. Screenshots should be added to a directory named assets , located in the same directory as the Markdown file you are adding or editing. CLI screen dumps: If you are contributing a change that contains a screen dump from the openstack command-line client, please limit its width to 100 characters. You can do this by setting the following environment variable in your terminal, before you start work on your change. export CLIFF_MAX_TERM_WIDTH = 100 Modifying content from your browser Every page on this site has an Edit button \ud83d\udd8d\ufe0f. If you click it, it\u2019ll take you straight to the corresponding source page in GitHub. Then, you can follow GitHub\u2019s documentation on how to propose changes to another user\u2019s repository. Modifying content using Git The Git repository for this site lives at https://github.com/citynetwork/docs . You can fork that repository , make the proposed changes in your fork, and then send us a standard GitHub pull request . For this purpose, use git in combination with either GitHub\u2019s web interface, or the gh command-line interface (CLI). First, create a fork of the documentation repository: git client and web browser gh client Open https://github.com/citynetwork/docs and click the Fork button. When you create your new fork, it\u2019s fine to leave the Copy the main branch only option enabled. Then, proceed to create a new local checkout of your fork: git clone git@github.com:<yourusername>/<your-repo-fork> cleura cloud-docs cd cleura cloud-docs gh repo fork --clone https://github.com/citynetwork/docs -- cleura cloud-docs cd cleura cloud-docs Next, create a local topic branch and make your modifications: git checkout -b <your-topic-branch-name> # edit your files git add <files-to-add> git commit Please see our notes on commit messages . Finally, create a pull request (PR) from your changes: git client and web browser gh client Run the following git command (assuming origin is the remote that points to your fork): git push origin <your-topic-branch-name> Then, open your browser to the URL suggested by the git push command, and proceed to create a pull request. gh pr create --fill Monitoring changes as you edit To see your changes as you work on them, you can use tox . Having created a topic branch with your modifications, run: cd cleura cloud-docs git checkout <your-topic-branch-name> tox -e serve A local copy of the documentation will then run on your local machine and be accessible from http://localhost:8000 in your browser. When you are planning to make several changes in rapid succession, you may want to speed up rendering the site after each change. You may do so by disabling a plugin that checks all links (including external links) for accessibility: cd cleura cloud-docs export DOCS_ENABLE_HTMLPROOFER = false tox -e serve Commit messages When you submit a change, you will need to provide a commit message, which is very nearly as important as the change itself. Excellent guides on what constitutes a good commit message are available from Tim Pope and Colleen Murphy . In addition, we have adopted the Conventional Commits style for commit message subjects. Please make sure that your commit message starts with one of the following prefixes: feat: denotes a content addition, such as adding documentation for some Cleura Cloud functionality that was not included in the documentation before. fix: denotes a content correction, such as fixing a documentation bug. build: denotes a change to the build process, such as an improvement to a CI check. chore: denotes a minor change that is neither a feature, nor a fix, nor a build improvement, such as when you edit the .mailmap file. docs: denotes a change to the documention for this site, such as an update to the README.md file.","title":"Modifying content on this site"},{"location":"contrib/modifications/#modifying-content-on-this-site","text":"You have two options for editing content: directly in your browser using GitHub, or using a Git-based workflow from your local work environment.","title":"Modifying content on this site"},{"location":"contrib/modifications/#notes-on-content-additions","text":"Sections: Generally, content additions should fit somewhere within the existing top-level and second-level sections. Try not to introduce a new top-level or second-level section. Screenshots: If you are contributing a change that contains screenshots from Cleura Cloud Management Panel, they should use a resolution of 1920\u00d71080 pixels (1080p). If your screen uses a larger resolution, use Firefox Responsive Design Mode or Chrome/Chromium Device Mode to configure your browser with 1080p. Screenshots should be added to a directory named assets , located in the same directory as the Markdown file you are adding or editing. CLI screen dumps: If you are contributing a change that contains a screen dump from the openstack command-line client, please limit its width to 100 characters. You can do this by setting the following environment variable in your terminal, before you start work on your change. export CLIFF_MAX_TERM_WIDTH = 100","title":"Notes on content additions"},{"location":"contrib/modifications/#modifying-content-from-your-browser","text":"Every page on this site has an Edit button \ud83d\udd8d\ufe0f. If you click it, it\u2019ll take you straight to the corresponding source page in GitHub. Then, you can follow GitHub\u2019s documentation on how to propose changes to another user\u2019s repository.","title":"Modifying content from your browser"},{"location":"contrib/modifications/#modifying-content-using-git","text":"The Git repository for this site lives at https://github.com/citynetwork/docs . You can fork that repository , make the proposed changes in your fork, and then send us a standard GitHub pull request . For this purpose, use git in combination with either GitHub\u2019s web interface, or the gh command-line interface (CLI). First, create a fork of the documentation repository: git client and web browser gh client Open https://github.com/citynetwork/docs and click the Fork button. When you create your new fork, it\u2019s fine to leave the Copy the main branch only option enabled. Then, proceed to create a new local checkout of your fork: git clone git@github.com:<yourusername>/<your-repo-fork> cleura cloud-docs cd cleura cloud-docs gh repo fork --clone https://github.com/citynetwork/docs -- cleura cloud-docs cd cleura cloud-docs Next, create a local topic branch and make your modifications: git checkout -b <your-topic-branch-name> # edit your files git add <files-to-add> git commit Please see our notes on commit messages . Finally, create a pull request (PR) from your changes: git client and web browser gh client Run the following git command (assuming origin is the remote that points to your fork): git push origin <your-topic-branch-name> Then, open your browser to the URL suggested by the git push command, and proceed to create a pull request. gh pr create --fill","title":"Modifying content using Git"},{"location":"contrib/modifications/#monitoring-changes-as-you-edit","text":"To see your changes as you work on them, you can use tox . Having created a topic branch with your modifications, run: cd cleura cloud-docs git checkout <your-topic-branch-name> tox -e serve A local copy of the documentation will then run on your local machine and be accessible from http://localhost:8000 in your browser. When you are planning to make several changes in rapid succession, you may want to speed up rendering the site after each change. You may do so by disabling a plugin that checks all links (including external links) for accessibility: cd cleura cloud-docs export DOCS_ENABLE_HTMLPROOFER = false tox -e serve","title":"Monitoring changes as you edit"},{"location":"contrib/modifications/#commit-messages","text":"When you submit a change, you will need to provide a commit message, which is very nearly as important as the change itself. Excellent guides on what constitutes a good commit message are available from Tim Pope and Colleen Murphy . In addition, we have adopted the Conventional Commits style for commit message subjects. Please make sure that your commit message starts with one of the following prefixes: feat: denotes a content addition, such as adding documentation for some Cleura Cloud functionality that was not included in the documentation before. fix: denotes a content correction, such as fixing a documentation bug. build: denotes a change to the build process, such as an improvement to a CI check. chore: denotes a minor change that is neither a feature, nor a fix, nor a build improvement, such as when you edit the .mailmap file. docs: denotes a change to the documention for this site, such as an update to the README.md file.","title":"Commit messages"},{"location":"contrib/quality/","text":"Quality checks There are a few checks that we apply to the configuration of this site. These checks run automatically via GitHub Actions workflows when you send your PR : We check the commit message with gitlint , and enforce the Conventional Commits commit message style. We check whether the documentation still builds correctly, with your change applied. We check to make sure that no internal or external links in the documentation are dead. This is one example where the checks might fail through no fault of yours \u2014 some external link may have disappeared between the most recent change and your contribution, by pure coincidence. When that happens, we\u2019ll fix it together. We check some YAML conventions with yamllint . However, most contributions would probably only touch Markdown files and not YAML, so you\u2019re unlikely to trip over this. If you\u2019re working in your local Git repository and your work environment has tox installed, you can also run the checks locally: tox You can also configure your local checkout to run quality checks on each commit. To do that, run: git config core.hooksPath .githooks","title":"Quality checks"},{"location":"contrib/quality/#quality-checks","text":"There are a few checks that we apply to the configuration of this site. These checks run automatically via GitHub Actions workflows when you send your PR : We check the commit message with gitlint , and enforce the Conventional Commits commit message style. We check whether the documentation still builds correctly, with your change applied. We check to make sure that no internal or external links in the documentation are dead. This is one example where the checks might fail through no fault of yours \u2014 some external link may have disappeared between the most recent change and your contribution, by pure coincidence. When that happens, we\u2019ll fix it together. We check some YAML conventions with yamllint . However, most contributions would probably only touch Markdown files and not YAML, so you\u2019re unlikely to trip over this. If you\u2019re working in your local Git repository and your work environment has tox installed, you can also run the checks locally: tox You can also configure your local checkout to run quality checks on each commit. To do that, run: git config core.hooksPath .githooks","title":"Quality checks"},{"location":"howto/","text":"About our How-To guides In this section you\u2019ll find details about how you can accomplish specific tasks in Cleura Cloud and the services we support. There are several categories of How-To guides, and they tend to be focused on a specific cloud technology. Getting Started How-Tos help you create an account in Cleura Cloud, and start using our services. Kubernetes How-Tos cover how you can create and manage your Kubernetes deployments using Cleura Cloud Management Panel. Object storage How-Tos deal with the S3 and Swift object storage APIs, and how you can use them for object storage in Cleura Cloud. OpenStack CLI/API How-Tos cover tasks that you can accomplish with the OpenStack command line interfaces and application programming interfaces. They generally do not depend on any adjacent services or tools, just your Cleura Cloud OpenStack credentials, the openstack client, and/or the native OpenStack APIs.","title":"About our How-To guides"},{"location":"howto/#about-our-how-to-guides","text":"In this section you\u2019ll find details about how you can accomplish specific tasks in Cleura Cloud and the services we support. There are several categories of How-To guides, and they tend to be focused on a specific cloud technology. Getting Started How-Tos help you create an account in Cleura Cloud, and start using our services. Kubernetes How-Tos cover how you can create and manage your Kubernetes deployments using Cleura Cloud Management Panel. Object storage How-Tos deal with the S3 and Swift object storage APIs, and how you can use them for object storage in Cleura Cloud. OpenStack CLI/API How-Tos cover tasks that you can accomplish with the OpenStack command line interfaces and application programming interfaces. They generally do not depend on any adjacent services or tools, just your Cleura Cloud OpenStack credentials, the openstack client, and/or the native OpenStack APIs.","title":"About our How-To guides"},{"location":"howto/account-billing/change-billing-data/","text":"Changing your account billing data Via Cleura Cloud Management Panel you can change the contact person, address, company name, and purchase order number associated with your account. To get started, navigate to https://cleura.cloud . Log in and click on the Profile button at the top right. You will now see the Account settings page. Choose the Customer Info tab, in which you can change and manage your customer information. Finish your changes by clicking the green Update button at the bottom. Changing an account\u2019s organization number You cannot change your organization number (for business accounts) or personal number (for individual accounts) in Cleura Cloud Management Panel. This requires that you submit a transfer form via our Service Center .","title":"Changing your account billing data"},{"location":"howto/account-billing/change-billing-data/#changing-your-account-billing-data","text":"Via Cleura Cloud Management Panel you can change the contact person, address, company name, and purchase order number associated with your account. To get started, navigate to https://cleura.cloud . Log in and click on the Profile button at the top right. You will now see the Account settings page. Choose the Customer Info tab, in which you can change and manage your customer information. Finish your changes by clicking the green Update button at the bottom.","title":"Changing your account billing data"},{"location":"howto/account-billing/change-billing-data/#changing-an-accounts-organization-number","text":"You cannot change your organization number (for business accounts) or personal number (for individual accounts) in Cleura Cloud Management Panel. This requires that you submit a transfer form via our Service Center .","title":"Changing an account's organization number"},{"location":"howto/getting-started/create-account/","text":"Creating a new account To gain access to the Cleura Cloud Management Panel, you first have to create a new account. For that, navigate to https://cleura.cloud . At the bottom right-hand side of the page, click on the Create account button. Select the new account type (that would be Company or Private ), carefully type in a valid email address, and choose your country. At your leisure, please read the City Network General Terms And Conditions and our Data Processing Agreement . Agree to these documents (select Yes ), check the I\u2019m not a robot box, and then click on the Create button. This will redirect you to the Cleura Cloud Management Panel, and since you are logging in from a new account for the first time, you now have to take three simple steps. Step 1 - Confirm your email . Check your inbox or your SPAM/junk folder for an email from no-reply@cleura.com with the subject Thank you for your registration - Cleura Cloud . Open that email and click on the link in the message body. Step 2 - Account information . After clicking on the confirmation link you move on to step two, where you enter all relevant information that uniquely identifies the brand-new account. Type in, for example, a username for the account user, and make sure you define a strong password for them. (A password manager may come in handy.) Please note that all fields are mandatory, so take a little time and fill them in accordingly. Should you have a rebate code, do not forget to click on I have a rebate code and type it in below. When you are done, click on the Save button. Step 3 - Account verification . While the new account is being created, and before it becomes fully operational, you have to take one last step toward verification. You do that either by entering valid credit card information or by placing a simple phone call. Should you choose to verify by credit card, rest assured that no charge will take place \u2014 no money will be drawn from the card, in other words. On the other hand, if you prefer to verify by phone, you may certainly do so during business hours (08:00 \u2013 17:00 CET/CEST UTC+1/UTC+2). If you choose to call, please remember that you will be asked for the username of the new account, so have that piece of info handy. After the account verification is complete, you are greeted by the Cleura Cloud Management Panel. Feel free to follow through the introductory guide to the environment \u2014 that will not take long \u2014 or skip it and start taking advantage of the Cleura Cloud without delay.","title":"Creating a new account"},{"location":"howto/getting-started/create-account/#creating-a-new-account","text":"To gain access to the Cleura Cloud Management Panel, you first have to create a new account. For that, navigate to https://cleura.cloud . At the bottom right-hand side of the page, click on the Create account button. Select the new account type (that would be Company or Private ), carefully type in a valid email address, and choose your country. At your leisure, please read the City Network General Terms And Conditions and our Data Processing Agreement . Agree to these documents (select Yes ), check the I\u2019m not a robot box, and then click on the Create button. This will redirect you to the Cleura Cloud Management Panel, and since you are logging in from a new account for the first time, you now have to take three simple steps. Step 1 - Confirm your email . Check your inbox or your SPAM/junk folder for an email from no-reply@cleura.com with the subject Thank you for your registration - Cleura Cloud . Open that email and click on the link in the message body. Step 2 - Account information . After clicking on the confirmation link you move on to step two, where you enter all relevant information that uniquely identifies the brand-new account. Type in, for example, a username for the account user, and make sure you define a strong password for them. (A password manager may come in handy.) Please note that all fields are mandatory, so take a little time and fill them in accordingly. Should you have a rebate code, do not forget to click on I have a rebate code and type it in below. When you are done, click on the Save button. Step 3 - Account verification . While the new account is being created, and before it becomes fully operational, you have to take one last step toward verification. You do that either by entering valid credit card information or by placing a simple phone call. Should you choose to verify by credit card, rest assured that no charge will take place \u2014 no money will be drawn from the card, in other words. On the other hand, if you prefer to verify by phone, you may certainly do so during business hours (08:00 \u2013 17:00 CET/CEST UTC+1/UTC+2). If you choose to call, please remember that you will be asked for the username of the new account, so have that piece of info handy. After the account verification is complete, you are greeted by the Cleura Cloud Management Panel. Feel free to follow through the introductory guide to the environment \u2014 that will not take long \u2014 or skip it and start taking advantage of the Cleura Cloud without delay.","title":"Creating a new account"},{"location":"howto/getting-started/enable-openstack-cli/","text":"Enabling the OpenStack CLI The OpenStack Command Line Interface (CLI) tool, also known as OpenStack Client (OSC) or simply openstack , conveniently provides access to various OpenStack APIs. Using the OpenStack CLI tool, you can remotely create and manage the lifecycle of objects related, for example, to Compute, Networking, or Storage. Before installing openstack to your local laptop or workstation, you first need to have an OpenStack user in your Cleura Cloud account. Next, you create and download a special RC file onto your computer, modify it to reflect your OpenStack user\u2019s credentials, and source it. Only then will you be able to use any installed openstack client. Creating an OpenStack user From your favorite web browser, navigate to the Cleura Cloud Management Panel start page, and login into your Cleura Cloud account. Please make sure the left-hand side pane on the Cleura Cloud Management Panel is fully visible, click the Users category to expand it, and click on Openstack Users . Then, at the top right-hand side of the Cleura Cloud Management Panel, click once more the Add new Openstack user option. A new pane will slide into view, titled Create Openstack User . Type in a username and a password for the new OpenStack user. To ensure you typed the password correctly, you must re-type it below. This password should be adequately strong, and thus a password manager may come in handy. Scroll down a bit, so the Regions section is in full view. Expand one or more of the available regions you want your new user to have access to. For each one of the expanded regions, select one or more Projects . For each project, activate one or more Roles . (Hint: For an overview of the rights that roles provide, hover the mouse pointer over the exclamation mark icon by the Roles .) Optionally, type in a description for the new OpenStack user. Then, create the user by clicking the green Create button below the Description box. The new OpenStack user will be ready in just a few seconds. At any time, you can view all available OpenStack users by going to the left-hand side pane on the Cleura Cloud Management Panel and selecting Users > Openstack Users . Creating and downloading an RC file On the Cleura Cloud Management Panel expand the left-hand side pane, click Users and then Openstack Users . You will then see, listed in the main pane titled Openstack Users , all available users. Click on the three-dotted round icon on the right of the user you want to create an RC file for. From the pop-up that appears, select Generate RC file . The RC file will be generated automatically. Before downloading it onto your local computer, you must select one of the available projects to relate the RC file to. Do so and then click the blue Download button. A \u201cSave as\u201d dialog window appears, specific to the operating system you are currently using. Select a convenient location and save your RC file. Modifying and sourcing the RC file The general naming for RC files goes like this: your_username--region_name--project_name--rc So, assuming your username is olafsdottir , and the RC file has been created for the fra1 region and the katla project, your RC file name should be this: olafsdottir--fra1--katla--rc Take a look at the contents of this file \u2014 they should be like this: export OS_USERNAME = olafsdottir export OS_PASSWORD = <your password goes here> export OS_AUTH_URL = https://fra1.citycloud.com:5000 export OS_USER_DOMAIN_NAME = ... export OS_PROJECT_DOMAIN_NAME = ... export OS_REGION_NAME = Fra1 export OS_PROJECT_NAME = \"katla\" export OS_TENANT_NAME = \"katla\" export OS_AUTH_VERSION = 3 export OS_IDENTITY_API_VERSION = 3 Before you source the RC file, and thus initialize all relevant environment variables, make sure to edit the file and put your OpenStack user password in place of <your password goes here> . Also, change the permissions of the file, so it is readable and writable by your local user only: chmod 600 olafsdottir--fra1--katla--rc Then, go ahead and source it: source olafsdottir--fra1--katla--rc Installing the OpenStack CLI If you do not have the OpenStack CLI tool readily available, use your operating system\u2019s package manager or pip to install it. Some examples follow. Debian/Ubuntu Mac OS X with Homebrew Python package apt update && apt install python3-openstackclient brew install openstackclient pip install python-openstackclient Testing access Provided you have already sourced your RC file, you can now use the openstack command line tool to access various OpenStack APIs on the Cleura Cloud. To make sure your local installation of openstack works as expected, type: openstack token issue If openstack can indeed connect to the Cleura Cloud OpenStack APIs, then you will get information, in tabular format, regarding the issuance of a new token. To get general help regarding openstack , type: openstack --help When you need help on a specific command, type something like openstack help command . Auto-adjusting the CLI output to your terminal size Many of the subcommands available in the openstack CLI produce tabular about by default. To ensure that this output always fits neatly into your terminal window, you may add the following line either to OpenStack RC file(s), or to your shell initialization file (like .profile or .bashrc ): export CLIFF_FIT_WIDTH = 1 Then, be sure to either re-source the file you modified, and/or restart your shell.","title":"Enabling the OpenStack CLI"},{"location":"howto/getting-started/enable-openstack-cli/#enabling-the-openstack-cli","text":"The OpenStack Command Line Interface (CLI) tool, also known as OpenStack Client (OSC) or simply openstack , conveniently provides access to various OpenStack APIs. Using the OpenStack CLI tool, you can remotely create and manage the lifecycle of objects related, for example, to Compute, Networking, or Storage. Before installing openstack to your local laptop or workstation, you first need to have an OpenStack user in your Cleura Cloud account. Next, you create and download a special RC file onto your computer, modify it to reflect your OpenStack user\u2019s credentials, and source it. Only then will you be able to use any installed openstack client.","title":"Enabling the OpenStack CLI"},{"location":"howto/getting-started/enable-openstack-cli/#creating-an-openstack-user","text":"From your favorite web browser, navigate to the Cleura Cloud Management Panel start page, and login into your Cleura Cloud account. Please make sure the left-hand side pane on the Cleura Cloud Management Panel is fully visible, click the Users category to expand it, and click on Openstack Users . Then, at the top right-hand side of the Cleura Cloud Management Panel, click once more the Add new Openstack user option. A new pane will slide into view, titled Create Openstack User . Type in a username and a password for the new OpenStack user. To ensure you typed the password correctly, you must re-type it below. This password should be adequately strong, and thus a password manager may come in handy. Scroll down a bit, so the Regions section is in full view. Expand one or more of the available regions you want your new user to have access to. For each one of the expanded regions, select one or more Projects . For each project, activate one or more Roles . (Hint: For an overview of the rights that roles provide, hover the mouse pointer over the exclamation mark icon by the Roles .) Optionally, type in a description for the new OpenStack user. Then, create the user by clicking the green Create button below the Description box. The new OpenStack user will be ready in just a few seconds. At any time, you can view all available OpenStack users by going to the left-hand side pane on the Cleura Cloud Management Panel and selecting Users > Openstack Users .","title":"Creating an OpenStack user"},{"location":"howto/getting-started/enable-openstack-cli/#creating-and-downloading-an-rc-file","text":"On the Cleura Cloud Management Panel expand the left-hand side pane, click Users and then Openstack Users . You will then see, listed in the main pane titled Openstack Users , all available users. Click on the three-dotted round icon on the right of the user you want to create an RC file for. From the pop-up that appears, select Generate RC file . The RC file will be generated automatically. Before downloading it onto your local computer, you must select one of the available projects to relate the RC file to. Do so and then click the blue Download button. A \u201cSave as\u201d dialog window appears, specific to the operating system you are currently using. Select a convenient location and save your RC file.","title":"Creating and downloading an RC file"},{"location":"howto/getting-started/enable-openstack-cli/#modifying-and-sourcing-the-rc-file","text":"The general naming for RC files goes like this: your_username--region_name--project_name--rc So, assuming your username is olafsdottir , and the RC file has been created for the fra1 region and the katla project, your RC file name should be this: olafsdottir--fra1--katla--rc Take a look at the contents of this file \u2014 they should be like this: export OS_USERNAME = olafsdottir export OS_PASSWORD = <your password goes here> export OS_AUTH_URL = https://fra1.citycloud.com:5000 export OS_USER_DOMAIN_NAME = ... export OS_PROJECT_DOMAIN_NAME = ... export OS_REGION_NAME = Fra1 export OS_PROJECT_NAME = \"katla\" export OS_TENANT_NAME = \"katla\" export OS_AUTH_VERSION = 3 export OS_IDENTITY_API_VERSION = 3 Before you source the RC file, and thus initialize all relevant environment variables, make sure to edit the file and put your OpenStack user password in place of <your password goes here> . Also, change the permissions of the file, so it is readable and writable by your local user only: chmod 600 olafsdottir--fra1--katla--rc Then, go ahead and source it: source olafsdottir--fra1--katla--rc","title":"Modifying and sourcing the RC file"},{"location":"howto/getting-started/enable-openstack-cli/#installing-the-openstack-cli","text":"If you do not have the OpenStack CLI tool readily available, use your operating system\u2019s package manager or pip to install it. Some examples follow. Debian/Ubuntu Mac OS X with Homebrew Python package apt update && apt install python3-openstackclient brew install openstackclient pip install python-openstackclient","title":"Installing the OpenStack CLI"},{"location":"howto/getting-started/enable-openstack-cli/#testing-access","text":"Provided you have already sourced your RC file, you can now use the openstack command line tool to access various OpenStack APIs on the Cleura Cloud. To make sure your local installation of openstack works as expected, type: openstack token issue If openstack can indeed connect to the Cleura Cloud OpenStack APIs, then you will get information, in tabular format, regarding the issuance of a new token. To get general help regarding openstack , type: openstack --help When you need help on a specific command, type something like openstack help command .","title":"Testing access"},{"location":"howto/getting-started/enable-openstack-cli/#auto-adjusting-the-cli-output-to-your-terminal-size","text":"Many of the subcommands available in the openstack CLI produce tabular about by default. To ensure that this output always fits neatly into your terminal window, you may add the following line either to OpenStack RC file(s), or to your shell initialization file (like .profile or .bashrc ): export CLIFF_FIT_WIDTH = 1 Then, be sure to either re-source the file you modified, and/or restart your shell.","title":"Auto-adjusting the CLI output to your terminal size"},{"location":"howto/kubernetes/","text":"Kubernetes in Cleura In Cleura Cloud, you have several options for deploying and managing Kubernetes clusters. Cleura Cloud Management Panel includes management interfaces for Gardener and OpenStack Magnum . To manage Magnum clusters, you can also use the OpenStack command-line interface .","title":"Kubernetes in Cleura"},{"location":"howto/kubernetes/#kubernetes-in-cleura","text":"In Cleura Cloud, you have several options for deploying and managing Kubernetes clusters. Cleura Cloud Management Panel includes management interfaces for Gardener and OpenStack Magnum . To manage Magnum clusters, you can also use the OpenStack command-line interface .","title":"Kubernetes in Cleura"},{"location":"howto/kubernetes/gardener/","text":"Gardener Gardener is a Kubernetes-native system that provides automated management and operation of Kubernetes clusters as a service. It allows you to create clusters and automatically handle their lifecycle operations, including configurable maintenance windows, hibernation schedules, and automatic updates to Kubernetes control plane and worker nodes. You can read more about Gardener and its capabilities on its documentation website . Gardener in Cleura Cloud is currently in a closed beta stage. For access to the closed beta, contact our Service Center . To learn how to use Gardener in the Cleura Cloud Management Panel, refer to Creating Kubernetes clusters with Gardener .","title":"Gardener"},{"location":"howto/kubernetes/gardener/#gardener","text":"Gardener is a Kubernetes-native system that provides automated management and operation of Kubernetes clusters as a service. It allows you to create clusters and automatically handle their lifecycle operations, including configurable maintenance windows, hibernation schedules, and automatic updates to Kubernetes control plane and worker nodes. You can read more about Gardener and its capabilities on its documentation website . Gardener in Cleura Cloud is currently in a closed beta stage. For access to the closed beta, contact our Service Center . To learn how to use Gardener in the Cleura Cloud Management Panel, refer to Creating Kubernetes clusters with Gardener .","title":"Gardener"},{"location":"howto/kubernetes/gardener/create-shoot-cluster/","text":"Creating Kubernetes clusters with Gardener If you want to create a Kubernetes cluster, you can do it via Cleura Cloud Management Panel using Gardener. This how-to shows you how to do that, and how to deploy a sample application on such a cluster. Prerequisites To access Gardener functionality from Cleura Cloud Management Panel, you need to enroll in our closed beta. For access to the closed beta, contact our Service Center . To access the Kubernetes cluster from your computer, you will need kubectl installed on your machine. Creating a Kubernetes cluster in Cleura Cloud Management Panel To get started, navigate to https://cleura.cloud , and in the side panel choose Kubernetes \u2192 Managed Kubernetes . You will see a Gardener page, in which you can create and manage your clusters. Click Create Kubernetes cluster . In Gardener\u2019s terminology, a Kubernetes cluster is referred as a Shoot cluster . You can see the name \u201cShoot\u201d in various places throughout the panel\u2019s UI, so it is good to know what it means. To learn more, check out Gardener architecture . In the opened form, fill in the name of the cluster and a region to see the rest of the options. Hover over question mark icons at each form field to learn more about it. For the purposes of this how-to, you can leave everything at default values and click Create at the bottom. In the form you can see a section about worker groups. This name refers to Kubernetes worker nodes. In the list of clusters, you will see your new Gardener shoot bootstrapping. The icon on the left marks the progress. Creating the cluster can take up to several minutes. Extract kubeconfig file from Shoot cluster When the Shoot cluster is up and running, you need to get a kubeconfig file to be able to access it. To do that, click on the cluster to expand its properties, and open Kubeconfig . You should now see the file\u2019s contents. You have the option to Copy Config or Rotate Kubeconfig if your credentials got compromised. Copy the content of the kubeconfig and insert it into ~/.kube/config . Create the directory and the file if needed. By default, Kubectl searches for its configuration in ~/.kube/config , but you can modify this behaviour if needed. More info here . Check if your kubectl uses the proper configuration by running: kubectl config view You should see something like this: apiVersion : v1 clusters : - cluster : certificate-authority-data : DATA+OMITTED server : https://api.test-cluster.p40698.staging-k8s.cleura.cloud name : shoot--p40698--test-cluster contexts : - context : cluster : shoot--p40698--test-cluster user : shoot--p40698--test-cluster-token name : shoot--p40698--test-cluster current-context : shoot--p40698--test-cluster kind : Config preferences : { } users : - name : shoot--p40698--test-cluster-token user : token : REDACTED Access your cluster with kubectl and deploy an application Check your available nodes by running: kubectl get nodes You should see Gardener\u2019s worker node that is available: NAME STATUS ROLES AGE VERSION shoot--p40698--test-cluster-czg4zf-z1-5d7b5-bfl7p Ready <none> 156m v1.24.3 Create a sample deployment with a Hello World application: kubectl create deployment hello-node --image = registry.k8s.io/echoserver:1.4 kubectl expose deployment hello-node --type = LoadBalancer --port = 8080 To access the created app, list the available services: kubectl get services You should get the load balancer service with its external IP and port number: NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE hello-node LoadBalancer 100.69.16.106 <External IP> 8080:32039/TCP 34m kubernetes ClusterIP 100.64.0.1 <none> 443/TCP 3h46m Open a browser and open <External IP>:8080 . You should see the page of the Hello World app.","title":"Creating Kubernetes clusters with Gardener"},{"location":"howto/kubernetes/gardener/create-shoot-cluster/#creating-kubernetes-clusters-with-gardener","text":"If you want to create a Kubernetes cluster, you can do it via Cleura Cloud Management Panel using Gardener. This how-to shows you how to do that, and how to deploy a sample application on such a cluster.","title":"Creating Kubernetes clusters with Gardener"},{"location":"howto/kubernetes/gardener/create-shoot-cluster/#prerequisites","text":"To access Gardener functionality from Cleura Cloud Management Panel, you need to enroll in our closed beta. For access to the closed beta, contact our Service Center . To access the Kubernetes cluster from your computer, you will need kubectl installed on your machine.","title":"Prerequisites"},{"location":"howto/kubernetes/gardener/create-shoot-cluster/#creating-a-kubernetes-cluster-in-cleura-cloud-management-panel","text":"To get started, navigate to https://cleura.cloud , and in the side panel choose Kubernetes \u2192 Managed Kubernetes . You will see a Gardener page, in which you can create and manage your clusters. Click Create Kubernetes cluster . In Gardener\u2019s terminology, a Kubernetes cluster is referred as a Shoot cluster . You can see the name \u201cShoot\u201d in various places throughout the panel\u2019s UI, so it is good to know what it means. To learn more, check out Gardener architecture . In the opened form, fill in the name of the cluster and a region to see the rest of the options. Hover over question mark icons at each form field to learn more about it. For the purposes of this how-to, you can leave everything at default values and click Create at the bottom. In the form you can see a section about worker groups. This name refers to Kubernetes worker nodes. In the list of clusters, you will see your new Gardener shoot bootstrapping. The icon on the left marks the progress. Creating the cluster can take up to several minutes.","title":"Creating a Kubernetes cluster in Cleura Cloud Management Panel"},{"location":"howto/kubernetes/gardener/create-shoot-cluster/#extract-kubeconfig-file-from-shoot-cluster","text":"When the Shoot cluster is up and running, you need to get a kubeconfig file to be able to access it. To do that, click on the cluster to expand its properties, and open Kubeconfig . You should now see the file\u2019s contents. You have the option to Copy Config or Rotate Kubeconfig if your credentials got compromised. Copy the content of the kubeconfig and insert it into ~/.kube/config . Create the directory and the file if needed. By default, Kubectl searches for its configuration in ~/.kube/config , but you can modify this behaviour if needed. More info here . Check if your kubectl uses the proper configuration by running: kubectl config view You should see something like this: apiVersion : v1 clusters : - cluster : certificate-authority-data : DATA+OMITTED server : https://api.test-cluster.p40698.staging-k8s.cleura.cloud name : shoot--p40698--test-cluster contexts : - context : cluster : shoot--p40698--test-cluster user : shoot--p40698--test-cluster-token name : shoot--p40698--test-cluster current-context : shoot--p40698--test-cluster kind : Config preferences : { } users : - name : shoot--p40698--test-cluster-token user : token : REDACTED","title":"Extract kubeconfig file from Shoot cluster"},{"location":"howto/kubernetes/gardener/create-shoot-cluster/#access-your-cluster-with-kubectl-and-deploy-an-application","text":"Check your available nodes by running: kubectl get nodes You should see Gardener\u2019s worker node that is available: NAME STATUS ROLES AGE VERSION shoot--p40698--test-cluster-czg4zf-z1-5d7b5-bfl7p Ready <none> 156m v1.24.3 Create a sample deployment with a Hello World application: kubectl create deployment hello-node --image = registry.k8s.io/echoserver:1.4 kubectl expose deployment hello-node --type = LoadBalancer --port = 8080 To access the created app, list the available services: kubectl get services You should get the load balancer service with its external IP and port number: NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE hello-node LoadBalancer 100.69.16.106 <External IP> 8080:32039/TCP 34m kubernetes ClusterIP 100.64.0.1 <none> 443/TCP 3h46m Open a browser and open <External IP>:8080 . You should see the page of the Hello World app.","title":"Access your cluster with kubectl and deploy an application"},{"location":"howto/kubernetes/magnum/","text":"Magnum Magnum lets you create clusters via the OpenStack APIs. To do that, you base your configuration on a Cluster Template. The template defines parameters describing how the cluster will be constructed, such as worker flavors. In each region, we offer predefined public Cluster Templates with ready-to-use configurations. To learn more about Cluster Templates, check out the Magnum documentation . Once you have chosen your Cluster Template, you move on to create a cluster based on that template . When you create the cluster, you can define the number of nodes in your cluster, ask for multiple master nodes with a load balancer in front, etc.","title":"Magnum"},{"location":"howto/kubernetes/magnum/#magnum","text":"Magnum lets you create clusters via the OpenStack APIs. To do that, you base your configuration on a Cluster Template. The template defines parameters describing how the cluster will be constructed, such as worker flavors. In each region, we offer predefined public Cluster Templates with ready-to-use configurations. To learn more about Cluster Templates, check out the Magnum documentation . Once you have chosen your Cluster Template, you move on to create a cluster based on that template . When you create the cluster, you can define the number of nodes in your cluster, ask for multiple master nodes with a load balancer in front, etc.","title":"Magnum"},{"location":"howto/object-storage/s3/","text":"S3 API S3 is an object-access API based on HTTP and HTTPS. In Cleura Cloud, you interact with the S3 API using either the s3cmd command-line interface (CLI), the MinIO client CLI ( mc ), or the standard aws CLI. Either way, in addition to installing and configuring the Python openstackclient module , you need to install one of the aforementioned utilities. Debian/Ubuntu Mac OS X with Homebrew Python Package apt install s3cmd aws brew install minio-mc s3cmd pip install s3cmd Availability The S3 API is available in select Cleura Cloud regions. Refer to the feature support matrix for details on S3 API availability.","title":"S3 API"},{"location":"howto/object-storage/s3/#s3-api","text":"S3 is an object-access API based on HTTP and HTTPS. In Cleura Cloud, you interact with the S3 API using either the s3cmd command-line interface (CLI), the MinIO client CLI ( mc ), or the standard aws CLI. Either way, in addition to installing and configuring the Python openstackclient module , you need to install one of the aforementioned utilities. Debian/Ubuntu Mac OS X with Homebrew Python Package apt install s3cmd aws brew install minio-mc s3cmd pip install s3cmd","title":"S3 API"},{"location":"howto/object-storage/s3/#availability","text":"The S3 API is available in select Cleura Cloud regions. Refer to the feature support matrix for details on S3 API availability.","title":"Availability"},{"location":"howto/object-storage/s3/credentials/","text":"Working with S3-compatible credentials When you want to interact with object storage in Cleura Cloud using tools that support an Amazon S3 compatible API (such as s3cmd , rclone , the aws CLI, or the Python boto3 library), you need an S3-compatible access key ID and secret key. Creating credentials You can create a set of S3-compatible credentials with the following command: openstack ec2 credentials create This will return an Access and Secret key that you can use to populate the AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY environment variables (or whichever configuration options your application requires). Your S3-compatible credentials are always scoped to your Cleura Cloud region and project . You cannot reuse an access and secret key across multiple regions or projects. Also, your credentials are only \u201cS3-compatible\u201d in the sense that they use the same format as AWS S3 does. They are never valid against AWS S3 itself. Listing credentials You can list any previously-created credentials with: openstack ec2 credentials list Configuring your S3 API client Once you have obtained your S3-compatible access and secret key, you need to configure your S3 client with it. How exactly you do that depends on your preferred client: aws mc s3cmd Create a new profile, named after your Cleura Cloud region: aws configure set \\ --profile <region> \\ aws_access_key_id <access-key> aws configure set \\ --profile <region> \\ aws_secret_access_key <secret-key> For the aws CLI, you cannot define a region\u2019s endpoint in the profile. As such, you must add the --endpoint-url=https://s3-<region>.citycloud.com:8080 option to each aws s3api call. Create a new alias, named after your Cleura Cloud region: mc alias set <region> \\ https://s3-<region>.citycloud.com:8080 \\ <access-key> <secret-key> Once you have configured an alias like this, you are able to run bucket operations with mc using the alias/bucket syntax. s3cmd does not support configuration profiles, so you need to use a separate configuration file for each Cleura Cloud region you want to use: s3cmd -c ~/.s3cfg-<region> --configure Set your Access Key and Secret Key when prompted. Leave Default Region unchanged. Set S3 Endpoint to s3-<region>.citycloud.com:8080 . Set DNS-style bucket+hostname:port template for accessing a bucket to s3-<region>.citycloud.com:8080 as well. Set Use HTTPS protocol to Yes (the default). Configure GnuPG encryption and your HTTP proxy server, if needed. Test access with your supplied credentials. On subsequent invocations of the s3cmd CLI, always add the -c ~/.s3cfg-<region> option. Deleting credentials If at any time you need to delete a set of AWS-compatible credentials, you can do so with the following command: openstack ec2 credentials delete <access-key-id> Deleting a set of S3-compatible credentials will immediately revoke access for any applications that were using it.","title":"Working with S3-compatible credentials"},{"location":"howto/object-storage/s3/credentials/#working-with-s3-compatible-credentials","text":"When you want to interact with object storage in Cleura Cloud using tools that support an Amazon S3 compatible API (such as s3cmd , rclone , the aws CLI, or the Python boto3 library), you need an S3-compatible access key ID and secret key.","title":"Working with S3-compatible credentials"},{"location":"howto/object-storage/s3/credentials/#creating-credentials","text":"You can create a set of S3-compatible credentials with the following command: openstack ec2 credentials create This will return an Access and Secret key that you can use to populate the AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY environment variables (or whichever configuration options your application requires). Your S3-compatible credentials are always scoped to your Cleura Cloud region and project . You cannot reuse an access and secret key across multiple regions or projects. Also, your credentials are only \u201cS3-compatible\u201d in the sense that they use the same format as AWS S3 does. They are never valid against AWS S3 itself.","title":"Creating credentials"},{"location":"howto/object-storage/s3/credentials/#listing-credentials","text":"You can list any previously-created credentials with: openstack ec2 credentials list","title":"Listing credentials"},{"location":"howto/object-storage/s3/credentials/#configuring-your-s3-api-client","text":"Once you have obtained your S3-compatible access and secret key, you need to configure your S3 client with it. How exactly you do that depends on your preferred client: aws mc s3cmd Create a new profile, named after your Cleura Cloud region: aws configure set \\ --profile <region> \\ aws_access_key_id <access-key> aws configure set \\ --profile <region> \\ aws_secret_access_key <secret-key> For the aws CLI, you cannot define a region\u2019s endpoint in the profile. As such, you must add the --endpoint-url=https://s3-<region>.citycloud.com:8080 option to each aws s3api call. Create a new alias, named after your Cleura Cloud region: mc alias set <region> \\ https://s3-<region>.citycloud.com:8080 \\ <access-key> <secret-key> Once you have configured an alias like this, you are able to run bucket operations with mc using the alias/bucket syntax. s3cmd does not support configuration profiles, so you need to use a separate configuration file for each Cleura Cloud region you want to use: s3cmd -c ~/.s3cfg-<region> --configure Set your Access Key and Secret Key when prompted. Leave Default Region unchanged. Set S3 Endpoint to s3-<region>.citycloud.com:8080 . Set DNS-style bucket+hostname:port template for accessing a bucket to s3-<region>.citycloud.com:8080 as well. Set Use HTTPS protocol to Yes (the default). Configure GnuPG encryption and your HTTP proxy server, if needed. Test access with your supplied credentials. On subsequent invocations of the s3cmd CLI, always add the -c ~/.s3cfg-<region> option.","title":"Configuring your S3 API client"},{"location":"howto/object-storage/s3/credentials/#deleting-credentials","text":"If at any time you need to delete a set of AWS-compatible credentials, you can do so with the following command: openstack ec2 credentials delete <access-key-id> Deleting a set of S3-compatible credentials will immediately revoke access for any applications that were using it.","title":"Deleting credentials"},{"location":"howto/object-storage/s3/expiry/","text":"Object expiry Object expiry requires that you configure your environment with working S3-compatible credentials . You can set a bucket\u2019s lifecycle configuration such that it automatically deletes objects after a certain number of days. First, you need to create a JSON file, lifecycle.json , that contains the lifecycle configuration rule. Be sure to set Days to your desired value: { \"Rules\" : [{ \"ID\" : \"cleanup\" , \"Status\" : \"Enabled\" , \"Prefix\" : \"\" , \"Expiration\" : { \"Days\" : 5 } }] } Then, apply this lifecycle configuration to your bucket using one of the following commands: aws mc s3cmd aws --profile <region> \\ --endpoint-url = https://s3-<region>.citycloud.com:8080 \\ s3api put-bucket-lifecycle-configuration \\ --lifecycle-configuration file://lifecycle.json \\ --bucket <bucket-name> mc ilm import <region>/<bucket-name> < lifecycle.json s3cmd -c ~/.s3cfg-<region> setlifecycle lifecycle.json s3://<bucket-name>","title":"Object expiry"},{"location":"howto/object-storage/s3/expiry/#object-expiry","text":"Object expiry requires that you configure your environment with working S3-compatible credentials . You can set a bucket\u2019s lifecycle configuration such that it automatically deletes objects after a certain number of days. First, you need to create a JSON file, lifecycle.json , that contains the lifecycle configuration rule. Be sure to set Days to your desired value: { \"Rules\" : [{ \"ID\" : \"cleanup\" , \"Status\" : \"Enabled\" , \"Prefix\" : \"\" , \"Expiration\" : { \"Days\" : 5 } }] } Then, apply this lifecycle configuration to your bucket using one of the following commands: aws mc s3cmd aws --profile <region> \\ --endpoint-url = https://s3-<region>.citycloud.com:8080 \\ s3api put-bucket-lifecycle-configuration \\ --lifecycle-configuration file://lifecycle.json \\ --bucket <bucket-name> mc ilm import <region>/<bucket-name> < lifecycle.json s3cmd -c ~/.s3cfg-<region> setlifecycle lifecycle.json s3://<bucket-name>","title":"Object expiry"},{"location":"howto/object-storage/s3/sse-c/","text":"Client-side encryption (SSE-C) You can use objects encryption via S3 API, according to the Amazon SSE-C specification. This means that you need to provide an encryption/decryption key with each request to the object. You can store the encryption key in Barbican, and provide it to the S3 client at runtime. Below we will provide more detailed explanation regarding how to use this in your workloads. Requirements This guide assumes familiarity with the following tools: python-openstackclient (with the python-barbicanclient plugin), pwgen , rclone version 1.54 or later. Create encryption details According to SSE-C specification, in order to use server-side encryption, any S3 client needs to provide three pieces of information, which it includes in the request headers for each S3 request being made: Encryption algorithm: the only valid option here is AES256. Encryption key: a generated random key that we will store in Barbican. It should be valid AES key, which means that key length must be 32 bytes. Encryption key checksum: MD5 checksum of the encryption key. It\u2019s used for integrity checks. In order to generate encryption key and store it in Barbican, proceed as follows. Generate secret: secret_raw=$(pwgen 32 1) Store secret in Barbican: barbican_secret_url=$(openstack secret store --name objectSecret --algorithm aes --bit-length 256 --payload ${secret_raw} -f value -c 'Secret href') Retrieve secret from Barbican: secret=$(openstack secret get ${barbican_secret_url} -p -c Payload -f value) Managing encrypted objects in S3 (with rclone ) SSE-C encryption has been implemented/fixed with version 1.54. Prior rclone versions won\u2019t work here. Download and install the latest rclone for your distribution: https://rclone.org/downloads/ Create or retrieve your access key ID and secret key . Create a configuration file named ~/.rclone.conf , with the following content: [cleuracloud] type = s3 provider = Ceph env_auth = false access_key_id = <access key id> secret_access_key = <secret key> endpoint = <region>.citycloud.com:8080 acl = private sse_customer_algorithm = AES256 Create an S3 bucket: rclone mkdir cleuracloud:encrypted Sync a directory to the S3 bucket, encrypting the files it contains on upload: rclone sync ~/media/ cleuracloud:encrypted \\ --s3-sse-customer-key=${secret} Retrieve a file from S3 and decrypt it: rclone copy cleuracloud:encrypted/file.png \\ --s3-sse-customer-key=${secret} For more examples on how to use rclone, please use its reference documentation: https://rclone.org/docs/#subcommands","title":"Client-side encryption (SSE-C)"},{"location":"howto/object-storage/s3/sse-c/#client-side-encryption-sse-c","text":"You can use objects encryption via S3 API, according to the Amazon SSE-C specification. This means that you need to provide an encryption/decryption key with each request to the object. You can store the encryption key in Barbican, and provide it to the S3 client at runtime. Below we will provide more detailed explanation regarding how to use this in your workloads.","title":"Client-side encryption (SSE-C)"},{"location":"howto/object-storage/s3/sse-c/#requirements","text":"This guide assumes familiarity with the following tools: python-openstackclient (with the python-barbicanclient plugin), pwgen , rclone version 1.54 or later.","title":"Requirements"},{"location":"howto/object-storage/s3/sse-c/#create-encryption-details","text":"According to SSE-C specification, in order to use server-side encryption, any S3 client needs to provide three pieces of information, which it includes in the request headers for each S3 request being made: Encryption algorithm: the only valid option here is AES256. Encryption key: a generated random key that we will store in Barbican. It should be valid AES key, which means that key length must be 32 bytes. Encryption key checksum: MD5 checksum of the encryption key. It\u2019s used for integrity checks. In order to generate encryption key and store it in Barbican, proceed as follows. Generate secret: secret_raw=$(pwgen 32 1) Store secret in Barbican: barbican_secret_url=$(openstack secret store --name objectSecret --algorithm aes --bit-length 256 --payload ${secret_raw} -f value -c 'Secret href') Retrieve secret from Barbican: secret=$(openstack secret get ${barbican_secret_url} -p -c Payload -f value)","title":"Create encryption details"},{"location":"howto/object-storage/s3/sse-c/#managing-encrypted-objects-in-s3-with-rclone","text":"SSE-C encryption has been implemented/fixed with version 1.54. Prior rclone versions won\u2019t work here. Download and install the latest rclone for your distribution: https://rclone.org/downloads/ Create or retrieve your access key ID and secret key . Create a configuration file named ~/.rclone.conf , with the following content: [cleuracloud] type = s3 provider = Ceph env_auth = false access_key_id = <access key id> secret_access_key = <secret key> endpoint = <region>.citycloud.com:8080 acl = private sse_customer_algorithm = AES256 Create an S3 bucket: rclone mkdir cleuracloud:encrypted Sync a directory to the S3 bucket, encrypting the files it contains on upload: rclone sync ~/media/ cleuracloud:encrypted \\ --s3-sse-customer-key=${secret} Retrieve a file from S3 and decrypt it: rclone copy cleuracloud:encrypted/file.png \\ --s3-sse-customer-key=${secret} For more examples on how to use rclone, please use its reference documentation: https://rclone.org/docs/#subcommands","title":"Managing encrypted objects in S3 (with rclone)"},{"location":"howto/object-storage/s3/versioning/","text":"Object versioning Object versioning requires that you configure your environment with working S3-compatible credentials . Enabling bucket versioning To enable versioning in a bucket, use one of the following commands: aws mc s3cmd aws --profile <region> \\ --endpoint-url = https://s3-<region>.citycloud.com:8080 \\ s3api put-bucket-versioning \\ --versioning-configuration Status = Enabled \\ --bucket <bucket-name> mc version enable <region>/<bucket-name> This functionality is not available with the s3cmd command. Checking bucket versioning status To check whether object versioning is enabled on a bucket, use one of the following commands: aws mc s3cmd aws --profile <region> \\ --endpoint-url = https://s3-<region>.citycloud.com:8080 \\ s3api get-bucket-versioning \\ --bucket <bucket-name> mc version info <region>/<bucket-name> This functionality is not available with the s3cmd command. Creating a versioned object Once object versioning is enabled on a bucket, the normal object creation and replacement commands behave in a manner different from that in unversioned buckets: If the object does not already exist, it is created (as in an unversioned bucket). If the object does already exist, it is not replaced. Instead, a new version appears in addition to the old one. aws mc s3cmd aws --profile <region> \\ --endpoint-url = https://s3-<region>.citycloud.com:8080 \\ s3api put-object \\ --bucket <bucket-name> \\ --key <object-name> \\ --body <local-filename> mc cp \\ <local-filename> \\ <region>/<bucket-name>/<object-name> s3cmd put <local-filename> s3://<bucket> Listing object versions In a bucket that has versioning enabled, you may list the versions available for an object: aws mc s3cmd aws --profile <region> \\ --endpoint-url = https://s3-<region>.citycloud.com:8080 \\ s3api list-object-versions \\ --bucket <bucket-name> \\ --key <object-name> mc stat --versions <region>/<bucket-name> This functionality may be impacted by bugs in several versions of the mc client. This functionality is not available with the s3cmd command. Retrieving a versioned object To download a specific version of an object in a bucket, use one of the following commands: aws mc s3cmd aws --profile <region> \\ --endpoint-url = https://s3-<region>.citycloud.com:8080 \\ s3api get-object \\ --bucket <bucket-name> \\ --key <object-name> \\ --version-id <versionid> \\ <local-filename> mc cp \\ --version-id <versionid> \\ <region>/<bucket-name>/<object-name> \\ <local-filename> This functionality is not available with the s3cmd command. When you download an object from a versioned bucket without specifying a version identifier, your S3 client will download the latest version of that object. Deleting a versioned object Like the commands to create objects, the commands to delete them behave differently once object versioning is enabled on a bucket. The command to delete an object will normally not delete it, but revert it to the prior version. The exception to this rule is when there is only a single version of the object left in the bucket, in which case object removal does occur. aws mc s3cmd aws --profile <region> \\ --endpoint-url = https://s3-<region>.citycloud.com:8080 \\ s3api delete-object \\ --bucket <bucket-name> \\ --key <object-name> mc rm \\ <region>/<bucket-name>/<object-name> s3cmd del s3://<bucket-name>/<object-name> You also have the option of deleting not the latest version, but a specific object version: aws mc s3cmd aws --profile <region> \\ --endpoint-url = https://s3-<region>.citycloud.com:8080 \\ s3api delete-object \\ --version-id <versionid> \\ --bucket <bucket-name> \\ --key <object-name> mc rm \\ --version-id <versionid> \\ <region>/<bucket-name>/<object-name> This functionality is not available with the s3cmd command.","title":"Object versioning"},{"location":"howto/object-storage/s3/versioning/#object-versioning","text":"Object versioning requires that you configure your environment with working S3-compatible credentials .","title":"Object versioning"},{"location":"howto/object-storage/s3/versioning/#enabling-bucket-versioning","text":"To enable versioning in a bucket, use one of the following commands: aws mc s3cmd aws --profile <region> \\ --endpoint-url = https://s3-<region>.citycloud.com:8080 \\ s3api put-bucket-versioning \\ --versioning-configuration Status = Enabled \\ --bucket <bucket-name> mc version enable <region>/<bucket-name> This functionality is not available with the s3cmd command.","title":"Enabling bucket versioning"},{"location":"howto/object-storage/s3/versioning/#checking-bucket-versioning-status","text":"To check whether object versioning is enabled on a bucket, use one of the following commands: aws mc s3cmd aws --profile <region> \\ --endpoint-url = https://s3-<region>.citycloud.com:8080 \\ s3api get-bucket-versioning \\ --bucket <bucket-name> mc version info <region>/<bucket-name> This functionality is not available with the s3cmd command.","title":"Checking bucket versioning status"},{"location":"howto/object-storage/s3/versioning/#creating-a-versioned-object","text":"Once object versioning is enabled on a bucket, the normal object creation and replacement commands behave in a manner different from that in unversioned buckets: If the object does not already exist, it is created (as in an unversioned bucket). If the object does already exist, it is not replaced. Instead, a new version appears in addition to the old one. aws mc s3cmd aws --profile <region> \\ --endpoint-url = https://s3-<region>.citycloud.com:8080 \\ s3api put-object \\ --bucket <bucket-name> \\ --key <object-name> \\ --body <local-filename> mc cp \\ <local-filename> \\ <region>/<bucket-name>/<object-name> s3cmd put <local-filename> s3://<bucket>","title":"Creating a versioned object"},{"location":"howto/object-storage/s3/versioning/#listing-object-versions","text":"In a bucket that has versioning enabled, you may list the versions available for an object: aws mc s3cmd aws --profile <region> \\ --endpoint-url = https://s3-<region>.citycloud.com:8080 \\ s3api list-object-versions \\ --bucket <bucket-name> \\ --key <object-name> mc stat --versions <region>/<bucket-name> This functionality may be impacted by bugs in several versions of the mc client. This functionality is not available with the s3cmd command.","title":"Listing object versions"},{"location":"howto/object-storage/s3/versioning/#retrieving-a-versioned-object","text":"To download a specific version of an object in a bucket, use one of the following commands: aws mc s3cmd aws --profile <region> \\ --endpoint-url = https://s3-<region>.citycloud.com:8080 \\ s3api get-object \\ --bucket <bucket-name> \\ --key <object-name> \\ --version-id <versionid> \\ <local-filename> mc cp \\ --version-id <versionid> \\ <region>/<bucket-name>/<object-name> \\ <local-filename> This functionality is not available with the s3cmd command. When you download an object from a versioned bucket without specifying a version identifier, your S3 client will download the latest version of that object.","title":"Retrieving a versioned object"},{"location":"howto/object-storage/s3/versioning/#deleting-a-versioned-object","text":"Like the commands to create objects, the commands to delete them behave differently once object versioning is enabled on a bucket. The command to delete an object will normally not delete it, but revert it to the prior version. The exception to this rule is when there is only a single version of the object left in the bucket, in which case object removal does occur. aws mc s3cmd aws --profile <region> \\ --endpoint-url = https://s3-<region>.citycloud.com:8080 \\ s3api delete-object \\ --bucket <bucket-name> \\ --key <object-name> mc rm \\ <region>/<bucket-name>/<object-name> s3cmd del s3://<bucket-name>/<object-name> You also have the option of deleting not the latest version, but a specific object version: aws mc s3cmd aws --profile <region> \\ --endpoint-url = https://s3-<region>.citycloud.com:8080 \\ s3api delete-object \\ --version-id <versionid> \\ --bucket <bucket-name> \\ --key <object-name> mc rm \\ --version-id <versionid> \\ <region>/<bucket-name>/<object-name> This functionality is not available with the s3cmd command.","title":"Deleting a versioned object"},{"location":"howto/object-storage/swift/","text":"Swift API OpenStack Swift (not to be confused with the programming language of the same name ) is an object-access API similar to, but distinct from, the S3 object storage API. In Cleura Cloud, you interact with the Swift API using either the swift command-line interface (CLI), or the standard openstack CLI. Either way, in addition to installing and configuring the Python openstackclient module , you need to install the Python swiftclient module. Use either the package manager of your operating system, or pip : Debian/Ubuntu Mac OS X with Homebrew Python Package apt install python3-swiftclient This Python module is unavailable via brew , but you can install it via pip . pip install python-swiftclient Availability The OpenStack Swift API is available in select Cleura Cloud regions. Refer to the feature support matrix for details on Swift API availability.","title":"Swift API"},{"location":"howto/object-storage/swift/#swift-api","text":"OpenStack Swift (not to be confused with the programming language of the same name ) is an object-access API similar to, but distinct from, the S3 object storage API. In Cleura Cloud, you interact with the Swift API using either the swift command-line interface (CLI), or the standard openstack CLI. Either way, in addition to installing and configuring the Python openstackclient module , you need to install the Python swiftclient module. Use either the package manager of your operating system, or pip : Debian/Ubuntu Mac OS X with Homebrew Python Package apt install python3-swiftclient This Python module is unavailable via brew , but you can install it via pip . pip install python-swiftclient","title":"Swift API"},{"location":"howto/object-storage/swift/#availability","text":"The OpenStack Swift API is available in select Cleura Cloud regions. Refer to the feature support matrix for details on Swift API availability.","title":"Availability"},{"location":"howto/object-storage/swift/expiry/","text":"Object expiry Using the Swift API, you have the option for objects to automatically be deleted, after they have passed an expiry threshold. Prerequisites In order to manage object expiry, be sure that you have installed and configured the swift command-line interface (CLI). There is presently no way to set object expiry with the openstack CLI. Auto-deletion at a fixed date In order for an object to be automatically deleted at a certain date, you must first convert that date to a POSIX timestamp. You may do so with the date command. For example, to retrieve the POSIX timestamp for February 29, 2024, at 0000 UTC, use this command: $ TZ = Etc/UTC date -d '2024-02-29' + '%s' 1709164800 You can then set the X-Delete-At header on an object, so that it is automatically deleted at that time: $ swift post -H \"X-Delete-At: 1709164800\" private-container testobj.txt Then, you can read back the header with swift stat : $ swift stat private-container testobj.txt Account: AUTH_30a7768a0ffc40359d6110f21a6e7d88 Container: private-container Object: testobj.txt Content Type: binary/octet-stream Content Length: 12 Last Modified: Mon, 05 Dec 2022 14:09:02 GMT ETag: 6f5902ac237024bdd0c176cb93063dc4 Accept-Ranges: bytes X-Timestamp: 1670249342.53870 X-Delete-At: 1709164800 X-Trans-Id: tx00000646596cd018a2d7b-00638dfb91-300de11-default X-Openstack-Request-Id: tx00000646596cd018a2d7b-00638dfb91-300de11-default Auto-deletion after a time period Instead of giving an absolute time with X-Delete-At , you can also use X-Delete-After (in seconds), so that the object is automatically deleted after that timespan. This example uses 600 seconds or 10 minutes: $ swift post -H \"X-Delete-After: 600\" private-container testobj.txt The Swift API then converts this into an X-Delete-At header, adding the specified time span to the date the request is received (indicated by the X-Timestamp header). You can then read back the object metadata. Observe that in this example, the difference between the X-Timestamp and X-Delete-At headers is 600 seconds: $ swift stat private-container testobj.txt Account: AUTH_30a7768a0ffc40359d6110f21a6e7d88 Container: private-container Object: testobj.txt Content Type: binary/octet-stream Content Length: 12 Last Modified: Mon, 05 Dec 2022 14:09:55 GMT ETag: 6f5902ac237024bdd0c176cb93063dc4 Accept-Ranges: bytes X-Timestamp: 1670249395.20576 X-Delete-At: 1670249995 X-Trans-Id: tx0000065937c08551ba2be-00638dfbb6-301ddeb-default X-Openstack-Request-Id: tx0000065937c08551ba2be-00638dfbb6-301ddeb-default","title":"Object expiry"},{"location":"howto/object-storage/swift/expiry/#object-expiry","text":"Using the Swift API, you have the option for objects to automatically be deleted, after they have passed an expiry threshold.","title":"Object expiry"},{"location":"howto/object-storage/swift/expiry/#prerequisites","text":"In order to manage object expiry, be sure that you have installed and configured the swift command-line interface (CLI). There is presently no way to set object expiry with the openstack CLI.","title":"Prerequisites"},{"location":"howto/object-storage/swift/expiry/#auto-deletion-at-a-fixed-date","text":"In order for an object to be automatically deleted at a certain date, you must first convert that date to a POSIX timestamp. You may do so with the date command. For example, to retrieve the POSIX timestamp for February 29, 2024, at 0000 UTC, use this command: $ TZ = Etc/UTC date -d '2024-02-29' + '%s' 1709164800 You can then set the X-Delete-At header on an object, so that it is automatically deleted at that time: $ swift post -H \"X-Delete-At: 1709164800\" private-container testobj.txt Then, you can read back the header with swift stat : $ swift stat private-container testobj.txt Account: AUTH_30a7768a0ffc40359d6110f21a6e7d88 Container: private-container Object: testobj.txt Content Type: binary/octet-stream Content Length: 12 Last Modified: Mon, 05 Dec 2022 14:09:02 GMT ETag: 6f5902ac237024bdd0c176cb93063dc4 Accept-Ranges: bytes X-Timestamp: 1670249342.53870 X-Delete-At: 1709164800 X-Trans-Id: tx00000646596cd018a2d7b-00638dfb91-300de11-default X-Openstack-Request-Id: tx00000646596cd018a2d7b-00638dfb91-300de11-default","title":"Auto-deletion at a fixed date"},{"location":"howto/object-storage/swift/expiry/#auto-deletion-after-a-time-period","text":"Instead of giving an absolute time with X-Delete-At , you can also use X-Delete-After (in seconds), so that the object is automatically deleted after that timespan. This example uses 600 seconds or 10 minutes: $ swift post -H \"X-Delete-After: 600\" private-container testobj.txt The Swift API then converts this into an X-Delete-At header, adding the specified time span to the date the request is received (indicated by the X-Timestamp header). You can then read back the object metadata. Observe that in this example, the difference between the X-Timestamp and X-Delete-At headers is 600 seconds: $ swift stat private-container testobj.txt Account: AUTH_30a7768a0ffc40359d6110f21a6e7d88 Container: private-container Object: testobj.txt Content Type: binary/octet-stream Content Length: 12 Last Modified: Mon, 05 Dec 2022 14:09:55 GMT ETag: 6f5902ac237024bdd0c176cb93063dc4 Accept-Ranges: bytes X-Timestamp: 1670249395.20576 X-Delete-At: 1670249995 X-Trans-Id: tx0000065937c08551ba2be-00638dfbb6-301ddeb-default X-Openstack-Request-Id: tx0000065937c08551ba2be-00638dfbb6-301ddeb-default","title":"Auto-deletion after a time period"},{"location":"howto/object-storage/swift/private-container/","text":"Working with a private Swift container Prerequisites In order to create a Swift container, be sure that you have installed and configured the required command-line interface (CLI) tools. Creating a private container To create a private container (that is, one that can only be accessed with proper Swift API credentials), use the following command: OpenStack CLI Swift CLI $ openstack container create private-container +---------------------------------------+-------------------+----------------------------------------------------+ | account | container | x-trans-id | +---------------------------------------+-------------------+----------------------------------------------------+ | AUTH_30a7768a0ffc40359d6110f21a6e7d88 | private-container | tx00000ddb0f9e2a50ad881-00638dbf9c-300de11-default | +---------------------------------------+-------------------+----------------------------------------------------+ $ swift post private-container This command produces no output. Retrieving container information To create a list of all containers accessible with your current set of credentials, use this command: OpenStack CLI Swift CLI $ openstack container list +-------------------+ | Name | +-------------------+ | private-container | +-------------------+ $ swift list private-container To retrieve more detailed information about an individual container, you can also use this command: OpenStack CLI Swift CLI $ openstack container show private-container +----------------+---------------------------------------+ | Field | Value | +----------------+---------------------------------------+ | account | AUTH_30a7768a0ffc40359d6110f21a6e7d88 | | bytes_used | 0 | | container | private-container | | object_count | 0 | | storage_policy | default-placement | +----------------+---------------------------------------+ $ swift stat private-container Account: AUTH_30a7768a0ffc40359d6110f21a6e7d88 Container: private-container Objects: 0 Bytes: 0 Read ACL: Write ACL: Sync To: Sync Key: X-Timestamp: 1670234012.31534 X-Container-Bytes-Used-Actual: 0 X-Storage-Policy: default-placement X-Storage-Class: STANDARD Last-Modified: Mon, 05 Dec 2022 09:53:32 GMT X-Trans-Id: tx0000073eebb42acd6e7e1-00638dbfe8-301ddeb-default X-Openstack-Request-Id: tx0000073eebb42acd6e7e1-00638dbfe8-301ddeb-default Accept-Ranges: bytes Content-Type: text/plain; charset=utf-8 Uploading data To upload an object into the container, create a local test file: $ echo \"hello world\" > testobj.txt Then, upload the file (as a Swift object) into your container, and read back its metadata: OpenStack CLI Swift CLI $ openstack object create private-container testobj.txt +-------------+-------------------+----------------------------------+ | object | container | etag | +-------------+-------------------+----------------------------------+ | testobj.txt | private-container | 6f5902ac237024bdd0c176cb93063dc4 | +-------------+-------------------+----------------------------------+ $ openstack object show private-container testobj.txt +----------------+---------------------------------------+ | Field | Value | +----------------+---------------------------------------+ | account | AUTH_30a7768a0ffc40359d6110f21a6e7d88 | | container | private-container | | content-length | 12 | | content-type | text/plain | | etag | 6f5902ac237024bdd0c176cb93063dc4 | | last-modified | Mon, 05 Dec 2022 10:00:34 GMT | | object | testobj.txt | | properties | mtime='1670234292.370177' | +----------------+---------------------------------------+ $ swift upload private-container testobj.txt testobj.txt $ swift stat private-container testobj.txt Account: AUTH_30a7768a0ffc40359d6110f21a6e7d88 Container: private-container Object: testobj.txt Content Type: text/plain Content Length: 12 Last Modified: Mon, 05 Dec 2022 10:00:34 GMT ETag: 6f5902ac237024bdd0c176cb93063dc4 Meta Mtime: 1670234292.370177 Accept-Ranges: bytes X-Timestamp: 1670234434.67877 X-Trans-Id: tx000000f26ccf73c19f596-00638dc160-300de11-default X-Openstack-Request-Id: tx000000f26ccf73c19f596-00638dc160-300de11-default Downloading data To download an object from your Swift container, use the following command: OpenStack CLI Swift CLI $ openstack object save --file - private-container testobj.txt hello world The --file - option prints the file contents to stdout. If instead you want to save the object\u2019s content to a local file, use --file <filename> . If you omit the --file argument altogether, openstack object save will create a local file named like the object you are downloading (in this case, testobj.txt ). $ swift download -o - private-container testobj.txt hello world The -o - option prints the file contents to stdout. If instead you want to save the object\u2019s content to a local file, use -o <filename> . If you omit the -o argument altogether, swift download will create a local file named like the object you are downloading (in this case, testobj.txt ).","title":"Working with a private Swift container"},{"location":"howto/object-storage/swift/private-container/#working-with-a-private-swift-container","text":"","title":"Working with a private Swift container"},{"location":"howto/object-storage/swift/private-container/#prerequisites","text":"In order to create a Swift container, be sure that you have installed and configured the required command-line interface (CLI) tools.","title":"Prerequisites"},{"location":"howto/object-storage/swift/private-container/#creating-a-private-container","text":"To create a private container (that is, one that can only be accessed with proper Swift API credentials), use the following command: OpenStack CLI Swift CLI $ openstack container create private-container +---------------------------------------+-------------------+----------------------------------------------------+ | account | container | x-trans-id | +---------------------------------------+-------------------+----------------------------------------------------+ | AUTH_30a7768a0ffc40359d6110f21a6e7d88 | private-container | tx00000ddb0f9e2a50ad881-00638dbf9c-300de11-default | +---------------------------------------+-------------------+----------------------------------------------------+ $ swift post private-container This command produces no output.","title":"Creating a private container"},{"location":"howto/object-storage/swift/private-container/#retrieving-container-information","text":"To create a list of all containers accessible with your current set of credentials, use this command: OpenStack CLI Swift CLI $ openstack container list +-------------------+ | Name | +-------------------+ | private-container | +-------------------+ $ swift list private-container To retrieve more detailed information about an individual container, you can also use this command: OpenStack CLI Swift CLI $ openstack container show private-container +----------------+---------------------------------------+ | Field | Value | +----------------+---------------------------------------+ | account | AUTH_30a7768a0ffc40359d6110f21a6e7d88 | | bytes_used | 0 | | container | private-container | | object_count | 0 | | storage_policy | default-placement | +----------------+---------------------------------------+ $ swift stat private-container Account: AUTH_30a7768a0ffc40359d6110f21a6e7d88 Container: private-container Objects: 0 Bytes: 0 Read ACL: Write ACL: Sync To: Sync Key: X-Timestamp: 1670234012.31534 X-Container-Bytes-Used-Actual: 0 X-Storage-Policy: default-placement X-Storage-Class: STANDARD Last-Modified: Mon, 05 Dec 2022 09:53:32 GMT X-Trans-Id: tx0000073eebb42acd6e7e1-00638dbfe8-301ddeb-default X-Openstack-Request-Id: tx0000073eebb42acd6e7e1-00638dbfe8-301ddeb-default Accept-Ranges: bytes Content-Type: text/plain; charset=utf-8","title":"Retrieving container information"},{"location":"howto/object-storage/swift/private-container/#uploading-data","text":"To upload an object into the container, create a local test file: $ echo \"hello world\" > testobj.txt Then, upload the file (as a Swift object) into your container, and read back its metadata: OpenStack CLI Swift CLI $ openstack object create private-container testobj.txt +-------------+-------------------+----------------------------------+ | object | container | etag | +-------------+-------------------+----------------------------------+ | testobj.txt | private-container | 6f5902ac237024bdd0c176cb93063dc4 | +-------------+-------------------+----------------------------------+ $ openstack object show private-container testobj.txt +----------------+---------------------------------------+ | Field | Value | +----------------+---------------------------------------+ | account | AUTH_30a7768a0ffc40359d6110f21a6e7d88 | | container | private-container | | content-length | 12 | | content-type | text/plain | | etag | 6f5902ac237024bdd0c176cb93063dc4 | | last-modified | Mon, 05 Dec 2022 10:00:34 GMT | | object | testobj.txt | | properties | mtime='1670234292.370177' | +----------------+---------------------------------------+ $ swift upload private-container testobj.txt testobj.txt $ swift stat private-container testobj.txt Account: AUTH_30a7768a0ffc40359d6110f21a6e7d88 Container: private-container Object: testobj.txt Content Type: text/plain Content Length: 12 Last Modified: Mon, 05 Dec 2022 10:00:34 GMT ETag: 6f5902ac237024bdd0c176cb93063dc4 Meta Mtime: 1670234292.370177 Accept-Ranges: bytes X-Timestamp: 1670234434.67877 X-Trans-Id: tx000000f26ccf73c19f596-00638dc160-300de11-default X-Openstack-Request-Id: tx000000f26ccf73c19f596-00638dc160-300de11-default","title":"Uploading data"},{"location":"howto/object-storage/swift/private-container/#downloading-data","text":"To download an object from your Swift container, use the following command: OpenStack CLI Swift CLI $ openstack object save --file - private-container testobj.txt hello world The --file - option prints the file contents to stdout. If instead you want to save the object\u2019s content to a local file, use --file <filename> . If you omit the --file argument altogether, openstack object save will create a local file named like the object you are downloading (in this case, testobj.txt ). $ swift download -o - private-container testobj.txt hello world The -o - option prints the file contents to stdout. If instead you want to save the object\u2019s content to a local file, use -o <filename> . If you omit the -o argument altogether, swift download will create a local file named like the object you are downloading (in this case, testobj.txt ).","title":"Downloading data"},{"location":"howto/object-storage/swift/public-container/","text":"Working with a public Swift container Prerequisites In order to create a Swift container, be sure that you have installed and configured the required command-line interface (CLI) tools. Creating the container To create a public container (that is, one whose contents can be accessed without credentials), use the following command: OpenStack CLI Swift CLI $ openstack container create --public public-container +---------------------------------------+------------------+----------------------------------------------------+ | account | container | x-trans-id | +---------------------------------------+------------------+----------------------------------------------------+ | AUTH_30a7768a0ffc40359d6110f21a6e7d88 | public-container | tx00000d4f7d958e3e0c9aa-00638dc6ac-300de11-default | +---------------------------------------+------------------+----------------------------------------------------+ $ swift post --read-acl \".r:*,.rlistings\" public-container This command produces no output. Retrieving container information To create a list of all containers accessible with your current set of credentials, use this command: OpenStack CLI Swift CLI $ openstack container list +-------------------+ | Name | +-------------------+ | private-container | | public-container | +-------------------+ $ swift list private-container public-container To retrieve more detailed information about an individual container, you can also use this command. Observe that the Read access control list (ACL) contains the entry .r:*,.rlistings , which enables read access to all objects in a container, and to a list of objects included in the container. OpenStack CLI Swift CLI openstack container show public-container +----------------+---------------------------------------+ | Field | Value | +----------------+---------------------------------------+ | account | AUTH_30a7768a0ffc40359d6110f21a6e7d88 | | bytes_used | 0 | | container | public-container | | object_count | 0 | | read_acl | .r:*,.rlistings | | storage_policy | default-placement | +----------------+---------------------------------------+ $ swift stat public-container Account: AUTH_30a7768a0ffc40359d6110f21a6e7d88 Container: public-container Objects: 0 Bytes: 0 Read ACL: .r:*,.rlistings Write ACL: Sync To: Sync Key: X-Timestamp: 1670235997.87682 X-Container-Bytes-Used-Actual: 0 X-Storage-Policy: default-placement X-Storage-Class: STANDARD Last-Modified: Mon, 05 Dec 2022 10:26:37 GMT X-Trans-Id: tx00000cd9e7c26095ab862-00638dc78a-301ddeb-default X-Openstack-Request-Id: tx00000cd9e7c26095ab862-00638dc78a-301ddeb-default Accept-Ranges: bytes Content-Type: text/plain; charset=utf-8 Uploading data To upload an object into the container, create a local test file: $ echo \"hello world\" > testobj.txt Then, upload the file (as a Swift object) into your container, and read back its metadata: OpenStack CLI Swift CLI $ openstack object create public-container testobj.txt +-------------+------------------+----------------------------------+ | object | container | etag | +-------------+------------------+----------------------------------+ | testobj.txt | public-container | 6f5902ac237024bdd0c176cb93063dc4 | +-------------+------------------+----------------------------------+ $ openstack object show public-container testobj.txt +----------------+---------------------------------------+ | Field | Value | +----------------+---------------------------------------+ | account | AUTH_30a7768a0ffc40359d6110f21a6e7d88 | | container | public-container | | content-length | 12 | | content-type | text/plain | | etag | 6f5902ac237024bdd0c176cb93063dc4 | | last-modified | Mon, 05 Dec 2022 10:28:09 GMT | | object | testobj.txt | +----------------+---------------------------------------+ $ swift upload public-container testobj.txt testobj.txt $ swift stat public-container testobj.txt Account: AUTH_30a7768a0ffc40359d6110f21a6e7d88 Container: public-container Object: testobj.txt Content Type: text/plain Content Length: 12 Last Modified: Mon, 05 Dec 2022 10:28:09 GMT ETag: 6f5902ac237024bdd0c176cb93063dc4 Accept-Ranges: bytes X-Timestamp: 1670236089.75015 X-Trans-Id: tx0000075bca59e9149bc53-00638dc7fa-301ddeb-default X-Openstack-Request-Id: tx0000075bca59e9149bc53-00638dc7fa-301ddeb-default Downloading data To download an object from your public Swift container, you can use the following commands (as with a private container): OpenStack CLI Swift CLI $ openstack object save --file - private-container testobj.txt hello world The --file - option prints the file contents to stdout. If instead you want to save the object\u2019s content to a local file, use --file <filename> . If you omit the --file argument altogether, openstack object save will create a local file named like the object you are downloading (in this case, testobj.txt ). $ swift download -o - private-container testobj.txt hello world The -o - option prints the file contents to stdout. If instead you want to save the object\u2019s content to a local file, use -o <filename> . If you omit the -o argument altogether, swift download will create a local file named like the object you are downloading (in this case, testobj.txt ). However, this being a public container, you can also retrieve your object using any regular HTTP/HTTPS client, using a public URL. This URL is composed as follows: The Swift API\u2019s base URL, which differs by Cleura Cloud region ( https://swift\u2011<region>.citycloud.com:<port>/swift/v1/ ), the container\u2019s account string, starting with AUTH_ , the container name (in our example, public-container ), the object name (in our example, testobj.txt ). Rather than composing the public URL manually, you can also retrieve it by parsing the CLI\u2019s debug output: OpenStack CLI Swift CLI $ openstack object show --debug public-container testobj.txt 2 > & 1 \\ | grep -o \"https://.*testobj.txt\" https://swift-fra1.citycloud.com:8080/swift/v1/AUTH_30a7768a0ffc40359d6110f21a6e7d88/public-container/testobj.txt https://swift-fra1.citycloud.com:8080 \"HEAD /swift/v1/AUTH_30a7768a0ffc40359d6110f21a6e7d88/public-container/testobj.txt https://swift-fra1.citycloud.com:8080/swift/v1/AUTH_30a7768a0ffc40359d6110f21a6e7d88/public-container/testobj.txt $ swift stat --debug public-container testobj.txt 2 > & 1 \\ | grep -o \"https://.*testobj.txt\" https://swift-fra1.citycloud.com:8080/swift/v1/AUTH_30a7768a0ffc40359d6110f21a6e7d88/public-container/testobj.txt Once you have retrieved your public URL, you can fetch the object\u2019s contents using the client of your choice. This example uses curl : $ curl https://swift-fra1.citycloud.com:8080/swift/v1/AUTH_30a7768a0ffc40359d6110f21a6e7d88/public-container/testobj.txt hello world","title":"Working with a public Swift container"},{"location":"howto/object-storage/swift/public-container/#working-with-a-public-swift-container","text":"","title":"Working with a public Swift container"},{"location":"howto/object-storage/swift/public-container/#prerequisites","text":"In order to create a Swift container, be sure that you have installed and configured the required command-line interface (CLI) tools.","title":"Prerequisites"},{"location":"howto/object-storage/swift/public-container/#creating-the-container","text":"To create a public container (that is, one whose contents can be accessed without credentials), use the following command: OpenStack CLI Swift CLI $ openstack container create --public public-container +---------------------------------------+------------------+----------------------------------------------------+ | account | container | x-trans-id | +---------------------------------------+------------------+----------------------------------------------------+ | AUTH_30a7768a0ffc40359d6110f21a6e7d88 | public-container | tx00000d4f7d958e3e0c9aa-00638dc6ac-300de11-default | +---------------------------------------+------------------+----------------------------------------------------+ $ swift post --read-acl \".r:*,.rlistings\" public-container This command produces no output.","title":"Creating the container"},{"location":"howto/object-storage/swift/public-container/#retrieving-container-information","text":"To create a list of all containers accessible with your current set of credentials, use this command: OpenStack CLI Swift CLI $ openstack container list +-------------------+ | Name | +-------------------+ | private-container | | public-container | +-------------------+ $ swift list private-container public-container To retrieve more detailed information about an individual container, you can also use this command. Observe that the Read access control list (ACL) contains the entry .r:*,.rlistings , which enables read access to all objects in a container, and to a list of objects included in the container. OpenStack CLI Swift CLI openstack container show public-container +----------------+---------------------------------------+ | Field | Value | +----------------+---------------------------------------+ | account | AUTH_30a7768a0ffc40359d6110f21a6e7d88 | | bytes_used | 0 | | container | public-container | | object_count | 0 | | read_acl | .r:*,.rlistings | | storage_policy | default-placement | +----------------+---------------------------------------+ $ swift stat public-container Account: AUTH_30a7768a0ffc40359d6110f21a6e7d88 Container: public-container Objects: 0 Bytes: 0 Read ACL: .r:*,.rlistings Write ACL: Sync To: Sync Key: X-Timestamp: 1670235997.87682 X-Container-Bytes-Used-Actual: 0 X-Storage-Policy: default-placement X-Storage-Class: STANDARD Last-Modified: Mon, 05 Dec 2022 10:26:37 GMT X-Trans-Id: tx00000cd9e7c26095ab862-00638dc78a-301ddeb-default X-Openstack-Request-Id: tx00000cd9e7c26095ab862-00638dc78a-301ddeb-default Accept-Ranges: bytes Content-Type: text/plain; charset=utf-8","title":"Retrieving container information"},{"location":"howto/object-storage/swift/public-container/#uploading-data","text":"To upload an object into the container, create a local test file: $ echo \"hello world\" > testobj.txt Then, upload the file (as a Swift object) into your container, and read back its metadata: OpenStack CLI Swift CLI $ openstack object create public-container testobj.txt +-------------+------------------+----------------------------------+ | object | container | etag | +-------------+------------------+----------------------------------+ | testobj.txt | public-container | 6f5902ac237024bdd0c176cb93063dc4 | +-------------+------------------+----------------------------------+ $ openstack object show public-container testobj.txt +----------------+---------------------------------------+ | Field | Value | +----------------+---------------------------------------+ | account | AUTH_30a7768a0ffc40359d6110f21a6e7d88 | | container | public-container | | content-length | 12 | | content-type | text/plain | | etag | 6f5902ac237024bdd0c176cb93063dc4 | | last-modified | Mon, 05 Dec 2022 10:28:09 GMT | | object | testobj.txt | +----------------+---------------------------------------+ $ swift upload public-container testobj.txt testobj.txt $ swift stat public-container testobj.txt Account: AUTH_30a7768a0ffc40359d6110f21a6e7d88 Container: public-container Object: testobj.txt Content Type: text/plain Content Length: 12 Last Modified: Mon, 05 Dec 2022 10:28:09 GMT ETag: 6f5902ac237024bdd0c176cb93063dc4 Accept-Ranges: bytes X-Timestamp: 1670236089.75015 X-Trans-Id: tx0000075bca59e9149bc53-00638dc7fa-301ddeb-default X-Openstack-Request-Id: tx0000075bca59e9149bc53-00638dc7fa-301ddeb-default","title":"Uploading data"},{"location":"howto/object-storage/swift/public-container/#downloading-data","text":"To download an object from your public Swift container, you can use the following commands (as with a private container): OpenStack CLI Swift CLI $ openstack object save --file - private-container testobj.txt hello world The --file - option prints the file contents to stdout. If instead you want to save the object\u2019s content to a local file, use --file <filename> . If you omit the --file argument altogether, openstack object save will create a local file named like the object you are downloading (in this case, testobj.txt ). $ swift download -o - private-container testobj.txt hello world The -o - option prints the file contents to stdout. If instead you want to save the object\u2019s content to a local file, use -o <filename> . If you omit the -o argument altogether, swift download will create a local file named like the object you are downloading (in this case, testobj.txt ). However, this being a public container, you can also retrieve your object using any regular HTTP/HTTPS client, using a public URL. This URL is composed as follows: The Swift API\u2019s base URL, which differs by Cleura Cloud region ( https://swift\u2011<region>.citycloud.com:<port>/swift/v1/ ), the container\u2019s account string, starting with AUTH_ , the container name (in our example, public-container ), the object name (in our example, testobj.txt ). Rather than composing the public URL manually, you can also retrieve it by parsing the CLI\u2019s debug output: OpenStack CLI Swift CLI $ openstack object show --debug public-container testobj.txt 2 > & 1 \\ | grep -o \"https://.*testobj.txt\" https://swift-fra1.citycloud.com:8080/swift/v1/AUTH_30a7768a0ffc40359d6110f21a6e7d88/public-container/testobj.txt https://swift-fra1.citycloud.com:8080 \"HEAD /swift/v1/AUTH_30a7768a0ffc40359d6110f21a6e7d88/public-container/testobj.txt https://swift-fra1.citycloud.com:8080/swift/v1/AUTH_30a7768a0ffc40359d6110f21a6e7d88/public-container/testobj.txt $ swift stat --debug public-container testobj.txt 2 > & 1 \\ | grep -o \"https://.*testobj.txt\" https://swift-fra1.citycloud.com:8080/swift/v1/AUTH_30a7768a0ffc40359d6110f21a6e7d88/public-container/testobj.txt Once you have retrieved your public URL, you can fetch the object\u2019s contents using the client of your choice. This example uses curl : $ curl https://swift-fra1.citycloud.com:8080/swift/v1/AUTH_30a7768a0ffc40359d6110f21a6e7d88/public-container/testobj.txt hello world","title":"Downloading data"},{"location":"howto/object-storage/swift/tempurl/","text":"Using temporary URLs Even though an object might be stored in a private container , you may still grant temporary access to it. This is known as a temporary URL, or TempURL. Prerequisites In order to manage TempURLs, be sure that you have installed and configured the swift command-line interface (CLI). There is presently no way to create TempURLs with the openstack CLI. Also, ensure that you have configured a private container , i.e. one with an empty Read ACL. The examples in this how-to guide assume that your container is named private-container . Setting a TempURL shared secret In order to be able to create TempURLs, you must first create a shared secret at the account level. You should create a secret that is hard to guess, such as one generated by a utility like pwgen : TEMP_URL_KEY = ` pwgen 32 1 ` To set the account-level secret, proceed with the following command: OpenStack CLI Swift CLI $ openstack object store account set --property Temp-URL-Key = ${ TEMP_URL_KEY } $ swift post -m Temp-Url-Key: ${ TEMP_URL_KEY } Note that since this an account-level setting, you invoke swift post without a container or object name. The TempURL secret is not encrypted or hashed; you can read it back at the account level with the following command: OpenStack CLI Swift CLI $ openstack object store account show +------------+-------------------------------------------------+ | Field | Value | +------------+-------------------------------------------------+ | Account | AUTH_30a7768a0ffc40359d6110f21a6e7d88 | | Bytes | 24 | | Containers | 2 | | Objects | 2 | | properties | temp-url-key='tooNgeiNgieJe6bohg7teik8eiDeeMai' | +------------+-------------------------------------------------+ $ swift stat Account: AUTH_30a7768a0ffc40359d6110f21a6e7d88 Containers: 2 Objects: 2 Bytes: 24 Objects in policy \"default-placement-bytes\": 0 Bytes in policy \"default-placement-bytes\": 0 Containers in policy \"default-placement\": 2 Objects in policy \"default-placement\": 2 Bytes in policy \"default-placement\": 24 Meta Temp-Url-Key: tooNgeiNgieJe6bohg7teik8eiDeeMai X-Timestamp: 1670245963.98328 X-Account-Bytes-Used-Actual: 8192 X-Trans-Id: tx00000fbce1bedc1e2b138-00638dee4b-301ddeb-default X-Openstack-Request-Id: tx00000fbce1bedc1e2b138-00638dee4b-301ddeb-default Accept-Ranges: bytes Content-Type: text/plain; charset=utf-8 Creating a TempURL for an object To create a temporary URL for an object in a private container, select a duration for which you want it to be valid. The example below uses 1 hour (3,600 seconds). Then, use swift tempurl and specify the HTTP method for which the TempURL should apply (usually GET ), the TempURL lifetime, in seconds, the full path to the object including the /v1 prefix, the account identifier starting with AUTH_ , the container name, the object name, the TempURL key. When specified in this way, the command returns a path similar to the following: $ swift tempurl GET 3600 \\ /v1/AUTH_30a7768a0ffc40359d6110f21a6e7d88/private-container/testobj.txt \\ tooNgeiNgieJe6bohg7teik8eiDeeMai /v1/AUTH_30a7768a0ffc40359d6110f21a6e7d88/private-container/testobj.txt?temp_url_sig=995d136bf2a8b1140d4b26886c9a8fc73bfb6c0d&temp_url_expires=1670250048 Accessing objects via their TempURL You must then use your freshly generated TempURL path as the path in a URL pointing to the object. This will enable you to fetch the object using a simple HTTP client, like curl : $ curl 'https://swift-fra1.citycloud.com:8080/swift/v1/AUTH_30a7768a0ffc40359d6110f21a6e7d88/private-container/testobj.txt?temp_url_sig=995d136bf2a8b1140d4b26886c9a8fc73bfb6c0d&temp_url_expires=1670250048' hello world If you (or someone else) were to attempt to fetch the same URL after its lifetime expired, they would be met with an HTTP 401 error: $ curl -i 'https://swift-fra1.citycloud.com:8080/swift/v1/AUTH_30a7768a0ffc40359d6110f21a6e7d88/private-container/testobj.txt?temp_url_sig=995d136bf2a8b1140d4b26886c9a8fc73bfb6c0d&temp_url_expires=1670250048' HTTP/1.1 401 Unauthorized content-length: 12 x-trans-id: tx0000001113c5020d8a1de-00638df0ea-301ddeb-default x-openstack-request-id: tx0000001113c5020d8a1de-00638df0ea-301ddeb-default accept-ranges: bytes content-type: text/plain; charset=utf-8 date: Mon, 05 Dec 2022 14:23:54 GMT","title":"Using temporary URLs"},{"location":"howto/object-storage/swift/tempurl/#using-temporary-urls","text":"Even though an object might be stored in a private container , you may still grant temporary access to it. This is known as a temporary URL, or TempURL.","title":"Using temporary URLs"},{"location":"howto/object-storage/swift/tempurl/#prerequisites","text":"In order to manage TempURLs, be sure that you have installed and configured the swift command-line interface (CLI). There is presently no way to create TempURLs with the openstack CLI. Also, ensure that you have configured a private container , i.e. one with an empty Read ACL. The examples in this how-to guide assume that your container is named private-container .","title":"Prerequisites"},{"location":"howto/object-storage/swift/tempurl/#setting-a-tempurl-shared-secret","text":"In order to be able to create TempURLs, you must first create a shared secret at the account level. You should create a secret that is hard to guess, such as one generated by a utility like pwgen : TEMP_URL_KEY = ` pwgen 32 1 ` To set the account-level secret, proceed with the following command: OpenStack CLI Swift CLI $ openstack object store account set --property Temp-URL-Key = ${ TEMP_URL_KEY } $ swift post -m Temp-Url-Key: ${ TEMP_URL_KEY } Note that since this an account-level setting, you invoke swift post without a container or object name. The TempURL secret is not encrypted or hashed; you can read it back at the account level with the following command: OpenStack CLI Swift CLI $ openstack object store account show +------------+-------------------------------------------------+ | Field | Value | +------------+-------------------------------------------------+ | Account | AUTH_30a7768a0ffc40359d6110f21a6e7d88 | | Bytes | 24 | | Containers | 2 | | Objects | 2 | | properties | temp-url-key='tooNgeiNgieJe6bohg7teik8eiDeeMai' | +------------+-------------------------------------------------+ $ swift stat Account: AUTH_30a7768a0ffc40359d6110f21a6e7d88 Containers: 2 Objects: 2 Bytes: 24 Objects in policy \"default-placement-bytes\": 0 Bytes in policy \"default-placement-bytes\": 0 Containers in policy \"default-placement\": 2 Objects in policy \"default-placement\": 2 Bytes in policy \"default-placement\": 24 Meta Temp-Url-Key: tooNgeiNgieJe6bohg7teik8eiDeeMai X-Timestamp: 1670245963.98328 X-Account-Bytes-Used-Actual: 8192 X-Trans-Id: tx00000fbce1bedc1e2b138-00638dee4b-301ddeb-default X-Openstack-Request-Id: tx00000fbce1bedc1e2b138-00638dee4b-301ddeb-default Accept-Ranges: bytes Content-Type: text/plain; charset=utf-8","title":"Setting a TempURL shared secret"},{"location":"howto/object-storage/swift/tempurl/#creating-a-tempurl-for-an-object","text":"To create a temporary URL for an object in a private container, select a duration for which you want it to be valid. The example below uses 1 hour (3,600 seconds). Then, use swift tempurl and specify the HTTP method for which the TempURL should apply (usually GET ), the TempURL lifetime, in seconds, the full path to the object including the /v1 prefix, the account identifier starting with AUTH_ , the container name, the object name, the TempURL key. When specified in this way, the command returns a path similar to the following: $ swift tempurl GET 3600 \\ /v1/AUTH_30a7768a0ffc40359d6110f21a6e7d88/private-container/testobj.txt \\ tooNgeiNgieJe6bohg7teik8eiDeeMai /v1/AUTH_30a7768a0ffc40359d6110f21a6e7d88/private-container/testobj.txt?temp_url_sig=995d136bf2a8b1140d4b26886c9a8fc73bfb6c0d&temp_url_expires=1670250048","title":"Creating a TempURL for an object"},{"location":"howto/object-storage/swift/tempurl/#accessing-objects-via-their-tempurl","text":"You must then use your freshly generated TempURL path as the path in a URL pointing to the object. This will enable you to fetch the object using a simple HTTP client, like curl : $ curl 'https://swift-fra1.citycloud.com:8080/swift/v1/AUTH_30a7768a0ffc40359d6110f21a6e7d88/private-container/testobj.txt?temp_url_sig=995d136bf2a8b1140d4b26886c9a8fc73bfb6c0d&temp_url_expires=1670250048' hello world If you (or someone else) were to attempt to fetch the same URL after its lifetime expired, they would be met with an HTTP 401 error: $ curl -i 'https://swift-fra1.citycloud.com:8080/swift/v1/AUTH_30a7768a0ffc40359d6110f21a6e7d88/private-container/testobj.txt?temp_url_sig=995d136bf2a8b1140d4b26886c9a8fc73bfb6c0d&temp_url_expires=1670250048' HTTP/1.1 401 Unauthorized content-length: 12 x-trans-id: tx0000001113c5020d8a1de-00638df0ea-301ddeb-default x-openstack-request-id: tx0000001113c5020d8a1de-00638df0ea-301ddeb-default accept-ranges: bytes content-type: text/plain; charset=utf-8 date: Mon, 05 Dec 2022 14:23:54 GMT","title":"Accessing objects via their TempURL"},{"location":"howto/object-storage/swift/versioning/","text":"Object versioning Using the Swift API, you have the option to retain multiple versions of an object, rather than overwriting it in place. Prerequisites In order to manage object versioning, be sure that you have installed and configured the swift command-line interface (CLI). There is presently no way to set object expiry with the openstack CLI. Also, ensure that you have configured a private container , i.e. one with an empty Read ACL. The examples in this how-to guide assume that your container is named private-container , and that it presently contains a single object named testobj.txt . Creating a container for non-current versioned objects In addition to the container holding your live objects, private-container , you will also need one for your prior versions. In this example, we use the name private-container-versions for that container: $ swift post private-container-versions This command produces no output. Setting X-Versions-Location You must next set the X-Versions-Location header on the original container: $ swift post -H \"X-Versions-Location: private-container-versions\" private-container Testing object versioning You can now verify that object versioning is working correctly. Upload a new version of testobj.txt : $ echo \"bye bye\" > testobj.txt $ swift upload private-container testobj.txt Observe that there is now a newly created object in the private-container-versions container: $ swift list private-container-versions 00btestobj.txt/1670250073.717985 Issue a command to delete the object: $ swift delete private-container testobj.txt testobj.txt Read back the object. Since the container is now versioned, the \u201cdeletion\u201d in step 3 only caused a roll-back to the object\u2019s prior state: $ swift download -o - private-container testobj.txt hello world Object versioning does not prevent deleting the last remaining (i.e. first created) version of an object. Do not use object versioning as a prevention mechanism for inadvertent object deletion; it is not suitable for that purpose.","title":"Object versioning"},{"location":"howto/object-storage/swift/versioning/#object-versioning","text":"Using the Swift API, you have the option to retain multiple versions of an object, rather than overwriting it in place.","title":"Object versioning"},{"location":"howto/object-storage/swift/versioning/#prerequisites","text":"In order to manage object versioning, be sure that you have installed and configured the swift command-line interface (CLI). There is presently no way to set object expiry with the openstack CLI. Also, ensure that you have configured a private container , i.e. one with an empty Read ACL. The examples in this how-to guide assume that your container is named private-container , and that it presently contains a single object named testobj.txt .","title":"Prerequisites"},{"location":"howto/object-storage/swift/versioning/#creating-a-container-for-non-current-versioned-objects","text":"In addition to the container holding your live objects, private-container , you will also need one for your prior versions. In this example, we use the name private-container-versions for that container: $ swift post private-container-versions This command produces no output.","title":"Creating a container for non-current versioned objects"},{"location":"howto/object-storage/swift/versioning/#setting-x-versions-location","text":"You must next set the X-Versions-Location header on the original container: $ swift post -H \"X-Versions-Location: private-container-versions\" private-container","title":"Setting X-Versions-Location"},{"location":"howto/object-storage/swift/versioning/#testing-object-versioning","text":"You can now verify that object versioning is working correctly. Upload a new version of testobj.txt : $ echo \"bye bye\" > testobj.txt $ swift upload private-container testobj.txt Observe that there is now a newly created object in the private-container-versions container: $ swift list private-container-versions 00btestobj.txt/1670250073.717985 Issue a command to delete the object: $ swift delete private-container testobj.txt testobj.txt Read back the object. Since the container is now versioned, the \u201cdeletion\u201d in step 3 only caused a roll-back to the object\u2019s prior state: $ swift download -o - private-container testobj.txt hello world Object versioning does not prevent deleting the last remaining (i.e. first created) version of an object. Do not use object versioning as a prevention mechanism for inadvertent object deletion; it is not suitable for that purpose.","title":"Testing object versioning"},{"location":"howto/openstack/barbican/","text":"Using Barbican for secret storage Barbican is OpenStack\u2019s secret storage facility. In Cleura Cloud, Barbican is supported for the following purposes: Generic secret storage , encryption for persistent volumes , certificate storage for HTTPS load balancers . To manage secrets with Barbican, you will need the openstack command line interface (CLI), and its Barbican plugin. You can install them both with the following commands: pip install python-openstackclient python-barbicanclient On Debian/Ubuntu platforms, you may also install these utilities via their APT packages: apt install python3-openstackclient python3-barbicanclient","title":"Using Barbican for secret storage"},{"location":"howto/openstack/barbican/#using-barbican-for-secret-storage","text":"Barbican is OpenStack\u2019s secret storage facility. In Cleura Cloud, Barbican is supported for the following purposes: Generic secret storage , encryption for persistent volumes , certificate storage for HTTPS load balancers . To manage secrets with Barbican, you will need the openstack command line interface (CLI), and its Barbican plugin. You can install them both with the following commands: pip install python-openstackclient python-barbicanclient On Debian/Ubuntu platforms, you may also install these utilities via their APT packages: apt install python3-openstackclient python3-barbicanclient","title":"Using Barbican for secret storage"},{"location":"howto/openstack/barbican/generic-secret/","text":"Generic secret storage The simplest way to use Barbican is to create and retrieve a securely stored, generic secret. How to store a generic secret It is possible to store any secret data with Barbican. The command below will create a secret of the type passphrase , named mysecret , which contains the passphrase my very secret passphrase . openstack secret store \\ --secret-type passphrase \\ -p \"my very secret passphrase\" \\ -n mysecret The example output below uses Cleura Cloud\u2019s Fra1 region. In other regions, the secret URIs will differ. +---------------+--------------------------------------------------------------------------------+ | Field | Value | +---------------+--------------------------------------------------------------------------------+ | Secret href | https://fra1.citycloud.com:9311/v1/secrets/33ef0985-f89e-4bf0-b318-887ecac0cba | | Name | mysecret | | Created | None | | Status | None | | Content types | None | | Algorithm | aes | | Bit length | 256 | | Secret type | passphrase | | Mode | cbc | | Expiration | None | +---------------+--------------------------------------------------------------------------------+ Note that passphrase type secrets are symmetrically encrypted, using the AES encryption algorithm with a 256-bit key length. You can select other bit lengths and algorithms with the -b and -a command line options, if desired. How to retrieve secrets Secrets are stored in Barbican in an encrypted format. You can see a list of secrets created for your user with the following command: openstack secret list +--------------------------------------------------------------------------------+----------+---------------------------+--------+-----------------------------------------+-----------+------------+-------------+------+------------+ | Secret href | Name | Created | Status | Content types | Algorithm | Bit length | Secret type | Mode | Expiration | +--------------------------------------------------------------------------------+----------+---------------------------+--------+-----------------------------------------+-----------+------------+-------------+------+------------+ | https://fra1.citycloud.com:9311/v1/secrets/33ef0985-f89e-4bf0-b318-887ecac0cba | mysecret | 2021-04-29T10:33:18+00:00 | ACTIVE | {'default': 'application/octet-stream'} | aes | 256 | passphrase | cbc | None | | https://fra1.citycloud.com:9311/v1/secrets/ad628532-53b8-4d2f-91e5-0097b51da4e | None | 2021-04-27T13:52:10+00:00 | ACTIVE | {'default': 'application/octet-stream'} | aes | 256 | symmetric | None | None | +--------------------------------------------------------------------------------+----------+---------------------------+--------+-----------------------------------------+-----------+------------+-------------+------+------------+ You can retrieve the decrypted secret with the openstack secret get command, adding the -p (or --payload ) option: $ openstack secret get -p \\ https://fra1.citycloud.com:9311/v1/secrets/33ef0985-f89e-4bf0-b318-887ecac0cba +---------+---------------------------+ | Field | Value | +---------+---------------------------+ | Payload | my very secret passphrase | +---------+---------------------------+ Unlike many other OpenStack services, which allow you to retrieve object references by name or UUID, Barbican only lets you retrieve secrets by their full URI . That URI must include the https://<region>.citycloud.com:9311/v1/secrets/ prefix.","title":"Generic secret storage"},{"location":"howto/openstack/barbican/generic-secret/#generic-secret-storage","text":"The simplest way to use Barbican is to create and retrieve a securely stored, generic secret.","title":"Generic secret storage"},{"location":"howto/openstack/barbican/generic-secret/#how-to-store-a-generic-secret","text":"It is possible to store any secret data with Barbican. The command below will create a secret of the type passphrase , named mysecret , which contains the passphrase my very secret passphrase . openstack secret store \\ --secret-type passphrase \\ -p \"my very secret passphrase\" \\ -n mysecret The example output below uses Cleura Cloud\u2019s Fra1 region. In other regions, the secret URIs will differ. +---------------+--------------------------------------------------------------------------------+ | Field | Value | +---------------+--------------------------------------------------------------------------------+ | Secret href | https://fra1.citycloud.com:9311/v1/secrets/33ef0985-f89e-4bf0-b318-887ecac0cba | | Name | mysecret | | Created | None | | Status | None | | Content types | None | | Algorithm | aes | | Bit length | 256 | | Secret type | passphrase | | Mode | cbc | | Expiration | None | +---------------+--------------------------------------------------------------------------------+ Note that passphrase type secrets are symmetrically encrypted, using the AES encryption algorithm with a 256-bit key length. You can select other bit lengths and algorithms with the -b and -a command line options, if desired.","title":"How to store a generic secret"},{"location":"howto/openstack/barbican/generic-secret/#how-to-retrieve-secrets","text":"Secrets are stored in Barbican in an encrypted format. You can see a list of secrets created for your user with the following command: openstack secret list +--------------------------------------------------------------------------------+----------+---------------------------+--------+-----------------------------------------+-----------+------------+-------------+------+------------+ | Secret href | Name | Created | Status | Content types | Algorithm | Bit length | Secret type | Mode | Expiration | +--------------------------------------------------------------------------------+----------+---------------------------+--------+-----------------------------------------+-----------+------------+-------------+------+------------+ | https://fra1.citycloud.com:9311/v1/secrets/33ef0985-f89e-4bf0-b318-887ecac0cba | mysecret | 2021-04-29T10:33:18+00:00 | ACTIVE | {'default': 'application/octet-stream'} | aes | 256 | passphrase | cbc | None | | https://fra1.citycloud.com:9311/v1/secrets/ad628532-53b8-4d2f-91e5-0097b51da4e | None | 2021-04-27T13:52:10+00:00 | ACTIVE | {'default': 'application/octet-stream'} | aes | 256 | symmetric | None | None | +--------------------------------------------------------------------------------+----------+---------------------------+--------+-----------------------------------------+-----------+------------+-------------+------+------------+ You can retrieve the decrypted secret with the openstack secret get command, adding the -p (or --payload ) option: $ openstack secret get -p \\ https://fra1.citycloud.com:9311/v1/secrets/33ef0985-f89e-4bf0-b318-887ecac0cba +---------+---------------------------+ | Field | Value | +---------+---------------------------+ | Payload | my very secret passphrase | +---------+---------------------------+ Unlike many other OpenStack services, which allow you to retrieve object references by name or UUID, Barbican only lets you retrieve secrets by their full URI . That URI must include the https://<region>.citycloud.com:9311/v1/secrets/ prefix.","title":"How to retrieve secrets"},{"location":"howto/openstack/barbican/share-secret/","text":"Sharing secrets via ACLs Normally, a Barbican secret is only available to the OpenStack API user that created it. However, under some circumstances it may be desirable to make a secret available to another user. To do so, you will need the secret\u2019s URI , the other user\u2019s OpenStack API user ID. Any Cleura Cloud user can always retrieve their own user ID with the following command: openstack token issue -f value -c user_id Once you have assembled this information, you can proceed with the openstack acl user add command: openstack acl user add \\ --user <user_id> \\ --operation-type read \\ https://region.citycloud.com:9311/v1/secrets/<secret_id> If you want to unshare the secret again, you simply use the corresponding openstack acl user remove command: openstack acl user remove \\ --user <user_id> \\ --operation-type read \\ https://region.citycloud.com:9311/v1/secrets/<secret_id>","title":"Sharing secrets via ACLs"},{"location":"howto/openstack/barbican/share-secret/#sharing-secrets-via-acls","text":"Normally, a Barbican secret is only available to the OpenStack API user that created it. However, under some circumstances it may be desirable to make a secret available to another user. To do so, you will need the secret\u2019s URI , the other user\u2019s OpenStack API user ID. Any Cleura Cloud user can always retrieve their own user ID with the following command: openstack token issue -f value -c user_id Once you have assembled this information, you can proceed with the openstack acl user add command: openstack acl user add \\ --user <user_id> \\ --operation-type read \\ https://region.citycloud.com:9311/v1/secrets/<secret_id> If you want to unshare the secret again, you simply use the corresponding openstack acl user remove command: openstack acl user remove \\ --user <user_id> \\ --operation-type read \\ https://region.citycloud.com:9311/v1/secrets/<secret_id>","title":"Sharing secrets via ACLs"},{"location":"howto/openstack/cinder/encrypted-volumes/","text":"Encrypted volumes When using Barbican for block storage encryption, you ensure that data in persistent storage volumes is stored in an encrypted fashion. That encryption is transparent to virtual machines (instances) that you attach the volume to. Creating an encrypted volume For the creation of an encrypted volume, you need to provide a specific volume type. You can retrieve the list of available volume types with the following command: openstack volume type list +--------------------------------------+-----------------------+-----------+ | ID | Name | Is Public | +--------------------------------------+-----------------------+-----------+ | a479a6b0-b283-41a5-b38b-5b08e7f902ca | volumes_hdd_encrypted | True | | d9dfa98a-238d-4ca0-9abf-701fceb05623 | __DEFAULT__ | True | | 86796611-fb12-4628-b6b1-e09469e301d7 | volumes_hdd | True | +--------------------------------------+-----------------------+-----------+ In Cleura Cloud, all volume types that support encryption use the suffix _encrypted . To create a volume with encryption, you need to explicitly specify the --type option to the openstack volume create command. The following example creates a volume using the volumes_hdd_encrypted type, naming it enc_drive and setting its size to 10 GiB: openstack volume create \\ --type volumes_hdd_encrypted \\ --size 10 \\ enc_drive +---------------------+--------------------------------------+ | Field | Value | +---------------------+--------------------------------------+ | attachments | [] | | availability_zone | nova | | bootable | false | | consistencygroup_id | None | | created_at | 2021-04-27T13:52:10.000000 | | description | None | | encrypted | True | | id | 33211b21-8d4f-48e9-b76f-ec73ffd19def | | multiattach | False | | name | enc_drive | | properties | | | replication_status | None | | size | 10 | | snapshot_id | None | | source_volid | None | | status | creating | | type | volumes_hdd_encrypted | | updated_at | None | | user_id | 966ad341f4e14920b5f589f900246ccc | +---------------------+--------------------------------------+ Upon volume creation, this will create a one-off encryption key, which is stored in Barbican and applies to this one volume only. In other words, the key created for this volume will be unable to decrypt any other volumes except the one it was created for. Retrieving a volume\u2019s encryption key Once you have created an encrypted volume, you may retrieve a reference to the Barbican secret that represents its encryption key. You do this with the following command: openstack volume show \\ --os-volume-api-version 3 .66 \\ -f value \\ -c encryption_key_id \\ enc_drive Instead of the volume name, you can of course also specify its UUID: openstack volume show \\ --os-volume-api-version 3 .66 \\ -f value \\ -c encryption_key_id \\ 33211b21-8d4f-48e9-b76f-ec73ffd19def Deleting an encrypted volume When you decide you no longer need an encrypted volume and want to delete it, you can do so with the openstack volume delete command. As long as you do this with the same user account as the one that created the volume, this will succeed without further intervention. However, if you are trying to delete a volume that was created by a different user, you\u2019ll run into the limitation that the secret associated with the volume is owned by that user. As a result, the deletion of the encrypted volume using your own user credentials will fail. There are two options to work around this limitation: You can switch to the user credentials of the user that created the volume (if you have access to them), and proceed with the deletion. You can ask the user that created the volume to add you to the Access Control List (ACL) for the secret . This will enable you to read the secret, and to delete the volume using your own credentials. Block device encryption caveats Once a volume is configured to use encryption and is also attached to an instance in Cleura Cloud, some caveats apply that you might want to keep in mind. Sometimes, automatically or through administrator intervention, we move one of your instances to another physical machine. This process is known as live migration, and it normally does not interrupt the instance\u2019s functionality at all \u2014 typically, neither you nor the application users notice that live migration has even happened. This is a very common occurrence when we do routine upgrades of the Cleura Cloud platform, during our pre-announced maintenance windows. The same considerations apply to physical node failure. If the physical machine running your instance fails, we can automatically recover it onto another machine \u2014 an action known as evacuation. Live migration or evacuation including encrypted volumes does, however, require that whoever does the migration also has at least read access to the volume\u2019s encryption secret. This means that you have two options: If you do trust us to include your instances in live migrations and evacuations, even if they attach encrypted volumes, then you can add our administrative account to the Access Control List (ACL) for your secrets . If you don\u2019t want to share your secrets but you still want to use encrypted volumes, you should build your own mechanism or process (preferably automated) so that your instances recover in case they become non-functional.","title":"Encrypted volumes"},{"location":"howto/openstack/cinder/encrypted-volumes/#encrypted-volumes","text":"When using Barbican for block storage encryption, you ensure that data in persistent storage volumes is stored in an encrypted fashion. That encryption is transparent to virtual machines (instances) that you attach the volume to.","title":"Encrypted volumes"},{"location":"howto/openstack/cinder/encrypted-volumes/#creating-an-encrypted-volume","text":"For the creation of an encrypted volume, you need to provide a specific volume type. You can retrieve the list of available volume types with the following command: openstack volume type list +--------------------------------------+-----------------------+-----------+ | ID | Name | Is Public | +--------------------------------------+-----------------------+-----------+ | a479a6b0-b283-41a5-b38b-5b08e7f902ca | volumes_hdd_encrypted | True | | d9dfa98a-238d-4ca0-9abf-701fceb05623 | __DEFAULT__ | True | | 86796611-fb12-4628-b6b1-e09469e301d7 | volumes_hdd | True | +--------------------------------------+-----------------------+-----------+ In Cleura Cloud, all volume types that support encryption use the suffix _encrypted . To create a volume with encryption, you need to explicitly specify the --type option to the openstack volume create command. The following example creates a volume using the volumes_hdd_encrypted type, naming it enc_drive and setting its size to 10 GiB: openstack volume create \\ --type volumes_hdd_encrypted \\ --size 10 \\ enc_drive +---------------------+--------------------------------------+ | Field | Value | +---------------------+--------------------------------------+ | attachments | [] | | availability_zone | nova | | bootable | false | | consistencygroup_id | None | | created_at | 2021-04-27T13:52:10.000000 | | description | None | | encrypted | True | | id | 33211b21-8d4f-48e9-b76f-ec73ffd19def | | multiattach | False | | name | enc_drive | | properties | | | replication_status | None | | size | 10 | | snapshot_id | None | | source_volid | None | | status | creating | | type | volumes_hdd_encrypted | | updated_at | None | | user_id | 966ad341f4e14920b5f589f900246ccc | +---------------------+--------------------------------------+ Upon volume creation, this will create a one-off encryption key, which is stored in Barbican and applies to this one volume only. In other words, the key created for this volume will be unable to decrypt any other volumes except the one it was created for.","title":"Creating an encrypted volume"},{"location":"howto/openstack/cinder/encrypted-volumes/#retrieving-a-volumes-encryption-key","text":"Once you have created an encrypted volume, you may retrieve a reference to the Barbican secret that represents its encryption key. You do this with the following command: openstack volume show \\ --os-volume-api-version 3 .66 \\ -f value \\ -c encryption_key_id \\ enc_drive Instead of the volume name, you can of course also specify its UUID: openstack volume show \\ --os-volume-api-version 3 .66 \\ -f value \\ -c encryption_key_id \\ 33211b21-8d4f-48e9-b76f-ec73ffd19def","title":"Retrieving a volume\u2019s encryption key"},{"location":"howto/openstack/cinder/encrypted-volumes/#deleting-an-encrypted-volume","text":"When you decide you no longer need an encrypted volume and want to delete it, you can do so with the openstack volume delete command. As long as you do this with the same user account as the one that created the volume, this will succeed without further intervention. However, if you are trying to delete a volume that was created by a different user, you\u2019ll run into the limitation that the secret associated with the volume is owned by that user. As a result, the deletion of the encrypted volume using your own user credentials will fail. There are two options to work around this limitation: You can switch to the user credentials of the user that created the volume (if you have access to them), and proceed with the deletion. You can ask the user that created the volume to add you to the Access Control List (ACL) for the secret . This will enable you to read the secret, and to delete the volume using your own credentials.","title":"Deleting an encrypted volume"},{"location":"howto/openstack/cinder/encrypted-volumes/#block-device-encryption-caveats","text":"Once a volume is configured to use encryption and is also attached to an instance in Cleura Cloud, some caveats apply that you might want to keep in mind. Sometimes, automatically or through administrator intervention, we move one of your instances to another physical machine. This process is known as live migration, and it normally does not interrupt the instance\u2019s functionality at all \u2014 typically, neither you nor the application users notice that live migration has even happened. This is a very common occurrence when we do routine upgrades of the Cleura Cloud platform, during our pre-announced maintenance windows. The same considerations apply to physical node failure. If the physical machine running your instance fails, we can automatically recover it onto another machine \u2014 an action known as evacuation. Live migration or evacuation including encrypted volumes does, however, require that whoever does the migration also has at least read access to the volume\u2019s encryption secret. This means that you have two options: If you do trust us to include your instances in live migrations and evacuations, even if they attach encrypted volumes, then you can add our administrative account to the Access Control List (ACL) for your secrets . If you don\u2019t want to share your secrets but you still want to use encrypted volumes, you should build your own mechanism or process (preferably automated) so that your instances recover in case they become non-functional.","title":"Block device encryption caveats"},{"location":"howto/openstack/magnum/new-k8s-cluster/","text":"Creating new Kubernetes clusters By employing OpenStack Magnum you can easily create Kubernetes clusters over OpenStack, using either the Cleura Cloud Management Panel or the OpenStack CLI. Let us demonstrate the creation of a Kubernetes cluster following both approaches. Prerequisites First and foremost, you need an account in Cleura Cloud . If you prefer to work with the OpenStack CLI, go ahead and enable it first . Then, in addition to the Python openstackclient module, make sure you also install the corresponding plugin module for Magnum. Use either the package manager of your operating system or pip : Debian/Ubuntu Mac OS X with Homebrew Python Package apt install python3-magnumclient This Python module is unavailable via brew , but you can install it via pip . pip install python-magnumclient Creating a Kubernetes cluster To create a Kubernetes cluster from the Cleura Cloud Management Panel, fire up your favorite web browser, navigate to the Cleura Cloud Management Panel start page, and log into your Cleura Cloud account. On the other hand, if you prefer to work with the OpenStack CLI, please do not forget to source the RC file first . Cleura Cloud Management Panel OpenStack CLI On the top right-hand side of the Cleura Cloud Management Panel, click the Create button. A new pane titled Create will slide into view from the right-hand side of the browser window. You will notice several rounded boxes on that pane. Go ahead and click the one labeled Magnum Cluster . A new pane titled Create a Magnum Cluster will slide over. At the top, type in a name for the new Kubernetes cluster and select one of the available regions. Then, select one of the available templates to base the new cluster on. In the example below, we have selected the template named Kubernetes 1.18.6 on Fedora-coreos 33 2C-4GB-20GB No Master LB . The naming of any template indicates the version of Kubernetes that is about to be deployed, the characteristics of the cluster nodes, the operating system they run, and the presence or not of a load balancer for the control plane. Optionally, select one of the available keypairs for secure SSH access to the individual cluster nodes. For now, you may skip the Advanced Option section. Click the green Create button, and Magnum will start creating the new Kubernetes cluster. Please note that the whole process may take several minutes to complete. A simple, general command for creating a new Kubernetes cluster with Magnum looks like this: openstack coe cluster create \\ --cluster-template $CLUSTER_TMPL \\ --keypair $KEYPAIR \\ $CLUSTER_NAME Let us list all available templates in the region: openstack coe cluster template list +--------------------------------------+----------------------------------------------------------------+------+ | uuid | name | tags | +--------------------------------------+----------------------------------------------------------------+------+ | 3f476f01-b3de-4687-a188-6829ed947db0 | Kubernetes 1.15.5 on Fedora-atomic 29 4C-8GB-20GB No Master LB | None | | c458f02d-54b0-4ef8-abbc-e1c25b61165a | Kubernetes 1.15.5 on Fedora-atomic 29 2C-4GB-20GB No Master LB | None | | f9e1a2ea-b1ff-43e7-8d1e-6dd5861b82cf | Kubernetes 1.18.6 on Fedora-coreos 33 2C-4GB-20GB No Master LB | None | +--------------------------------------+----------------------------------------------------------------+------+ Select the template you want by setting the corresponding uuid value to the CLUSTER_TMPL variable: CLUSTER_TMPL = \"f9e1a2ea-b1ff-43e7-8d1e-6dd5861b82cf\" # just an example Then, list all available keypairs\u2026 openstack keypair list +---------+-------------------------------------------------+------+ | Name | Fingerprint | Type | +---------+-------------------------------------------------+------+ | husavik | 34:3b:58:ba:ec:95:f5:17:17:df:04:38:11:89:e6:3d | ssh | +---------+-------------------------------------------------+------+ \u2026and set the KEYPAIR variable to the name of the keypair you want: KEYPAIR = \"husavik\" # again, this is just an example Finally, decide on a name for your new Kubernetes cluster: CLUSTER_NAME = \"bangor\" With everything in place, go ahead and create your new Kubernetes cluster: openstack coe cluster create \\ --cluster-template $CLUSTER_TMPL \\ --keypair husavik bangor If everything went well with your request for a new cluster, on your terminal, you would see a message like the following: Request to create cluster e0df8c62-c6f6-4c7d-b67e-33e3606e9ab6 accepted The cluster creation process takes some time to complete, and while you are waiting, you can check if everything is progressing smoothly: openstack coe cluster list -c status If everything is going well, the message you will get will be CREATE_IN_PROGRESS . When Magnum has finished creating the cluster, the message will be CREATE_COMPLETE . Viewing the Kubernetes cluster After the Kubernetes cluster is ready, you may at any time view it and get detailed information about it. Cleura Cloud Management Panel OpenStack CLI In the left vertical pane of the Cleura Cloud Management Panel, click through Kubernetes , Magnum , and Clusters . In the central pane on the right, you will then see all your Kubernetes clusters in every region. Click on the three-dot icon on the right of the cluster you want to inspect, and select View details . To list all available Kubernetes clusters, just type: openstack coe cluster list +---------------+--------+---------+------------+--------------+---------------+---------------+ | uuid | name | keypair | node_count | master_count | status | health_status | +---------------+--------+---------+------------+--------------+---------------+---------------+ | e0df8c62-c6f6 | bangor | husavik | 1 | 1 | CREATE_COMPLE | HEALTHY | | -4c7d-b67e-33 | | | | | TE | | | e3606e9ab6 | | | | | | | +---------------+--------+---------+------------+--------------+---------------+---------------+ For many more details on a specific cluster, note its name and run a command like this: openstack coe cluster show bangor +----------------------+---------------------------------------------------------------------------+ | Field | Value | +----------------------+---------------------------------------------------------------------------+ | status | CREATE_COMPLETE | | health_status | HEALTHY | | cluster_template_id | f9e1a2ea-b1ff-43e7-8d1e-6dd5861b82cf | | node_addresses | ['185.52.156.105'] | | uuid | e0df8c62-c6f6-4c7d-b67e-33e3606e9ab6 | | stack_id | e3725aed-f665-4e8d-9409-85f5ee5e2f4a | | status_reason | None | | created_at | 2022-11-14T07:32:02+00:00 | | updated_at | 2022-11-14T07:37:26+00:00 | | coe_version | v1.18.6 | | labels | {'kube_tag': 'v1.18.6', 'heat_container_agent_tag': 'train-stable'} | | labels_overridden | {} | | labels_skipped | {} | | labels_added | {} | | fixed_network | None | | fixed_subnet | None | | floating_ip_enabled | True | | faults | | | keypair | husavik | | api_address | https://89.46.80.136:6443 | | master_addresses | ['89.46.80.136'] | | master_lb_enabled | False | | create_timeout | 60 | | node_count | 1 | | discovery_url | https://discovery.etcd.io/23af721dc3ee773d2674db4881ff70cb | | docker_volume_size | 50 | | master_count | 1 | | container_version | 1.12.6 | | name | bangor | | master_flavor_id | 2C-4GB-20GB | | flavor_id | 2C-4GB-20GB | | health_status_reason | {'bangor-id6nijycp2wy-master-0.Ready': 'True', 'bangor-id6nijycp2wy- | | | node-0.Ready': 'True', 'api': 'ok'} | | project_id | dfc700467396428bacba4376e72cc3e9 | +----------------------+---------------------------------------------------------------------------+ Accessing the Kubernetes cluster with kubectl You may install the Kubernetes command line tool, kubectl , on your local computer, and run commands against your cluster. To install kubectl , use the package manager of your operating system. Debian/Ubuntu Mac OS X with Homebrew apt install kubectl brew install kubectl Before running commands against a specific cluster, you must have the corresponding config file on your computer. Cleura Cloud Management Panel OpenStack CLI Downloading a config file from the Cleura Cloud Management Panel is currently not supported. You can still fetch the config file of your newly created Kubernetes cluster using the OpenStack CLI. To download the config file for your Kubernetes cluster, type the following: openstack coe cluster config --dir = ${ PWD } bangor After saving the config file locally, set the value of variable KUBECONFIG to the full path of the file. Type, for example: export KUBECONFIG = ${ PWD } /config Then, you can use kubectl to run commands against your cluster. See, for instance, all cluster nodes\u2026 kubectl get nodes NAME STATUS ROLES AGE VERSION bangor-id6nijycp2wy-master-0 Ready master 113m v1.18.6 bangor-id6nijycp2wy-node-0 Ready <none> 111m v1.18.6 \u2026or all running pods in every namespace: kubectl get pods --all-namespaces NAMESPACE NAME READY STATUS RESTARTS AGE kube-system coredns-786ffb7797-tw2hg 1/1 Running 0 167m kube-system coredns-786ffb7797-vbqwn 1/1 Running 0 167m kube-system csi-cinder-controllerplugin-0 5/5 Running 0 167m kube-system csi-cinder-nodeplugin-4nr69 2/2 Running 0 166m kube-system csi-cinder-nodeplugin-vtwqf 2/2 Running 0 167m kube-system dashboard-metrics-scraper-6b4884c9d5-4mlrg 1/1 Running 0 167m kube-system k8s-keystone-auth-wk5v2 1/1 Running 0 167m kube-system kube-dns-autoscaler-75859754fd-2wsd9 1/1 Running 0 167m kube-system kube-flannel-ds-7z9dp 1/1 Running 0 167m kube-system kube-flannel-ds-dmvk6 1/1 Running 0 166m kube-system kubernetes-dashboard-c98496485-stn42 1/1 Running 0 167m kube-system magnum-metrics-server-79556d6999-xdlpm 1/1 Running 0 167m kube-system npd-5p6gk 1/1 Running 0 165m kube-system openstack-cloud-controller-manager-44rz9 1/1 Running 0 167m","title":"Creating new Kubernetes clusters"},{"location":"howto/openstack/magnum/new-k8s-cluster/#creating-new-kubernetes-clusters","text":"By employing OpenStack Magnum you can easily create Kubernetes clusters over OpenStack, using either the Cleura Cloud Management Panel or the OpenStack CLI. Let us demonstrate the creation of a Kubernetes cluster following both approaches.","title":"Creating new Kubernetes clusters"},{"location":"howto/openstack/magnum/new-k8s-cluster/#prerequisites","text":"First and foremost, you need an account in Cleura Cloud . If you prefer to work with the OpenStack CLI, go ahead and enable it first . Then, in addition to the Python openstackclient module, make sure you also install the corresponding plugin module for Magnum. Use either the package manager of your operating system or pip : Debian/Ubuntu Mac OS X with Homebrew Python Package apt install python3-magnumclient This Python module is unavailable via brew , but you can install it via pip . pip install python-magnumclient","title":"Prerequisites"},{"location":"howto/openstack/magnum/new-k8s-cluster/#creating-a-kubernetes-cluster","text":"To create a Kubernetes cluster from the Cleura Cloud Management Panel, fire up your favorite web browser, navigate to the Cleura Cloud Management Panel start page, and log into your Cleura Cloud account. On the other hand, if you prefer to work with the OpenStack CLI, please do not forget to source the RC file first . Cleura Cloud Management Panel OpenStack CLI On the top right-hand side of the Cleura Cloud Management Panel, click the Create button. A new pane titled Create will slide into view from the right-hand side of the browser window. You will notice several rounded boxes on that pane. Go ahead and click the one labeled Magnum Cluster . A new pane titled Create a Magnum Cluster will slide over. At the top, type in a name for the new Kubernetes cluster and select one of the available regions. Then, select one of the available templates to base the new cluster on. In the example below, we have selected the template named Kubernetes 1.18.6 on Fedora-coreos 33 2C-4GB-20GB No Master LB . The naming of any template indicates the version of Kubernetes that is about to be deployed, the characteristics of the cluster nodes, the operating system they run, and the presence or not of a load balancer for the control plane. Optionally, select one of the available keypairs for secure SSH access to the individual cluster nodes. For now, you may skip the Advanced Option section. Click the green Create button, and Magnum will start creating the new Kubernetes cluster. Please note that the whole process may take several minutes to complete. A simple, general command for creating a new Kubernetes cluster with Magnum looks like this: openstack coe cluster create \\ --cluster-template $CLUSTER_TMPL \\ --keypair $KEYPAIR \\ $CLUSTER_NAME Let us list all available templates in the region: openstack coe cluster template list +--------------------------------------+----------------------------------------------------------------+------+ | uuid | name | tags | +--------------------------------------+----------------------------------------------------------------+------+ | 3f476f01-b3de-4687-a188-6829ed947db0 | Kubernetes 1.15.5 on Fedora-atomic 29 4C-8GB-20GB No Master LB | None | | c458f02d-54b0-4ef8-abbc-e1c25b61165a | Kubernetes 1.15.5 on Fedora-atomic 29 2C-4GB-20GB No Master LB | None | | f9e1a2ea-b1ff-43e7-8d1e-6dd5861b82cf | Kubernetes 1.18.6 on Fedora-coreos 33 2C-4GB-20GB No Master LB | None | +--------------------------------------+----------------------------------------------------------------+------+ Select the template you want by setting the corresponding uuid value to the CLUSTER_TMPL variable: CLUSTER_TMPL = \"f9e1a2ea-b1ff-43e7-8d1e-6dd5861b82cf\" # just an example Then, list all available keypairs\u2026 openstack keypair list +---------+-------------------------------------------------+------+ | Name | Fingerprint | Type | +---------+-------------------------------------------------+------+ | husavik | 34:3b:58:ba:ec:95:f5:17:17:df:04:38:11:89:e6:3d | ssh | +---------+-------------------------------------------------+------+ \u2026and set the KEYPAIR variable to the name of the keypair you want: KEYPAIR = \"husavik\" # again, this is just an example Finally, decide on a name for your new Kubernetes cluster: CLUSTER_NAME = \"bangor\" With everything in place, go ahead and create your new Kubernetes cluster: openstack coe cluster create \\ --cluster-template $CLUSTER_TMPL \\ --keypair husavik bangor If everything went well with your request for a new cluster, on your terminal, you would see a message like the following: Request to create cluster e0df8c62-c6f6-4c7d-b67e-33e3606e9ab6 accepted The cluster creation process takes some time to complete, and while you are waiting, you can check if everything is progressing smoothly: openstack coe cluster list -c status If everything is going well, the message you will get will be CREATE_IN_PROGRESS . When Magnum has finished creating the cluster, the message will be CREATE_COMPLETE .","title":"Creating a Kubernetes cluster"},{"location":"howto/openstack/magnum/new-k8s-cluster/#viewing-the-kubernetes-cluster","text":"After the Kubernetes cluster is ready, you may at any time view it and get detailed information about it. Cleura Cloud Management Panel OpenStack CLI In the left vertical pane of the Cleura Cloud Management Panel, click through Kubernetes , Magnum , and Clusters . In the central pane on the right, you will then see all your Kubernetes clusters in every region. Click on the three-dot icon on the right of the cluster you want to inspect, and select View details . To list all available Kubernetes clusters, just type: openstack coe cluster list +---------------+--------+---------+------------+--------------+---------------+---------------+ | uuid | name | keypair | node_count | master_count | status | health_status | +---------------+--------+---------+------------+--------------+---------------+---------------+ | e0df8c62-c6f6 | bangor | husavik | 1 | 1 | CREATE_COMPLE | HEALTHY | | -4c7d-b67e-33 | | | | | TE | | | e3606e9ab6 | | | | | | | +---------------+--------+---------+------------+--------------+---------------+---------------+ For many more details on a specific cluster, note its name and run a command like this: openstack coe cluster show bangor +----------------------+---------------------------------------------------------------------------+ | Field | Value | +----------------------+---------------------------------------------------------------------------+ | status | CREATE_COMPLETE | | health_status | HEALTHY | | cluster_template_id | f9e1a2ea-b1ff-43e7-8d1e-6dd5861b82cf | | node_addresses | ['185.52.156.105'] | | uuid | e0df8c62-c6f6-4c7d-b67e-33e3606e9ab6 | | stack_id | e3725aed-f665-4e8d-9409-85f5ee5e2f4a | | status_reason | None | | created_at | 2022-11-14T07:32:02+00:00 | | updated_at | 2022-11-14T07:37:26+00:00 | | coe_version | v1.18.6 | | labels | {'kube_tag': 'v1.18.6', 'heat_container_agent_tag': 'train-stable'} | | labels_overridden | {} | | labels_skipped | {} | | labels_added | {} | | fixed_network | None | | fixed_subnet | None | | floating_ip_enabled | True | | faults | | | keypair | husavik | | api_address | https://89.46.80.136:6443 | | master_addresses | ['89.46.80.136'] | | master_lb_enabled | False | | create_timeout | 60 | | node_count | 1 | | discovery_url | https://discovery.etcd.io/23af721dc3ee773d2674db4881ff70cb | | docker_volume_size | 50 | | master_count | 1 | | container_version | 1.12.6 | | name | bangor | | master_flavor_id | 2C-4GB-20GB | | flavor_id | 2C-4GB-20GB | | health_status_reason | {'bangor-id6nijycp2wy-master-0.Ready': 'True', 'bangor-id6nijycp2wy- | | | node-0.Ready': 'True', 'api': 'ok'} | | project_id | dfc700467396428bacba4376e72cc3e9 | +----------------------+---------------------------------------------------------------------------+","title":"Viewing the Kubernetes cluster"},{"location":"howto/openstack/magnum/new-k8s-cluster/#accessing-the-kubernetes-cluster-with-kubectl","text":"You may install the Kubernetes command line tool, kubectl , on your local computer, and run commands against your cluster. To install kubectl , use the package manager of your operating system. Debian/Ubuntu Mac OS X with Homebrew apt install kubectl brew install kubectl Before running commands against a specific cluster, you must have the corresponding config file on your computer. Cleura Cloud Management Panel OpenStack CLI Downloading a config file from the Cleura Cloud Management Panel is currently not supported. You can still fetch the config file of your newly created Kubernetes cluster using the OpenStack CLI. To download the config file for your Kubernetes cluster, type the following: openstack coe cluster config --dir = ${ PWD } bangor After saving the config file locally, set the value of variable KUBECONFIG to the full path of the file. Type, for example: export KUBECONFIG = ${ PWD } /config Then, you can use kubectl to run commands against your cluster. See, for instance, all cluster nodes\u2026 kubectl get nodes NAME STATUS ROLES AGE VERSION bangor-id6nijycp2wy-master-0 Ready master 113m v1.18.6 bangor-id6nijycp2wy-node-0 Ready <none> 111m v1.18.6 \u2026or all running pods in every namespace: kubectl get pods --all-namespaces NAMESPACE NAME READY STATUS RESTARTS AGE kube-system coredns-786ffb7797-tw2hg 1/1 Running 0 167m kube-system coredns-786ffb7797-vbqwn 1/1 Running 0 167m kube-system csi-cinder-controllerplugin-0 5/5 Running 0 167m kube-system csi-cinder-nodeplugin-4nr69 2/2 Running 0 166m kube-system csi-cinder-nodeplugin-vtwqf 2/2 Running 0 167m kube-system dashboard-metrics-scraper-6b4884c9d5-4mlrg 1/1 Running 0 167m kube-system k8s-keystone-auth-wk5v2 1/1 Running 0 167m kube-system kube-dns-autoscaler-75859754fd-2wsd9 1/1 Running 0 167m kube-system kube-flannel-ds-7z9dp 1/1 Running 0 167m kube-system kube-flannel-ds-dmvk6 1/1 Running 0 166m kube-system kubernetes-dashboard-c98496485-stn42 1/1 Running 0 167m kube-system magnum-metrics-server-79556d6999-xdlpm 1/1 Running 0 167m kube-system npd-5p6gk 1/1 Running 0 165m kube-system openstack-cloud-controller-manager-44rz9 1/1 Running 0 167m","title":"Accessing the Kubernetes cluster with kubectl"},{"location":"howto/openstack/neutron/create-security-groups/","text":"Creating security groups By definition , security groups are \u201d[\u2026] sets of IP filter rules that are applied to all project instances, which define networking access to the instance. Group rules are project specific; project members can edit the default rules for their group and add new rule sets.\u201d Creating a security group Navigate to the Cleura Cloud Management Panel page, and log into your Cleura Cloud account. On the other hand, if you prefer to work with the OpenStack CLI, please do not forget to source the RC file first . Cleura Cloud Management Panel OpenStack CLI To create a security group click on Security Groups in the left-hand side navigation menu: and then click on Create new Security Group in the top-right corner: An alternative way to create a Security Group is by clicking on Create \u2026 button in the top bar. Now give the security group a name and description, and choose in which region to create it, then click create : To create a security group use the following command: openstack security group create <name> When the command is executed successfully, you will get information regarding your new security group: +-----------------+--------------------------------------------------------------------------------+ | Field | Value | +-----------------+--------------------------------------------------------------------------------+ | created_at | 2022-11-14T09:15:14Z | | description | <name> | | id | 736da1d1-aa98-4da4-9ba4-2ab9aeea6a57 | | name | <name> | | project_id | cb43f189f7904fb88f3bbcfa22653ab8 | | revision_number | 1 | | rules | created_at='2022-11-14T09:15:14Z', direction='egress', ethertype='IPv4', | | | id='1f4c57cb-8e34-420c-a7e3-3b5625c79481', standard_attr_id='10579829', | | | updated_at='2022-11-14T09:15:14Z' | | | created_at='2022-11-14T09:15:14Z', direction='egress', ethertype='IPv6', | | | id='7c2c287e-9596-42ef-a5a8-0b09e38b206a', standard_attr_id='10579832', | | | updated_at='2022-11-14T09:15:14Z' | | stateful | True | | tags | [] | | updated_at | 2022-11-14T09:15:14Z | +-----------------+--------------------------------------------------------------------------------+ Removing default ingress rules By default, a security group named default has been already created for you, blocking all traffic from any source (ingress), except from servers and ports being in the same security group. All traffic to any destination (egress) is allowed by default. For accounts created before 2022-11-16, the default security group ingress rules allow all incoming traffic. See Adjust permissive default security group , to learn how to configure this security group according to our recommendations. Cleura Cloud Management Panel OpenStack CLI Navigate to the security groups page, click on default security group and select the Rules tab to view its rules: View the details of the default security group using the following command: openstack security group show default you will get a printout similar to this: +-----------------+--------------------------------------------------------------------------------+ | Field | Value | +-----------------+--------------------------------------------------------------------------------+ | created_at | 2022-09-12T15:00:57Z | | description | Default security group | | id | 935b1317-a0c0-42e9-b68d-7cf16637df14 | | name | default | | project_id | cb43f189f7904fb88f3bbcfa22653ab8 | | revision_number | 5 | | rules | created_at='2022-09-12T15:00:59Z', direction='ingress', ethertype='IPv4', | | | id='5e5e9f4d-1faa-492d-91f1-c105b464072b', protocol='0', | | | remote_group_id='60776d43-a78c-4eb4-8998-cea7a04c5f9b', | | | standard_attr_id='10422245', updated_at='2022-09-12T15:00:59Z' | | | created_at='2022-09-12T15:00:59Z', direction='ingress', ethertype='IPv6', | | | id='86b9413a-ad23-46c4-a35e-9306945dc63c', protocol='0', | | | remote_group_id='60776d43-a78c-4eb4-8998-cea7a04c5f9b', | | | standard_attr_id='10422248', updated_at='2022-09-12T15:00:59Z' | | | created_at='2022-09-12T15:00:57Z', direction='egress', ethertype='IPv6', | | | id='ad4a19ef-7fab-4eba-9982-e5b109be121c', standard_attr_id='10422242', | | | updated_at='2022-09-12T15:00:57Z' | | | created_at='2022-09-12T15:00:57Z', direction='egress', ethertype='IPv4', | | | id='f53b1a12-edbb-480b-910b-a71c4836346f', standard_attr_id='10422236', | | | updated_at='2022-09-12T15:00:57Z' | | stateful | True | | tags | [] | | updated_at | 2022-09-12T15:00:59Z | +-----------------+--------------------------------------------------------------------------------+ If you want to restrict the ingress rules to disallow access from other servers and ports in the group, you need to remove the default two ingress rules. Cleura Cloud Management Panel OpenStack CLI Click on the trashcan action button on the right-hand side for both ingress rules. Your default or newly created security group rules will now look like this: To view the rules use the following command: openstack security group rule list default The printout will be similar to this: +-----------+-------------+-----------+-----------+------------+-----------+-----------------------+----------------------+ | ID | IP Protocol | Ethertype | IP Range | Port Range | Direction | Remote Security Group | Remote Address Group | +-----------+-------------+-----------+-----------+------------+-----------+-----------------------+----------------------+ | 5e5e9f4d- | None | IPv4 | 0.0.0.0/0 | | ingress | 60776d43-a78c-4eb4- | None | | 1faa- | | | | | | 8998-cea7a04c5f9b | | | 492d- | | | | | | | | | 91f1- | | | | | | | | | c105b4640 | | | | | | | | | 72b | | | | | | | | | 86b9413a- | None | IPv6 | ::/0 | | ingress | 60776d43-a78c-4eb4- | None | | ad23- | | | | | | 8998-cea7a04c5f9b | | | 46c4- | | | | | | | | | a35e- | | | | | | | | | 9306945dc | | | | | | | | | 63c | | | | | | | | | ad4a19ef- | None | IPv6 | ::/0 | | egress | None | None | | 7fab- | | | | | | | | | 4eba- | | | | | | | | | 9982- | | | | | | | | | e5b109be1 | | | | | | | | | 21c | | | | | | | | | f53b1a12- | None | IPv4 | 0.0.0.0/0 | | egress | None | None | | edbb- | | | | | | | | | 480b- | | | | | | | | | 910b- | | | | | | | | | a71c48363 | | | | | | | | | 46f | | | | | | | | +-----------+-------------+-----------+-----------+------------+-----------+-----------------------+----------------------+ The IDs of the two ingress rules, one for IPv4 traffic and one for IPv6, in this case are: 5e5e9f4d-1faa-492d-91f1-c105b464072b and 86b9413a-ad23-46c4-a35e-9306945dc63c Delete them by using the following command: openstack security group rule delete \\ 5e5e9f4d-1faa-492d-91f1-c105b464072b 86b9413a-ad23-46c4-a35e-9306945dc63c Print the rules again: openstack security group rule list default Now the remaining rules are only the egress ones. +-----------+-------------+-----------+-----------+------------+-----------+-----------------------+----------------------+ | ID | IP Protocol | Ethertype | IP Range | Port Range | Direction | Remote Security Group | Remote Address Group | +-----------+-------------+-----------+-----------+------------+-----------+-----------------------+----------------------+ | ad4a19ef- | None | IPv6 | ::/0 | | egress | None | None | | 7fab- | | | | | | | | | 4eba- | | | | | | | | | 9982- | | | | | | | | | e5b109be1 | | | | | | | | | 21c | | | | | | | | | f53b1a12- | None | IPv4 | 0.0.0.0/0 | | egress | None | None | | edbb- | | | | | | | | | 480b- | | | | | | | | | 910b- | | | | | | | | | a71c48363 | | | | | | | | | 46f | | | | | | | | +-----------+-------------+-----------+-----------+------------+-----------+-----------------------+----------------------+ Allowing SSH access The next thing to do, is to allow SSH access on port 22 to the server, only from specific networks. Cleura Cloud Management Panel OpenStack CLI To do this, click on the Create new rule button. To create this rule use the following command: openstack security group rule create \\ --protocol tcp --dst-port 22 --remote-ip 203 .0.113.58/32 default If you don\u2019t know your IP, simply visit icanhazip.com . In this example your IP is 203.0.113.58, and if you want to allow SSH access from this IP address only, enter 203.0.113.58/32 as CIDR. If you want to allow SSH access from any address in that Class C subnet , instead enter 203.0.113.0/24 as CIDR. Allowing Web Traffic Next create the rules that allow anyone to access the server on port 80 and port 443 . Cleura Cloud Management Panel OpenStack CLI Using the same logic as before, click on Create new rule . Select TCP Protocol and port 80 as both min and max range value. This time, CIDR is left empty, allowing incoming traffic from any IP/source. The same applies to port 443. This time don\u2019t specify \u2013remote-ip to allow traffic from all sources, using the following command: openstack security group rule create --protocol tcp --dst-port 80 default One more time for port 443: openstack security group rule create --protocol tcp --dst-port 443 default To view the updated rules, print the them again: openstack security group rule list default +-----------+-------------+-----------+-----------+------------+-----------+-----------------------+----------------------+ | ID | IP Protocol | Ethertype | IP Range | Port Range | Direction | Remote Security Group | Remote Address Group | +-----------+-------------+-----------+-----------+------------+-----------+-----------------------+----------------------+ | 742bcc46- | tcp | IPv4 | 0.0.0.0/0 | 80:80 | ingress | None | None | | beb5- | | | | | | | | | 47a5- | | | | | | | | | 8eb1- | | | | | | | | | eb35da800 | | | | | | | | | 6ed | | | | | | | | | ad4a19ef- | None | IPv6 | ::/0 | | egress | None | None | | 7fab- | | | | | | | | | 4eba- | | | | | | | | | 9982- | | | | | | | | | e5b109be1 | | | | | | | | | 21c | | | | | | | | | cef0cd36- | tcp | IPv4 | 203.0.113 | 22:22 | ingress | None | None | | ad78- | | | .58/32 | | | | | | 4dbd- | | | | | | | | | b806- | | | | | | | | | 597300fd9 | | | | | | | | | e6a | | | | | | | | | f53b1a12- | None | IPv4 | 0.0.0.0/0 | | egress | None | None | | edbb- | | | | | | | | | 480b- | | | | | | | | | 910b- | | | | | | | | | a71c48363 | | | | | | | | | 46f | | | | | | | | | f90c598c- | tcp | IPv4 | 0.0.0.0/0 | 443:443 | ingress | None | None | | 3a5e- | | | | | | | | | 459f- | | | | | | | | | 8ed3- | | | | | | | | | 3c2538e7a | | | | | | | | | 24f | | | | | | | | +-----------+-------------+-----------+-----------+------------+-----------+-----------------------+----------------------+ All the rules for a simple web server are now in place. For any additional protocol or ingress rule, simply follow the same procedure as above. Adjust permissive default security group If your account was created before 2022-11-16, and you didn\u2019t configure the default security group, it is most likely permissive for all incoming traffic. We recommend to either create and use a new security group, other than the default one, or restrict ingress traffic to specific ports and sources. Cleura Cloud Management Panel OpenStack CLI To check how your default security group is configured, click on it and select the Rules tab to view its rules. If you have old, permissive default group, the rules should look like this: The top two ingress rules, having ::/0 and 0.0.0.0/0 values for remote access filters, mean that incoming traffic from all sources is allowed. If you want to use the default group, remove the two ingress rules that allow all incoming traffic. Click on the trashcan action button on the right-hand side for both ingress rules. Your default or newly created security group rules will now look like this: To view the rules use the following command: openstack security group rule list default The printout will be similar to this: +-----------+-------------+-----------+-----------+------------+-----------+-----------------------+----------------------+ | ID | IP Protocol | Ethertype | IP Range | Port Range | Direction | Remote Security Group | Remote Address Group | +-----------+-------------+-----------+-----------+------------+-----------+-----------------------+----------------------+ | 5e5e9f4d- | None | IPv4 | 0.0.0.0/0 | | ingress | None | None | | 1faa- | | | | | | | | | 492d- | | | | | | | | | 91f1- | | | | | | | | | c105b4640 | | | | | | | | | 72b | | | | | | | | | 86b9413a- | None | IPv6 | ::/0 | | ingress | None | None | | ad23- | | | | | | | | | 46c4- | | | | | | | | | a35e- | | | | | | | | | 9306945dc | | | | | | | | | 63c | | | | | | | | | ad4a19ef- | None | IPv6 | ::/0 | | egress | None | None | | 7fab- | | | | | | | | | 4eba- | | | | | | | | | 9982- | | | | | | | | | e5b109be1 | | | | | | | | | 21c | | | | | | | | | f53b1a12- | None | IPv4 | 0.0.0.0/0 | | egress | None | None | | edbb- | | | | | | | | | 480b- | | | | | | | | | 910b- | | | | | | | | | a71c48363 | | | | | | | | | 46f | | | | | | | | +-----------+-------------+-----------+-----------+------------+-----------+-----------------------+----------------------+ If the ingress rules have ::/0 and 0.0.0.0/0 values in IP Range column, and None in the Remote Security Group , then incoming traffic from any source is allowed. The IDs of the two ingress rules, one for IPv4 traffic and one for IPv6, are: 5e5e9f4d-1faa-492d-91f1-c105b464072b and 86b9413a-ad23-46c4-a35e-9306945dc63c respectively. Delete them by using the following command: openstack security group rule delete \\ 5e5e9f4d-1faa-492d-91f1-c105b464072b 86b9413a-ad23-46c4-a35e-9306945dc63c Print the rules again: openstack security group rule list default Now the remaining rules are only the egress ones. +-----------+-------------+-----------+-----------+------------+-----------+-----------------------+----------------------+ | ID | IP Protocol | Ethertype | IP Range | Port Range | Direction | Remote Security Group | Remote Address Group | +-----------+-------------+-----------+-----------+------------+-----------+-----------------------+----------------------+ | ad4a19ef- | None | IPv6 | ::/0 | | egress | None | None | | 7fab- | | | | | | | | | 4eba- | | | | | | | | | 9982- | | | | | | | | | e5b109be1 | | | | | | | | | 21c | | | | | | | | | f53b1a12- | None | IPv4 | 0.0.0.0/0 | | egress | None | None | | edbb- | | | | | | | | | 480b- | | | | | | | | | 910b- | | | | | | | | | a71c48363 | | | | | | | | | 46f | | | | | | | | +-----------+-------------+-----------+-----------+------------+-----------+-----------------------+----------------------+","title":"Creating security groups"},{"location":"howto/openstack/neutron/create-security-groups/#creating-security-groups","text":"By definition , security groups are \u201d[\u2026] sets of IP filter rules that are applied to all project instances, which define networking access to the instance. Group rules are project specific; project members can edit the default rules for their group and add new rule sets.\u201d","title":"Creating security groups"},{"location":"howto/openstack/neutron/create-security-groups/#creating-a-security-group","text":"Navigate to the Cleura Cloud Management Panel page, and log into your Cleura Cloud account. On the other hand, if you prefer to work with the OpenStack CLI, please do not forget to source the RC file first . Cleura Cloud Management Panel OpenStack CLI To create a security group click on Security Groups in the left-hand side navigation menu: and then click on Create new Security Group in the top-right corner: An alternative way to create a Security Group is by clicking on Create \u2026 button in the top bar. Now give the security group a name and description, and choose in which region to create it, then click create : To create a security group use the following command: openstack security group create <name> When the command is executed successfully, you will get information regarding your new security group: +-----------------+--------------------------------------------------------------------------------+ | Field | Value | +-----------------+--------------------------------------------------------------------------------+ | created_at | 2022-11-14T09:15:14Z | | description | <name> | | id | 736da1d1-aa98-4da4-9ba4-2ab9aeea6a57 | | name | <name> | | project_id | cb43f189f7904fb88f3bbcfa22653ab8 | | revision_number | 1 | | rules | created_at='2022-11-14T09:15:14Z', direction='egress', ethertype='IPv4', | | | id='1f4c57cb-8e34-420c-a7e3-3b5625c79481', standard_attr_id='10579829', | | | updated_at='2022-11-14T09:15:14Z' | | | created_at='2022-11-14T09:15:14Z', direction='egress', ethertype='IPv6', | | | id='7c2c287e-9596-42ef-a5a8-0b09e38b206a', standard_attr_id='10579832', | | | updated_at='2022-11-14T09:15:14Z' | | stateful | True | | tags | [] | | updated_at | 2022-11-14T09:15:14Z | +-----------------+--------------------------------------------------------------------------------+","title":"Creating a security group"},{"location":"howto/openstack/neutron/create-security-groups/#removing-default-ingress-rules","text":"By default, a security group named default has been already created for you, blocking all traffic from any source (ingress), except from servers and ports being in the same security group. All traffic to any destination (egress) is allowed by default. For accounts created before 2022-11-16, the default security group ingress rules allow all incoming traffic. See Adjust permissive default security group , to learn how to configure this security group according to our recommendations. Cleura Cloud Management Panel OpenStack CLI Navigate to the security groups page, click on default security group and select the Rules tab to view its rules: View the details of the default security group using the following command: openstack security group show default you will get a printout similar to this: +-----------------+--------------------------------------------------------------------------------+ | Field | Value | +-----------------+--------------------------------------------------------------------------------+ | created_at | 2022-09-12T15:00:57Z | | description | Default security group | | id | 935b1317-a0c0-42e9-b68d-7cf16637df14 | | name | default | | project_id | cb43f189f7904fb88f3bbcfa22653ab8 | | revision_number | 5 | | rules | created_at='2022-09-12T15:00:59Z', direction='ingress', ethertype='IPv4', | | | id='5e5e9f4d-1faa-492d-91f1-c105b464072b', protocol='0', | | | remote_group_id='60776d43-a78c-4eb4-8998-cea7a04c5f9b', | | | standard_attr_id='10422245', updated_at='2022-09-12T15:00:59Z' | | | created_at='2022-09-12T15:00:59Z', direction='ingress', ethertype='IPv6', | | | id='86b9413a-ad23-46c4-a35e-9306945dc63c', protocol='0', | | | remote_group_id='60776d43-a78c-4eb4-8998-cea7a04c5f9b', | | | standard_attr_id='10422248', updated_at='2022-09-12T15:00:59Z' | | | created_at='2022-09-12T15:00:57Z', direction='egress', ethertype='IPv6', | | | id='ad4a19ef-7fab-4eba-9982-e5b109be121c', standard_attr_id='10422242', | | | updated_at='2022-09-12T15:00:57Z' | | | created_at='2022-09-12T15:00:57Z', direction='egress', ethertype='IPv4', | | | id='f53b1a12-edbb-480b-910b-a71c4836346f', standard_attr_id='10422236', | | | updated_at='2022-09-12T15:00:57Z' | | stateful | True | | tags | [] | | updated_at | 2022-09-12T15:00:59Z | +-----------------+--------------------------------------------------------------------------------+ If you want to restrict the ingress rules to disallow access from other servers and ports in the group, you need to remove the default two ingress rules. Cleura Cloud Management Panel OpenStack CLI Click on the trashcan action button on the right-hand side for both ingress rules. Your default or newly created security group rules will now look like this: To view the rules use the following command: openstack security group rule list default The printout will be similar to this: +-----------+-------------+-----------+-----------+------------+-----------+-----------------------+----------------------+ | ID | IP Protocol | Ethertype | IP Range | Port Range | Direction | Remote Security Group | Remote Address Group | +-----------+-------------+-----------+-----------+------------+-----------+-----------------------+----------------------+ | 5e5e9f4d- | None | IPv4 | 0.0.0.0/0 | | ingress | 60776d43-a78c-4eb4- | None | | 1faa- | | | | | | 8998-cea7a04c5f9b | | | 492d- | | | | | | | | | 91f1- | | | | | | | | | c105b4640 | | | | | | | | | 72b | | | | | | | | | 86b9413a- | None | IPv6 | ::/0 | | ingress | 60776d43-a78c-4eb4- | None | | ad23- | | | | | | 8998-cea7a04c5f9b | | | 46c4- | | | | | | | | | a35e- | | | | | | | | | 9306945dc | | | | | | | | | 63c | | | | | | | | | ad4a19ef- | None | IPv6 | ::/0 | | egress | None | None | | 7fab- | | | | | | | | | 4eba- | | | | | | | | | 9982- | | | | | | | | | e5b109be1 | | | | | | | | | 21c | | | | | | | | | f53b1a12- | None | IPv4 | 0.0.0.0/0 | | egress | None | None | | edbb- | | | | | | | | | 480b- | | | | | | | | | 910b- | | | | | | | | | a71c48363 | | | | | | | | | 46f | | | | | | | | +-----------+-------------+-----------+-----------+------------+-----------+-----------------------+----------------------+ The IDs of the two ingress rules, one for IPv4 traffic and one for IPv6, in this case are: 5e5e9f4d-1faa-492d-91f1-c105b464072b and 86b9413a-ad23-46c4-a35e-9306945dc63c Delete them by using the following command: openstack security group rule delete \\ 5e5e9f4d-1faa-492d-91f1-c105b464072b 86b9413a-ad23-46c4-a35e-9306945dc63c Print the rules again: openstack security group rule list default Now the remaining rules are only the egress ones. +-----------+-------------+-----------+-----------+------------+-----------+-----------------------+----------------------+ | ID | IP Protocol | Ethertype | IP Range | Port Range | Direction | Remote Security Group | Remote Address Group | +-----------+-------------+-----------+-----------+------------+-----------+-----------------------+----------------------+ | ad4a19ef- | None | IPv6 | ::/0 | | egress | None | None | | 7fab- | | | | | | | | | 4eba- | | | | | | | | | 9982- | | | | | | | | | e5b109be1 | | | | | | | | | 21c | | | | | | | | | f53b1a12- | None | IPv4 | 0.0.0.0/0 | | egress | None | None | | edbb- | | | | | | | | | 480b- | | | | | | | | | 910b- | | | | | | | | | a71c48363 | | | | | | | | | 46f | | | | | | | | +-----------+-------------+-----------+-----------+------------+-----------+-----------------------+----------------------+","title":"Removing default ingress rules"},{"location":"howto/openstack/neutron/create-security-groups/#allowing-ssh-access","text":"The next thing to do, is to allow SSH access on port 22 to the server, only from specific networks. Cleura Cloud Management Panel OpenStack CLI To do this, click on the Create new rule button. To create this rule use the following command: openstack security group rule create \\ --protocol tcp --dst-port 22 --remote-ip 203 .0.113.58/32 default If you don\u2019t know your IP, simply visit icanhazip.com . In this example your IP is 203.0.113.58, and if you want to allow SSH access from this IP address only, enter 203.0.113.58/32 as CIDR. If you want to allow SSH access from any address in that Class C subnet , instead enter 203.0.113.0/24 as CIDR.","title":"Allowing SSH access"},{"location":"howto/openstack/neutron/create-security-groups/#allowing-web-traffic","text":"Next create the rules that allow anyone to access the server on port 80 and port 443 . Cleura Cloud Management Panel OpenStack CLI Using the same logic as before, click on Create new rule . Select TCP Protocol and port 80 as both min and max range value. This time, CIDR is left empty, allowing incoming traffic from any IP/source. The same applies to port 443. This time don\u2019t specify \u2013remote-ip to allow traffic from all sources, using the following command: openstack security group rule create --protocol tcp --dst-port 80 default One more time for port 443: openstack security group rule create --protocol tcp --dst-port 443 default To view the updated rules, print the them again: openstack security group rule list default +-----------+-------------+-----------+-----------+------------+-----------+-----------------------+----------------------+ | ID | IP Protocol | Ethertype | IP Range | Port Range | Direction | Remote Security Group | Remote Address Group | +-----------+-------------+-----------+-----------+------------+-----------+-----------------------+----------------------+ | 742bcc46- | tcp | IPv4 | 0.0.0.0/0 | 80:80 | ingress | None | None | | beb5- | | | | | | | | | 47a5- | | | | | | | | | 8eb1- | | | | | | | | | eb35da800 | | | | | | | | | 6ed | | | | | | | | | ad4a19ef- | None | IPv6 | ::/0 | | egress | None | None | | 7fab- | | | | | | | | | 4eba- | | | | | | | | | 9982- | | | | | | | | | e5b109be1 | | | | | | | | | 21c | | | | | | | | | cef0cd36- | tcp | IPv4 | 203.0.113 | 22:22 | ingress | None | None | | ad78- | | | .58/32 | | | | | | 4dbd- | | | | | | | | | b806- | | | | | | | | | 597300fd9 | | | | | | | | | e6a | | | | | | | | | f53b1a12- | None | IPv4 | 0.0.0.0/0 | | egress | None | None | | edbb- | | | | | | | | | 480b- | | | | | | | | | 910b- | | | | | | | | | a71c48363 | | | | | | | | | 46f | | | | | | | | | f90c598c- | tcp | IPv4 | 0.0.0.0/0 | 443:443 | ingress | None | None | | 3a5e- | | | | | | | | | 459f- | | | | | | | | | 8ed3- | | | | | | | | | 3c2538e7a | | | | | | | | | 24f | | | | | | | | +-----------+-------------+-----------+-----------+------------+-----------+-----------------------+----------------------+ All the rules for a simple web server are now in place. For any additional protocol or ingress rule, simply follow the same procedure as above.","title":"Allowing Web Traffic"},{"location":"howto/openstack/neutron/create-security-groups/#adjust-permissive-default-security-group","text":"If your account was created before 2022-11-16, and you didn\u2019t configure the default security group, it is most likely permissive for all incoming traffic. We recommend to either create and use a new security group, other than the default one, or restrict ingress traffic to specific ports and sources. Cleura Cloud Management Panel OpenStack CLI To check how your default security group is configured, click on it and select the Rules tab to view its rules. If you have old, permissive default group, the rules should look like this: The top two ingress rules, having ::/0 and 0.0.0.0/0 values for remote access filters, mean that incoming traffic from all sources is allowed. If you want to use the default group, remove the two ingress rules that allow all incoming traffic. Click on the trashcan action button on the right-hand side for both ingress rules. Your default or newly created security group rules will now look like this: To view the rules use the following command: openstack security group rule list default The printout will be similar to this: +-----------+-------------+-----------+-----------+------------+-----------+-----------------------+----------------------+ | ID | IP Protocol | Ethertype | IP Range | Port Range | Direction | Remote Security Group | Remote Address Group | +-----------+-------------+-----------+-----------+------------+-----------+-----------------------+----------------------+ | 5e5e9f4d- | None | IPv4 | 0.0.0.0/0 | | ingress | None | None | | 1faa- | | | | | | | | | 492d- | | | | | | | | | 91f1- | | | | | | | | | c105b4640 | | | | | | | | | 72b | | | | | | | | | 86b9413a- | None | IPv6 | ::/0 | | ingress | None | None | | ad23- | | | | | | | | | 46c4- | | | | | | | | | a35e- | | | | | | | | | 9306945dc | | | | | | | | | 63c | | | | | | | | | ad4a19ef- | None | IPv6 | ::/0 | | egress | None | None | | 7fab- | | | | | | | | | 4eba- | | | | | | | | | 9982- | | | | | | | | | e5b109be1 | | | | | | | | | 21c | | | | | | | | | f53b1a12- | None | IPv4 | 0.0.0.0/0 | | egress | None | None | | edbb- | | | | | | | | | 480b- | | | | | | | | | 910b- | | | | | | | | | a71c48363 | | | | | | | | | 46f | | | | | | | | +-----------+-------------+-----------+-----------+------------+-----------+-----------------------+----------------------+ If the ingress rules have ::/0 and 0.0.0.0/0 values in IP Range column, and None in the Remote Security Group , then incoming traffic from any source is allowed. The IDs of the two ingress rules, one for IPv4 traffic and one for IPv6, are: 5e5e9f4d-1faa-492d-91f1-c105b464072b and 86b9413a-ad23-46c4-a35e-9306945dc63c respectively. Delete them by using the following command: openstack security group rule delete \\ 5e5e9f4d-1faa-492d-91f1-c105b464072b 86b9413a-ad23-46c4-a35e-9306945dc63c Print the rules again: openstack security group rule list default Now the remaining rules are only the egress ones. +-----------+-------------+-----------+-----------+------------+-----------+-----------------------+----------------------+ | ID | IP Protocol | Ethertype | IP Range | Port Range | Direction | Remote Security Group | Remote Address Group | +-----------+-------------+-----------+-----------+------------+-----------+-----------------------+----------------------+ | ad4a19ef- | None | IPv6 | ::/0 | | egress | None | None | | 7fab- | | | | | | | | | 4eba- | | | | | | | | | 9982- | | | | | | | | | e5b109be1 | | | | | | | | | 21c | | | | | | | | | f53b1a12- | None | IPv4 | 0.0.0.0/0 | | egress | None | None | | edbb- | | | | | | | | | 480b- | | | | | | | | | 910b- | | | | | | | | | a71c48363 | | | | | | | | | 46f | | | | | | | | +-----------+-------------+-----------+-----------+------------+-----------+-----------------------+----------------------+","title":"Adjust permissive default security group"},{"location":"howto/openstack/neutron/delete-network/","text":"Deleting networks Deleting a network in Cleura Cloud may sound like a pretty straightforward task \u2014 and it is. It\u2019s just that before deleting a network, there are some steps we almost always need to take. In what follows we show, step by step and through specific examples, how we delete networks using either the Cleura Cloud Management Panel or the OpenStack CLI. Prerequisites Whether you choose to work from the Cleura Cloud Management Panel or with the OpenStack CLI, you need to have an account in Cleura Cloud. Additionally, to use the OpenStack CLI, make sure to enable it for the region you will be working in. Selecting a network Unless you already have the ID or know the name of the network you wish to delete, you may first list all available networks. Cleura Cloud Management Panel OpenStack CLI Fire up your favorite web browser, navigate to the Cleura Cloud Management Panel start page, and log into your Cleura Cloud account. In the vertical pane on the left-hand side of the dashboard, expand the Networking section and click Networks . In the central pane of the page, you will see all networks in all regions you have access to. For the purposes of this guide, let us assume you no longer need network carmacks , so now you want to delete it. To list all available networks in the region you are currently in, type the following: openstack network list --internal +--------------------------------------+--------------+--------------------------------------+ | ID | Name | Subnets | +--------------------------------------+--------------+--------------------------------------+ | 1f94d315-7ca1-4d44-acc1-09c6c650df74 | mayo | | | 9b127d2c-01d7-4803-994f-f88292870c1d | teslin | bd1d0ff2-7270-4a9a-a7ad-fff47e997e7b | | cb0a298a-bbb6-4ad6-832a-1456dafe45db | carmacks | 7fa9e5a2-7d5a-466e-b120-7d2bffb99ce5 | | e0c4ce17-2722-4777-8140-d6c87479e190 | network-kna1 | 421d8fd2-dd7f-4f7c-9a51-42ef4a866dd9 | +--------------------------------------+--------------+--------------------------------------+ Let us assume you wish to delete the network named carmacks . Determining component dependencies If the network to be deleted has a subnet component \u2014 and most likely it will have \u2014, you will first have to delete the subnet before deleting the network. If, in addition, the network is behind a router (figurately speaking), then before deleting the subnet, you will have to disconnect it from the router. Finally, you will have the option to delete the router also. Let us see what the situation is with network carmacks . Cleura Cloud Management Panel OpenStack CLI For more information on carmacks , click the three-dot icon (right-hand side of the network row) and select View details . Four tabs immediately appear below; Details , Ports , Subnets , and Routers . Looking at the Details tab, it is clear that network carmacks has a subnet and is behind a router. You may click on tabs Subnets and Routers , to see more information regarding the network subnet and the router in front of the network. To quickly check whether network carmacks has a subnet or not, type: openstack network show carmacks -c subnets +---------+--------------------------------------+ | Field | Value | +---------+--------------------------------------+ | subnets | 7fa9e5a2-7d5a-466e-b120-7d2bffb99ce5 | +---------+--------------------------------------+ If the value for the field subnets is non-empty, like in the example output above, that means the network has a subnet indeed, and the value is the ID of that subnet. At this point, it helps to assign the subnet ID to an environment variable, like so: SUBNET_ID = \"7fa9e5a2-7d5a-466e-b120-7d2bffb99ce5\" What about a router in front of carmacks ? You might try checking the output of this command: openstack network show carmacks +---------------------------+--------------------------------------+ | Field | Value | +---------------------------+--------------------------------------+ | admin_state_up | UP | | availability_zone_hints | | | availability_zones | nova | | created_at | 2022-12-09T18:52:09Z | | description | | | dns_domain | None | | id | cb0a298a-bbb6-4ad6-832a-1456dafe45db | | ipv4_address_scope | None | | ipv6_address_scope | None | | is_default | None | | is_vlan_transparent | None | | mtu | 1500 | | name | carmacks | | port_security_enabled | True | | project_id | 94109c764a754e24ac0f6b01aef82359 | | provider:network_type | None | | provider:physical_network | None | | provider:segmentation_id | None | | qos_policy_id | None | | revision_number | 2 | | router:external | Internal | | segments | None | | shared | False | | status | ACTIVE | | subnets | 7fa9e5a2-7d5a-466e-b120-7d2bffb99ce5 | | tags | | | tenant_id | 94109c764a754e24ac0f6b01aef82359 | | updated_at | 2022-12-09T18:55:18Z | +---------------------------+--------------------------------------+ While it usually pays off to use openstack commands with the verb show on various objects, in this case, you don\u2019t get what you\u2019re looking for \u2014 which is an indication of the presence or absence of a router in front of carmacks . In cases like this, try looking at things from a different vantage point. Try, in particular, to list all routers: openstack router list +------------------------+-----------------+--------+-------+------------------------+------+ | ID | Name | Status | State | Project | HA | +------------------------+-----------------+--------+-------+------------------------+------+ | 5ac45739-a379-4936- | router-kna1 | ACTIVE | UP | 94109c764a754e24ac0f6b | True | | 8b1b-67d10e017f4d | | | | 01aef82359 | | | 79ff91ae-91b5-4991- | carmacks-router | ACTIVE | UP | 94109c764a754e24ac0f6b | True | | af61-91e923fac87b | | | | 01aef82359 | | +------------------------+-----------------+--------+-------+------------------------+------+ The name of the second router says it all, but since it is just a name, it doesn\u2019t hurt to verify the role of this router: openstack router show carmacks-router -c interfaces_info +-----------------+--------------------------------------------------------------------------------+ | Field | Value | +-----------------+--------------------------------------------------------------------------------+ | interfaces_info | [{\"port_id\": \"439bc9d5-c8a9-4de1-93b9-b01e69258a56\", \"ip_address\": \"10.1.0.1\", | | | \"subnet_id\": \"7fa9e5a2-7d5a-466e-b120-7d2bffb99ce5\"}] | +-----------------+--------------------------------------------------------------------------------+ Looking at the value of interfaces_info , it is easy to see that subnet_id has the value of the variable SUBNET_ID you just instantiated. In other words, router carmacks-router is indeed in front of network carmacks . There will be times when router names won\u2019t help much. Then, try a more exhaustive search approach: for i in $( openstack router list -f value -c Name ) ; \\ do echo Checking router \" $i \" ; \\ openstack router show \" $i \" -f json -c interfaces_info \\ | grep \" $SUBNET_ID \" ; \\ done Checking router carmacks-router \"subnet_id\": \"7fa9e5a2-7d5a-466e-b120-7d2bffb99ce5\" Checking router router-kna1 Tearing down networks Now that you know you\u2019re dealing with a full-blown network and a router, you start by disconnecting the subnet from the router. Then, you will move on to deleting the subnet and the network, and after that, you can finish up with deleting the router. Cleura Cloud Management Panel OpenStack CLI Go to the Subnets tab of the carmacks network, and click the gray notepad-and-pen icon (at the left of the red circle-with-trashcan icon). A vertical pane titled Modify Subnet will slide over from the right-hand side of the page. Pay attention to the Router Connections section. You will notice an active connection to the router. Click the red circle-with-line-over-chainlink icon to deactivate the connection, effectively disconnecting the subnet from the router. A pop-up window will appear, asking if you really want to go ahead with the disconnection. Just click the red Yes, Remove interface button. After disconnecting the subnet, click the red circle-and-trashcan icon to delete it. Once more, a pop-up will appear asking for confirmation. Click the red Yes, Delete button. As soon as you delete the subnet, in the Subnets tab you will see the message No subnets found . You can now delete the network. Click the three-dot icon (right-hand side of the network row) and select Delete Network . Of course, you will have to confirm this action. Clicking the red Yes, Delete button is enough. After deleting the network, it will not be on the list of all available networks. There\u2019s still that router lying around, and if you have no use for it, go to the Routers page to delete it. In the vertical pane on the left, expand the Networking section and click on Routers . In the central pane of the page, you will see all routers in all regions you have access to. Click the red three-dot icon of the router you wish to delete and select Delete Router . A pop-up will appear asking for confirmation, so click the red Yes, Delete button. After successfully deleting the router, there will be no trace of it in the list of all routers. First, take a look at all available subnets: openstack subnet list +-------------------------------+-----------------+--------------------------------+---------------+ | ID | Name | Network | Subnet | +-------------------------------+-----------------+--------------------------------+---------------+ | 421d8fd2-dd7f-4f7c-9a51- | subnet-kna1 | e0c4ce17-2722-4777-8140- | 10.15.20.0/24 | | 42ef4a866dd9 | | d6c87479e190 | | | 7fa9e5a2-7d5a-466e-b120- | carmacks-subnet | cb0a298a-bbb6-4ad6-832a- | 10.1.0.0/24 | | 7d2bffb99ce5 | | 1456dafe45db | | | bd1d0ff2-7270-4a9a-a7ad- | teslin-subnet | 9b127d2c-01d7-4803-994f- | 10.254.0.0/24 | | fff47e997e7b | | f88292870c1d | | +-------------------------------+-----------------+--------------------------------+---------------+ As you would expect, included on the list is subnet carmacks-subnet , which you are about to delete. That\u2019s easier said than done, though: openstack subnet delete $SUBNET_ID Failed to delete subnet with name or ID '7fa9e5a2-7d5a-466e-b120-7d2bffb99ce5': ConflictException: 409: Client Error for url: kna1.citycloud.com:9696/v2.0/subnets/7fa9e5a2-7d5a-466e-b120-7d2bffb99ce5, Unable to complete operation on subnet 7fa9e5a2-7d5a-466e-b120-7d2bffb99ce5: One or more ports have an IP allocation from this subnet. 1 of 1 subnets failed to delete. The trick here is to first disconnect the subnet from the corresponding router, which is perfectly doable from the side of the router. As we discovered a bit earlier, the router we are talking about is carmacks-router : openstack router remove subnet carmacks-router $SUBNET_ID If the command above is successful, you will see no output on your terminal. Now, an attempt to delete carmacks-subnet should go through with flying colors: openstack subnet delete $SUBNET_ID Again, no command output means success, but we suggest you check yourself: openstack subnet list +--------------------------------+---------------+---------------------------------+---------------+ | ID | Name | Network | Subnet | +--------------------------------+---------------+---------------------------------+---------------+ | 421d8fd2-dd7f-4f7c-9a51- | subnet-kna1 | e0c4ce17-2722-4777-8140- | 10.15.20.0/24 | | 42ef4a866dd9 | | d6c87479e190 | | | bd1d0ff2-7270-4a9a-a7ad- | teslin-subnet | 9b127d2c-01d7-4803-994f- | 10.254.0.0/24 | | fff47e997e7b | | f88292870c1d | | +--------------------------------+---------------+---------------------------------+---------------+ The subnet carmacks-subnet is not on the list, which is what you wanted exactly. Next is network carmacks , which you should be able to delete by now. First, take a look at all available networks: openstack network list --internal +--------------------------------------+--------------+--------------------------------------+ | ID | Name | Subnets | +--------------------------------------+--------------+--------------------------------------+ | 1f94d315-7ca1-4d44-acc1-09c6c650df74 | mayo | | | 9b127d2c-01d7-4803-994f-f88292870c1d | teslin | bd1d0ff2-7270-4a9a-a7ad-fff47e997e7b | | cb0a298a-bbb6-4ad6-832a-1456dafe45db | carmacks | | | e0c4ce17-2722-4777-8140-d6c87479e190 | network-kna1 | 421d8fd2-dd7f-4f7c-9a51-42ef4a866dd9 | +--------------------------------------+--------------+--------------------------------------+ Network carmacks is on the list, and by looking at the Subnets column, you see that it has no subnet. That\u2019s expected, so go ahead and delete the network: openstack network delete carmacks No command output signals success, but it never hurts to verify yourself: openstack network list --internal +--------------------------------------+--------------+--------------------------------------+ | ID | Name | Subnets | +--------------------------------------+--------------+--------------------------------------+ | 1f94d315-7ca1-4d44-acc1-09c6c650df74 | mayo | | | 9b127d2c-01d7-4803-994f-f88292870c1d | teslin | bd1d0ff2-7270-4a9a-a7ad-fff47e997e7b | | e0c4ce17-2722-4777-8140-d6c87479e190 | network-kna1 | 421d8fd2-dd7f-4f7c-9a51-42ef4a866dd9 | +--------------------------------------+--------------+--------------------------------------+ Network carmacks is gone, and if you have no use of carmacks-router , go ahead and delete it: openstack router delete carmacks-router There is no output on the terminal, and yet the router is gone: openstack router list +-----------------------------+-------------+--------+-------+------------------------------+------+ | ID | Name | Status | State | Project | HA | +-----------------------------+-------------+--------+-------+------------------------------+------+ | 5ac45739-a379-4936-8b1b- | router-kna1 | ACTIVE | UP | 94109c764a754e24ac0f6b01aef8 | True | | 67d10e017f4d | | | | 2359 | | +-----------------------------+-------------+--------+-------+------------------------------+------+ Networks with a subnet but no router These are faster to delete, for there is no router to disconnect the subnet from. For our demonstration, we created network teslin , with subnet teslin-subnet and no router in front of it. Cleura Cloud Management Panel OpenStack CLI In the vertical pane on the left-hand side of the dashboard, expand the Networking section and click Networks . In the central pane of the page, you will see all networks in all regions you have access to. Select a network with a subnet and no router \u2014 like teslin in our example. Looking at the network details, it is immediately apparent that there\u2019s no router in front of it. Go to the Subnets tab, and click the red circle-with-trashcan icon to delete the subnet. Then, click the red three-dot icon at the right-hand side of the teslin row, and select Delete Network . Let us first take a look at all available networks\u2026 openstack network list --internal +--------------------------------------+--------------+--------------------------------------+ | ID | Name | Subnets | +--------------------------------------+--------------+--------------------------------------+ | 1f94d315-7ca1-4d44-acc1-09c6c650df74 | mayo | | | 9b127d2c-01d7-4803-994f-f88292870c1d | teslin | bd1d0ff2-7270-4a9a-a7ad-fff47e997e7b | | e0c4ce17-2722-4777-8140-d6c87479e190 | network-kna1 | 421d8fd2-dd7f-4f7c-9a51-42ef4a866dd9 | +--------------------------------------+--------------+--------------------------------------+ \u2026and at all available subnets: openstack subnet list +--------------------------------+---------------+---------------------------------+---------------+ | ID | Name | Network | Subnet | +--------------------------------+---------------+---------------------------------+---------------+ | 421d8fd2-dd7f-4f7c-9a51- | subnet-kna1 | e0c4ce17-2722-4777-8140- | 10.15.20.0/24 | | 42ef4a866dd9 | | d6c87479e190 | | | bd1d0ff2-7270-4a9a-a7ad- | teslin-subnet | 9b127d2c-01d7-4803-994f- | 10.254.0.0/24 | | fff47e997e7b | | f88292870c1d | | +--------------------------------+---------------+---------------------------------+---------------+ Since there is nothing to disconnect the teslin-subnet from, you may go ahead and delete the subnet: openstack subnet delete teslin-subnet There is no command output. This is expected, but why not check yourself? openstack subnet list +---------------------------------+-------------+----------------------------------+---------------+ | ID | Name | Network | Subnet | +---------------------------------+-------------+----------------------------------+---------------+ | 421d8fd2-dd7f-4f7c-9a51- | subnet-kna1 | e0c4ce17-2722-4777-8140- | 10.15.20.0/24 | | 42ef4a866dd9 | | d6c87479e190 | | +---------------------------------+-------------+----------------------------------+---------------+ Finally, network teslin can go away with a single command: openstack network delete teslin The absence of any output means the command was successful. Take a look yourself: openstack network list --internal +--------------------------------------+--------------+--------------------------------------+ | ID | Name | Subnets | +--------------------------------------+--------------+--------------------------------------+ | 1f94d315-7ca1-4d44-acc1-09c6c650df74 | mayo | | | e0c4ce17-2722-4777-8140-d6c87479e190 | network-kna1 | 421d8fd2-dd7f-4f7c-9a51-42ef4a866dd9 | +--------------------------------------+--------------+--------------------------------------+ Networks with no subnet and no router You may directly, without the slightest preparation, delete networks like these. For our demonstration, we created a network named mayo , with no subnet and no router in front of it. Cleura Cloud Management Panel OpenStack CLI While viewing all available networks, click the red three-dot icon at the right-hand side of the mayo row and select Delete Network . You will have to confirm the action, and the network will be gone as soon as you do. Once more, take a look at all remaining networks: openstack network list --internal +--------------------------------------+--------------+--------------------------------------+ | ID | Name | Subnets | +--------------------------------------+--------------+--------------------------------------+ | 1f94d315-7ca1-4d44-acc1-09c6c650df74 | mayo | | | e0c4ce17-2722-4777-8140-d6c87479e190 | network-kna1 | 421d8fd2-dd7f-4f7c-9a51-42ef4a866dd9 | +--------------------------------------+--------------+--------------------------------------+ Since mayo has no subnet, issue a single command to delete it: openstack network delete mayo And, yes, it is still a good idea to check yourself: openstack network list --internal +--------------------------------------+--------------+--------------------------------------+ | ID | Name | Subnets | +--------------------------------------+--------------+--------------------------------------+ | e0c4ce17-2722-4777-8140-d6c87479e190 | network-kna1 | 421d8fd2-dd7f-4f7c-9a51-42ef4a866dd9 | +--------------------------------------+--------------+--------------------------------------+ Recap: Of networks and towns Depending on the features of a Neutron network, deleting it may require some preparation work. For the purposes of this guide, we created three different networks with different characteristics; carmacks , teslin , and mayo . Then, either from the Cleura Cloud Management Panel or with the help of OpenStack CLI, we showed how we discover any component dependencies and how we work towards deletion. Eventually, all three test networks were gone. We should point out, though, that all three namesake towns in Yukon are still there.","title":"Deleting networks"},{"location":"howto/openstack/neutron/delete-network/#deleting-networks","text":"Deleting a network in Cleura Cloud may sound like a pretty straightforward task \u2014 and it is. It\u2019s just that before deleting a network, there are some steps we almost always need to take. In what follows we show, step by step and through specific examples, how we delete networks using either the Cleura Cloud Management Panel or the OpenStack CLI.","title":"Deleting networks"},{"location":"howto/openstack/neutron/delete-network/#prerequisites","text":"Whether you choose to work from the Cleura Cloud Management Panel or with the OpenStack CLI, you need to have an account in Cleura Cloud. Additionally, to use the OpenStack CLI, make sure to enable it for the region you will be working in.","title":"Prerequisites"},{"location":"howto/openstack/neutron/delete-network/#selecting-a-network","text":"Unless you already have the ID or know the name of the network you wish to delete, you may first list all available networks. Cleura Cloud Management Panel OpenStack CLI Fire up your favorite web browser, navigate to the Cleura Cloud Management Panel start page, and log into your Cleura Cloud account. In the vertical pane on the left-hand side of the dashboard, expand the Networking section and click Networks . In the central pane of the page, you will see all networks in all regions you have access to. For the purposes of this guide, let us assume you no longer need network carmacks , so now you want to delete it. To list all available networks in the region you are currently in, type the following: openstack network list --internal +--------------------------------------+--------------+--------------------------------------+ | ID | Name | Subnets | +--------------------------------------+--------------+--------------------------------------+ | 1f94d315-7ca1-4d44-acc1-09c6c650df74 | mayo | | | 9b127d2c-01d7-4803-994f-f88292870c1d | teslin | bd1d0ff2-7270-4a9a-a7ad-fff47e997e7b | | cb0a298a-bbb6-4ad6-832a-1456dafe45db | carmacks | 7fa9e5a2-7d5a-466e-b120-7d2bffb99ce5 | | e0c4ce17-2722-4777-8140-d6c87479e190 | network-kna1 | 421d8fd2-dd7f-4f7c-9a51-42ef4a866dd9 | +--------------------------------------+--------------+--------------------------------------+ Let us assume you wish to delete the network named carmacks .","title":"Selecting a network"},{"location":"howto/openstack/neutron/delete-network/#determining-component-dependencies","text":"If the network to be deleted has a subnet component \u2014 and most likely it will have \u2014, you will first have to delete the subnet before deleting the network. If, in addition, the network is behind a router (figurately speaking), then before deleting the subnet, you will have to disconnect it from the router. Finally, you will have the option to delete the router also. Let us see what the situation is with network carmacks . Cleura Cloud Management Panel OpenStack CLI For more information on carmacks , click the three-dot icon (right-hand side of the network row) and select View details . Four tabs immediately appear below; Details , Ports , Subnets , and Routers . Looking at the Details tab, it is clear that network carmacks has a subnet and is behind a router. You may click on tabs Subnets and Routers , to see more information regarding the network subnet and the router in front of the network. To quickly check whether network carmacks has a subnet or not, type: openstack network show carmacks -c subnets +---------+--------------------------------------+ | Field | Value | +---------+--------------------------------------+ | subnets | 7fa9e5a2-7d5a-466e-b120-7d2bffb99ce5 | +---------+--------------------------------------+ If the value for the field subnets is non-empty, like in the example output above, that means the network has a subnet indeed, and the value is the ID of that subnet. At this point, it helps to assign the subnet ID to an environment variable, like so: SUBNET_ID = \"7fa9e5a2-7d5a-466e-b120-7d2bffb99ce5\" What about a router in front of carmacks ? You might try checking the output of this command: openstack network show carmacks +---------------------------+--------------------------------------+ | Field | Value | +---------------------------+--------------------------------------+ | admin_state_up | UP | | availability_zone_hints | | | availability_zones | nova | | created_at | 2022-12-09T18:52:09Z | | description | | | dns_domain | None | | id | cb0a298a-bbb6-4ad6-832a-1456dafe45db | | ipv4_address_scope | None | | ipv6_address_scope | None | | is_default | None | | is_vlan_transparent | None | | mtu | 1500 | | name | carmacks | | port_security_enabled | True | | project_id | 94109c764a754e24ac0f6b01aef82359 | | provider:network_type | None | | provider:physical_network | None | | provider:segmentation_id | None | | qos_policy_id | None | | revision_number | 2 | | router:external | Internal | | segments | None | | shared | False | | status | ACTIVE | | subnets | 7fa9e5a2-7d5a-466e-b120-7d2bffb99ce5 | | tags | | | tenant_id | 94109c764a754e24ac0f6b01aef82359 | | updated_at | 2022-12-09T18:55:18Z | +---------------------------+--------------------------------------+ While it usually pays off to use openstack commands with the verb show on various objects, in this case, you don\u2019t get what you\u2019re looking for \u2014 which is an indication of the presence or absence of a router in front of carmacks . In cases like this, try looking at things from a different vantage point. Try, in particular, to list all routers: openstack router list +------------------------+-----------------+--------+-------+------------------------+------+ | ID | Name | Status | State | Project | HA | +------------------------+-----------------+--------+-------+------------------------+------+ | 5ac45739-a379-4936- | router-kna1 | ACTIVE | UP | 94109c764a754e24ac0f6b | True | | 8b1b-67d10e017f4d | | | | 01aef82359 | | | 79ff91ae-91b5-4991- | carmacks-router | ACTIVE | UP | 94109c764a754e24ac0f6b | True | | af61-91e923fac87b | | | | 01aef82359 | | +------------------------+-----------------+--------+-------+------------------------+------+ The name of the second router says it all, but since it is just a name, it doesn\u2019t hurt to verify the role of this router: openstack router show carmacks-router -c interfaces_info +-----------------+--------------------------------------------------------------------------------+ | Field | Value | +-----------------+--------------------------------------------------------------------------------+ | interfaces_info | [{\"port_id\": \"439bc9d5-c8a9-4de1-93b9-b01e69258a56\", \"ip_address\": \"10.1.0.1\", | | | \"subnet_id\": \"7fa9e5a2-7d5a-466e-b120-7d2bffb99ce5\"}] | +-----------------+--------------------------------------------------------------------------------+ Looking at the value of interfaces_info , it is easy to see that subnet_id has the value of the variable SUBNET_ID you just instantiated. In other words, router carmacks-router is indeed in front of network carmacks . There will be times when router names won\u2019t help much. Then, try a more exhaustive search approach: for i in $( openstack router list -f value -c Name ) ; \\ do echo Checking router \" $i \" ; \\ openstack router show \" $i \" -f json -c interfaces_info \\ | grep \" $SUBNET_ID \" ; \\ done Checking router carmacks-router \"subnet_id\": \"7fa9e5a2-7d5a-466e-b120-7d2bffb99ce5\" Checking router router-kna1","title":"Determining component dependencies"},{"location":"howto/openstack/neutron/delete-network/#tearing-down-networks","text":"Now that you know you\u2019re dealing with a full-blown network and a router, you start by disconnecting the subnet from the router. Then, you will move on to deleting the subnet and the network, and after that, you can finish up with deleting the router. Cleura Cloud Management Panel OpenStack CLI Go to the Subnets tab of the carmacks network, and click the gray notepad-and-pen icon (at the left of the red circle-with-trashcan icon). A vertical pane titled Modify Subnet will slide over from the right-hand side of the page. Pay attention to the Router Connections section. You will notice an active connection to the router. Click the red circle-with-line-over-chainlink icon to deactivate the connection, effectively disconnecting the subnet from the router. A pop-up window will appear, asking if you really want to go ahead with the disconnection. Just click the red Yes, Remove interface button. After disconnecting the subnet, click the red circle-and-trashcan icon to delete it. Once more, a pop-up will appear asking for confirmation. Click the red Yes, Delete button. As soon as you delete the subnet, in the Subnets tab you will see the message No subnets found . You can now delete the network. Click the three-dot icon (right-hand side of the network row) and select Delete Network . Of course, you will have to confirm this action. Clicking the red Yes, Delete button is enough. After deleting the network, it will not be on the list of all available networks. There\u2019s still that router lying around, and if you have no use for it, go to the Routers page to delete it. In the vertical pane on the left, expand the Networking section and click on Routers . In the central pane of the page, you will see all routers in all regions you have access to. Click the red three-dot icon of the router you wish to delete and select Delete Router . A pop-up will appear asking for confirmation, so click the red Yes, Delete button. After successfully deleting the router, there will be no trace of it in the list of all routers. First, take a look at all available subnets: openstack subnet list +-------------------------------+-----------------+--------------------------------+---------------+ | ID | Name | Network | Subnet | +-------------------------------+-----------------+--------------------------------+---------------+ | 421d8fd2-dd7f-4f7c-9a51- | subnet-kna1 | e0c4ce17-2722-4777-8140- | 10.15.20.0/24 | | 42ef4a866dd9 | | d6c87479e190 | | | 7fa9e5a2-7d5a-466e-b120- | carmacks-subnet | cb0a298a-bbb6-4ad6-832a- | 10.1.0.0/24 | | 7d2bffb99ce5 | | 1456dafe45db | | | bd1d0ff2-7270-4a9a-a7ad- | teslin-subnet | 9b127d2c-01d7-4803-994f- | 10.254.0.0/24 | | fff47e997e7b | | f88292870c1d | | +-------------------------------+-----------------+--------------------------------+---------------+ As you would expect, included on the list is subnet carmacks-subnet , which you are about to delete. That\u2019s easier said than done, though: openstack subnet delete $SUBNET_ID Failed to delete subnet with name or ID '7fa9e5a2-7d5a-466e-b120-7d2bffb99ce5': ConflictException: 409: Client Error for url: kna1.citycloud.com:9696/v2.0/subnets/7fa9e5a2-7d5a-466e-b120-7d2bffb99ce5, Unable to complete operation on subnet 7fa9e5a2-7d5a-466e-b120-7d2bffb99ce5: One or more ports have an IP allocation from this subnet. 1 of 1 subnets failed to delete. The trick here is to first disconnect the subnet from the corresponding router, which is perfectly doable from the side of the router. As we discovered a bit earlier, the router we are talking about is carmacks-router : openstack router remove subnet carmacks-router $SUBNET_ID If the command above is successful, you will see no output on your terminal. Now, an attempt to delete carmacks-subnet should go through with flying colors: openstack subnet delete $SUBNET_ID Again, no command output means success, but we suggest you check yourself: openstack subnet list +--------------------------------+---------------+---------------------------------+---------------+ | ID | Name | Network | Subnet | +--------------------------------+---------------+---------------------------------+---------------+ | 421d8fd2-dd7f-4f7c-9a51- | subnet-kna1 | e0c4ce17-2722-4777-8140- | 10.15.20.0/24 | | 42ef4a866dd9 | | d6c87479e190 | | | bd1d0ff2-7270-4a9a-a7ad- | teslin-subnet | 9b127d2c-01d7-4803-994f- | 10.254.0.0/24 | | fff47e997e7b | | f88292870c1d | | +--------------------------------+---------------+---------------------------------+---------------+ The subnet carmacks-subnet is not on the list, which is what you wanted exactly. Next is network carmacks , which you should be able to delete by now. First, take a look at all available networks: openstack network list --internal +--------------------------------------+--------------+--------------------------------------+ | ID | Name | Subnets | +--------------------------------------+--------------+--------------------------------------+ | 1f94d315-7ca1-4d44-acc1-09c6c650df74 | mayo | | | 9b127d2c-01d7-4803-994f-f88292870c1d | teslin | bd1d0ff2-7270-4a9a-a7ad-fff47e997e7b | | cb0a298a-bbb6-4ad6-832a-1456dafe45db | carmacks | | | e0c4ce17-2722-4777-8140-d6c87479e190 | network-kna1 | 421d8fd2-dd7f-4f7c-9a51-42ef4a866dd9 | +--------------------------------------+--------------+--------------------------------------+ Network carmacks is on the list, and by looking at the Subnets column, you see that it has no subnet. That\u2019s expected, so go ahead and delete the network: openstack network delete carmacks No command output signals success, but it never hurts to verify yourself: openstack network list --internal +--------------------------------------+--------------+--------------------------------------+ | ID | Name | Subnets | +--------------------------------------+--------------+--------------------------------------+ | 1f94d315-7ca1-4d44-acc1-09c6c650df74 | mayo | | | 9b127d2c-01d7-4803-994f-f88292870c1d | teslin | bd1d0ff2-7270-4a9a-a7ad-fff47e997e7b | | e0c4ce17-2722-4777-8140-d6c87479e190 | network-kna1 | 421d8fd2-dd7f-4f7c-9a51-42ef4a866dd9 | +--------------------------------------+--------------+--------------------------------------+ Network carmacks is gone, and if you have no use of carmacks-router , go ahead and delete it: openstack router delete carmacks-router There is no output on the terminal, and yet the router is gone: openstack router list +-----------------------------+-------------+--------+-------+------------------------------+------+ | ID | Name | Status | State | Project | HA | +-----------------------------+-------------+--------+-------+------------------------------+------+ | 5ac45739-a379-4936-8b1b- | router-kna1 | ACTIVE | UP | 94109c764a754e24ac0f6b01aef8 | True | | 67d10e017f4d | | | | 2359 | | +-----------------------------+-------------+--------+-------+------------------------------+------+","title":"Tearing down networks"},{"location":"howto/openstack/neutron/delete-network/#networks-with-a-subnet-but-no-router","text":"These are faster to delete, for there is no router to disconnect the subnet from. For our demonstration, we created network teslin , with subnet teslin-subnet and no router in front of it. Cleura Cloud Management Panel OpenStack CLI In the vertical pane on the left-hand side of the dashboard, expand the Networking section and click Networks . In the central pane of the page, you will see all networks in all regions you have access to. Select a network with a subnet and no router \u2014 like teslin in our example. Looking at the network details, it is immediately apparent that there\u2019s no router in front of it. Go to the Subnets tab, and click the red circle-with-trashcan icon to delete the subnet. Then, click the red three-dot icon at the right-hand side of the teslin row, and select Delete Network . Let us first take a look at all available networks\u2026 openstack network list --internal +--------------------------------------+--------------+--------------------------------------+ | ID | Name | Subnets | +--------------------------------------+--------------+--------------------------------------+ | 1f94d315-7ca1-4d44-acc1-09c6c650df74 | mayo | | | 9b127d2c-01d7-4803-994f-f88292870c1d | teslin | bd1d0ff2-7270-4a9a-a7ad-fff47e997e7b | | e0c4ce17-2722-4777-8140-d6c87479e190 | network-kna1 | 421d8fd2-dd7f-4f7c-9a51-42ef4a866dd9 | +--------------------------------------+--------------+--------------------------------------+ \u2026and at all available subnets: openstack subnet list +--------------------------------+---------------+---------------------------------+---------------+ | ID | Name | Network | Subnet | +--------------------------------+---------------+---------------------------------+---------------+ | 421d8fd2-dd7f-4f7c-9a51- | subnet-kna1 | e0c4ce17-2722-4777-8140- | 10.15.20.0/24 | | 42ef4a866dd9 | | d6c87479e190 | | | bd1d0ff2-7270-4a9a-a7ad- | teslin-subnet | 9b127d2c-01d7-4803-994f- | 10.254.0.0/24 | | fff47e997e7b | | f88292870c1d | | +--------------------------------+---------------+---------------------------------+---------------+ Since there is nothing to disconnect the teslin-subnet from, you may go ahead and delete the subnet: openstack subnet delete teslin-subnet There is no command output. This is expected, but why not check yourself? openstack subnet list +---------------------------------+-------------+----------------------------------+---------------+ | ID | Name | Network | Subnet | +---------------------------------+-------------+----------------------------------+---------------+ | 421d8fd2-dd7f-4f7c-9a51- | subnet-kna1 | e0c4ce17-2722-4777-8140- | 10.15.20.0/24 | | 42ef4a866dd9 | | d6c87479e190 | | +---------------------------------+-------------+----------------------------------+---------------+ Finally, network teslin can go away with a single command: openstack network delete teslin The absence of any output means the command was successful. Take a look yourself: openstack network list --internal +--------------------------------------+--------------+--------------------------------------+ | ID | Name | Subnets | +--------------------------------------+--------------+--------------------------------------+ | 1f94d315-7ca1-4d44-acc1-09c6c650df74 | mayo | | | e0c4ce17-2722-4777-8140-d6c87479e190 | network-kna1 | 421d8fd2-dd7f-4f7c-9a51-42ef4a866dd9 | +--------------------------------------+--------------+--------------------------------------+","title":"Networks with a subnet but no router"},{"location":"howto/openstack/neutron/delete-network/#networks-with-no-subnet-and-no-router","text":"You may directly, without the slightest preparation, delete networks like these. For our demonstration, we created a network named mayo , with no subnet and no router in front of it. Cleura Cloud Management Panel OpenStack CLI While viewing all available networks, click the red three-dot icon at the right-hand side of the mayo row and select Delete Network . You will have to confirm the action, and the network will be gone as soon as you do. Once more, take a look at all remaining networks: openstack network list --internal +--------------------------------------+--------------+--------------------------------------+ | ID | Name | Subnets | +--------------------------------------+--------------+--------------------------------------+ | 1f94d315-7ca1-4d44-acc1-09c6c650df74 | mayo | | | e0c4ce17-2722-4777-8140-d6c87479e190 | network-kna1 | 421d8fd2-dd7f-4f7c-9a51-42ef4a866dd9 | +--------------------------------------+--------------+--------------------------------------+ Since mayo has no subnet, issue a single command to delete it: openstack network delete mayo And, yes, it is still a good idea to check yourself: openstack network list --internal +--------------------------------------+--------------+--------------------------------------+ | ID | Name | Subnets | +--------------------------------------+--------------+--------------------------------------+ | e0c4ce17-2722-4777-8140-d6c87479e190 | network-kna1 | 421d8fd2-dd7f-4f7c-9a51-42ef4a866dd9 | +--------------------------------------+--------------+--------------------------------------+","title":"Networks with no subnet and no router"},{"location":"howto/openstack/neutron/delete-network/#recap-of-networks-and-towns","text":"Depending on the features of a Neutron network, deleting it may require some preparation work. For the purposes of this guide, we created three different networks with different characteristics; carmacks , teslin , and mayo . Then, either from the Cleura Cloud Management Panel or with the help of OpenStack CLI, we showed how we discover any component dependencies and how we work towards deletion. Eventually, all three test networks were gone. We should point out, though, that all three namesake towns in Yukon are still there.","title":"Recap: Of networks and towns"},{"location":"howto/openstack/neutron/multiple-public-ips/","text":"Assigning multiple public (floating) IPs to a server In Cleura Cloud, we do not pass external networks to the compute nodes. This means that you, as a user, can not directly attach a server to the public network. In order to provide connectivity to the public network (for IPv4), you need to use floating IPs. A floating IP is created in the public subnet, and is mapped to the specific network port. All traffic comes through a virtual router. For some scenarios, you might need to have more than one public IP assigned to a server. But in case of 1-to-1 NAT (which is how the floating IP is implemented under the hood) you can not assign more than one external IP to the internal one. And adding a new port to the VM is also not an option, since this would result in asymmetric routing, as replies will go through the first interface for which a default route is set. Instead, you must first configure an additional private (\u201cfixed\u201d) IP address for your port, then associate a public (\u201cfloating\u201d) IP address to map to it. Add an extra IP to the port Assume you already have a network port inside your private network: $ openstack port show 51dae637-ad79-4ba9-9e41-78e5e0f3332c -c fixed_ips +-----------+--------------------------------------------------------------------------+ | Field | Value | +-----------+--------------------------------------------------------------------------+ | fixed_ips | ip_address='10.2.0.58', subnet_id='5efeae9f-06b8-41a5-987f-085e8c7113a6' | +-----------+--------------------------------------------------------------------------+ And you also have a floating IP associated with it: $ openstack floating ip list -c ID -c \"Floating IP Address\" -c \"Fixed IP Address\" -c Port +--------------------------------------+---------------------+------------------+--------------------------------------+ | ID | Floating IP Address | Fixed IP Address | Port | +--------------------------------------+---------------------+------------------+--------------------------------------+ | 989f8a96-4ab4-4190-83e4-25b71d309ea9 | 192.0.2.169 | 10.2.0.58 | 51dae637-ad79-4ba9-9e41-78e5e0f3332c | | c45a5eaf-2f3a-4679-89fe-266a5cbe840a | 198.51.100.12 | None | None | +--------------------------------------+---------------------+------------------+--------------------------------------+ Then what you need to do, is to add extra IP address to your existing port: $ openstack port set --fixed-ip subnet=5efeae9f-06b8-41a5-987f-085e8c7113a6 51dae637-ad79-4ba9-9e41-78e5e0f3332c You can then confirm that the port does have two entries in its fixed_ips list: $ openstack port show 51dae637-ad79-4ba9-9e41-78e5e0f3332c -c fixed_ips +-----------+---------------------------------------------------------------------------+ | Field | Value | +-----------+---------------------------------------------------------------------------+ | fixed_ips | ip_address='10.2.0.228', subnet_id='5efeae9f-06b8-41a5-987f-085e8c7113a6' | | | ip_address='10.2.0.58', subnet_id='5efeae9f-06b8-41a5-987f-085e8c7113a6' | +-----------+---------------------------------------------------------------------------+ Don\u2019t forget to configure new IP as an alias to the interface inside your VM! When you have an IP address on your port that is not yet assigned to any floating IP, you can assign it to the new floating IP. Proceed with: $ openstack floating ip set c45a5eaf-2f3a-4679-89fe-266a5cbe840a --port 51dae637-ad79-4ba9-9e41-78e5e0f3332c --fixed-ip-address 10.2.0.228 Then, list the floating (public) IP addresses, together with their fixed (private) counterparts: $ openstack floating ip list -c ID -c \"Floating IP Address\" -c \"Fixed IP Address\" -c Port +--------------------------------------+---------------------+------------------+--------------------------------------+ | ID | Floating IP Address | Fixed IP Address | Port | +--------------------------------------+---------------------+------------------+--------------------------------------+ | 989f8a96-4ab4-4190-83e4-25b71d309ea9 | 192.0.2.169 | 10.2.0.58 | 51dae637-ad79-4ba9-9e41-78e5e0f3332c | | c45a5eaf-2f3a-4679-89fe-266a5cbe840a | 198.51.100.12 | 10.2.0.228 | 51dae637-ad79-4ba9-9e41-78e5e0f3332c | +--------------------------------------+---------------------+------------------+--------------------------------------+ Now your server is accessible through two different public IP addresses.","title":"Assigning multiple public (floating) IPs to a server"},{"location":"howto/openstack/neutron/multiple-public-ips/#assigning-multiple-public-floating-ips-to-a-server","text":"In Cleura Cloud, we do not pass external networks to the compute nodes. This means that you, as a user, can not directly attach a server to the public network. In order to provide connectivity to the public network (for IPv4), you need to use floating IPs. A floating IP is created in the public subnet, and is mapped to the specific network port. All traffic comes through a virtual router. For some scenarios, you might need to have more than one public IP assigned to a server. But in case of 1-to-1 NAT (which is how the floating IP is implemented under the hood) you can not assign more than one external IP to the internal one. And adding a new port to the VM is also not an option, since this would result in asymmetric routing, as replies will go through the first interface for which a default route is set. Instead, you must first configure an additional private (\u201cfixed\u201d) IP address for your port, then associate a public (\u201cfloating\u201d) IP address to map to it.","title":"Assigning multiple public (floating) IPs to a server"},{"location":"howto/openstack/neutron/multiple-public-ips/#add-an-extra-ip-to-the-port","text":"Assume you already have a network port inside your private network: $ openstack port show 51dae637-ad79-4ba9-9e41-78e5e0f3332c -c fixed_ips +-----------+--------------------------------------------------------------------------+ | Field | Value | +-----------+--------------------------------------------------------------------------+ | fixed_ips | ip_address='10.2.0.58', subnet_id='5efeae9f-06b8-41a5-987f-085e8c7113a6' | +-----------+--------------------------------------------------------------------------+ And you also have a floating IP associated with it: $ openstack floating ip list -c ID -c \"Floating IP Address\" -c \"Fixed IP Address\" -c Port +--------------------------------------+---------------------+------------------+--------------------------------------+ | ID | Floating IP Address | Fixed IP Address | Port | +--------------------------------------+---------------------+------------------+--------------------------------------+ | 989f8a96-4ab4-4190-83e4-25b71d309ea9 | 192.0.2.169 | 10.2.0.58 | 51dae637-ad79-4ba9-9e41-78e5e0f3332c | | c45a5eaf-2f3a-4679-89fe-266a5cbe840a | 198.51.100.12 | None | None | +--------------------------------------+---------------------+------------------+--------------------------------------+ Then what you need to do, is to add extra IP address to your existing port: $ openstack port set --fixed-ip subnet=5efeae9f-06b8-41a5-987f-085e8c7113a6 51dae637-ad79-4ba9-9e41-78e5e0f3332c You can then confirm that the port does have two entries in its fixed_ips list: $ openstack port show 51dae637-ad79-4ba9-9e41-78e5e0f3332c -c fixed_ips +-----------+---------------------------------------------------------------------------+ | Field | Value | +-----------+---------------------------------------------------------------------------+ | fixed_ips | ip_address='10.2.0.228', subnet_id='5efeae9f-06b8-41a5-987f-085e8c7113a6' | | | ip_address='10.2.0.58', subnet_id='5efeae9f-06b8-41a5-987f-085e8c7113a6' | +-----------+---------------------------------------------------------------------------+ Don\u2019t forget to configure new IP as an alias to the interface inside your VM! When you have an IP address on your port that is not yet assigned to any floating IP, you can assign it to the new floating IP. Proceed with: $ openstack floating ip set c45a5eaf-2f3a-4679-89fe-266a5cbe840a --port 51dae637-ad79-4ba9-9e41-78e5e0f3332c --fixed-ip-address 10.2.0.228 Then, list the floating (public) IP addresses, together with their fixed (private) counterparts: $ openstack floating ip list -c ID -c \"Floating IP Address\" -c \"Fixed IP Address\" -c Port +--------------------------------------+---------------------+------------------+--------------------------------------+ | ID | Floating IP Address | Fixed IP Address | Port | +--------------------------------------+---------------------+------------------+--------------------------------------+ | 989f8a96-4ab4-4190-83e4-25b71d309ea9 | 192.0.2.169 | 10.2.0.58 | 51dae637-ad79-4ba9-9e41-78e5e0f3332c | | c45a5eaf-2f3a-4679-89fe-266a5cbe840a | 198.51.100.12 | 10.2.0.228 | 51dae637-ad79-4ba9-9e41-78e5e0f3332c | +--------------------------------------+---------------------+------------------+--------------------------------------+ Now your server is accessible through two different public IP addresses.","title":"Add an extra IP to the port"},{"location":"howto/openstack/neutron/new-network/","text":"Creating new networks Before creating a server in Cleura Cloud, you need at least one network to make the new server a member of. Since you may have more than one network per region, let us now walk through creating a new network using the Cleura Cloud Management Panel, or using the OpenStack CLI. Prerequisites Whether you choose to work from the Cleura Cloud Management Panel or with the OpenStack CLI, you need to have an account in Cleura Cloud. Additionally, to use the OpenStack CLI make sure to enable it first . Creating a network To create a network from the Cleura Cloud Management Panel, fire up your favorite web browser, navigate to the Cleura Cloud start page, and login into your Cleura Cloud account. On the other hand, if you prefer to work with OpenStack CLI, please do not forget to source the RC file first. Cleura Cloud Management Panel OpenStack CLI On the top right-hand side of the Cleura Cloud Management Panel, click the Create button. A new pane will slide into view from the right-hand side of the browser window, titled Create . You will notice several rounded boxes prominently displayed on that pane, each for defining, configuring, and instantiating a different Cleura Cloud object. Go ahead and click the Network box. A new pane titled Create Network will slide over. At the top, type in a name and select one of the available regions for the new network. Start by creating a new network, named nordostbahnhof : openstack network create nordostbahnhof By issuing the command above, you immediately get information regarding the new network: +---------------------------+--------------------------------------+ | Field | Value | +---------------------------+--------------------------------------+ | admin_state_up | UP | | availability_zone_hints | | | availability_zones | | | created_at | 2022-10-30T14:31:49Z | | description | | | dns_domain | None | | id | 201d458b-9b47-4408-9736-980bec77d405 | | ipv4_address_scope | None | | ipv6_address_scope | None | | is_default | False | | is_vlan_transparent | None | | mtu | 1500 | | name | nordostbahnhof | | port_security_enabled | True | | project_id | dfc700467396428bacba4376e72cc3e9 | | provider:network_type | None | | provider:physical_network | None | | provider:segmentation_id | None | | qos_policy_id | None | | revision_number | 1 | | router:external | Internal | | segments | None | | shared | False | | status | ACTIVE | | subnets | | | tags | | | updated_at | 2022-10-30T14:31:50Z | +---------------------------+--------------------------------------+ Adding a subnet and a router Creating a new network does not necessarily mean it has all the features you most likely would expect. Unless you work from the Cleura Cloud Management Panel, where almost every component is activated for you with a few clicks here and there, when you use the OpenStack CLI there is some extra work you need to do before you get a network you would characterize as useful. Cleura Cloud Management Panel OpenStack CLI Expand the Advanced Options section below, make sure Port Security is enabled, and leave the MTU parameter blank. You probably want a full-featured network for your cloud servers, so please activate the Create a complete network containing a subnet and a router option. You will notice that a network address in CIDR notation is pre-configured for your network. You also get a couple of DNS servers, a Gateway, and a DHCP server. Scroll down a little bit if you have to. Assuming you want your cloud servers to reach hosts on the Internet, for the External network parameter make sure you select ext-net . Then, click the green Create button to initialize the new network. In a few seconds, the new network will be readily available. You now have to create a subnet for the new network. Let us call this subnet nordostbahnhof-subnet : openstack subnet create nordostbahnhof-subnet \\ --network nordostbahnhof --subnet-range 10 .20.30.0/24 Again, you get detailed information regarding the new subnet: +----------------------+--------------------------------------+ | Field | Value | +----------------------+--------------------------------------+ | allocation_pools | 10.20.30.2-10.20.30.254 | | cidr | 10.20.30.0/24 | | created_at | 2022-10-30T14:47:40Z | | description | | | dns_nameservers | | | dns_publish_fixed_ip | None | | enable_dhcp | True | | gateway_ip | 10.20.30.1 | | host_routes | | | id | 1b0822b3-62e8-4b40-92e8-8544c72d4c15 | | ip_version | 4 | | ipv6_address_mode | None | | ipv6_ra_mode | None | | name | nordostbahnhof-subnet | | network_id | 201d458b-9b47-4408-9736-980bec77d405 | | project_id | dfc700467396428bacba4376e72cc3e9 | | revision_number | 0 | | segment_id | None | | service_types | | | subnetpool_id | None | | tags | | | updated_at | 2022-10-30T14:47:40Z | +----------------------+--------------------------------------+ If you want servers connected to the nordostbahnhof network to have Internet access, you need a router in front of the network. Following our unofficial naming convention, go ahead and create a new router called nordostbahnhof-router : openstack router create nordostbahnhof-router As expected, you will see lots of information regarding the new router: +-------------------------+--------------------------------------+ | Field | Value | +-------------------------+--------------------------------------+ | admin_state_up | UP | | availability_zone_hints | | | availability_zones | | | created_at | 2022-10-30T15:36:26Z | | description | | | enable_ndp_proxy | None | | external_gateway_info | null | | flavor_id | None | | ha | True | | id | 566de991-fc0e-4f85-b6c4-5c87694781f7 | | name | nordostbahnhof-router | | project_id | dfc700467396428bacba4376e72cc3e9 | | revision_number | 1 | | routes | | | status | ACTIVE | | tags | | | tenant_id | dfc700467396428bacba4376e72cc3e9 | | updated_at | 2022-10-30T15:36:26Z | +-------------------------+--------------------------------------+ You want the nordostbahnhof-router connected to the external network. The name of this network is ext-net : openstack router set nordostbahnhof-router --external-gateway ext-net Please note that if the command above is successful, you will get no output on your terminal. There is one last step to take, and that is to connect router nordostbahnhof-router to the subnet nordostbahnhof-subnet of network nordostbahnhof : openstack router add subnet nordostbahnhof-router nordostbahnhof-subnet Again, if the command above is successful, you will get no output. Listing networks and getting information At any time, you may connect to the Cleura Cloud Management Panel, list all networks you have already created, and get detailed information for any of these networks. Alternatively, you may get all that information using the OpenStack CLI. Cleura Cloud Management Panel OpenStack CLI You may see all defined networks, in all supported regions, by selecting Networking > Networks (see the left-hand side pane on the Cleura Cloud Management Panel). For more information regarding a specific network, click the corresponding three-dot icon (right-hand side) and select View details . Then, you can glance over all the details regarding the selected network\u2019s ports, subnets, and routers. To list all available networks in a specific region, just type: openstack network list You can always ask for more specific results. For instance, to see all internal networks only, type the following: openstack network list --internal You can also get detailed information about a specific network: openstack network show nordostbahnhof At any time, type openstack network list --help or openstack network show --help to see how to get information regarding networks, and what specific pieces of information you can have.","title":"Creating new networks"},{"location":"howto/openstack/neutron/new-network/#creating-new-networks","text":"Before creating a server in Cleura Cloud, you need at least one network to make the new server a member of. Since you may have more than one network per region, let us now walk through creating a new network using the Cleura Cloud Management Panel, or using the OpenStack CLI.","title":"Creating new networks"},{"location":"howto/openstack/neutron/new-network/#prerequisites","text":"Whether you choose to work from the Cleura Cloud Management Panel or with the OpenStack CLI, you need to have an account in Cleura Cloud. Additionally, to use the OpenStack CLI make sure to enable it first .","title":"Prerequisites"},{"location":"howto/openstack/neutron/new-network/#creating-a-network","text":"To create a network from the Cleura Cloud Management Panel, fire up your favorite web browser, navigate to the Cleura Cloud start page, and login into your Cleura Cloud account. On the other hand, if you prefer to work with OpenStack CLI, please do not forget to source the RC file first. Cleura Cloud Management Panel OpenStack CLI On the top right-hand side of the Cleura Cloud Management Panel, click the Create button. A new pane will slide into view from the right-hand side of the browser window, titled Create . You will notice several rounded boxes prominently displayed on that pane, each for defining, configuring, and instantiating a different Cleura Cloud object. Go ahead and click the Network box. A new pane titled Create Network will slide over. At the top, type in a name and select one of the available regions for the new network. Start by creating a new network, named nordostbahnhof : openstack network create nordostbahnhof By issuing the command above, you immediately get information regarding the new network: +---------------------------+--------------------------------------+ | Field | Value | +---------------------------+--------------------------------------+ | admin_state_up | UP | | availability_zone_hints | | | availability_zones | | | created_at | 2022-10-30T14:31:49Z | | description | | | dns_domain | None | | id | 201d458b-9b47-4408-9736-980bec77d405 | | ipv4_address_scope | None | | ipv6_address_scope | None | | is_default | False | | is_vlan_transparent | None | | mtu | 1500 | | name | nordostbahnhof | | port_security_enabled | True | | project_id | dfc700467396428bacba4376e72cc3e9 | | provider:network_type | None | | provider:physical_network | None | | provider:segmentation_id | None | | qos_policy_id | None | | revision_number | 1 | | router:external | Internal | | segments | None | | shared | False | | status | ACTIVE | | subnets | | | tags | | | updated_at | 2022-10-30T14:31:50Z | +---------------------------+--------------------------------------+","title":"Creating a network"},{"location":"howto/openstack/neutron/new-network/#adding-a-subnet-and-a-router","text":"Creating a new network does not necessarily mean it has all the features you most likely would expect. Unless you work from the Cleura Cloud Management Panel, where almost every component is activated for you with a few clicks here and there, when you use the OpenStack CLI there is some extra work you need to do before you get a network you would characterize as useful. Cleura Cloud Management Panel OpenStack CLI Expand the Advanced Options section below, make sure Port Security is enabled, and leave the MTU parameter blank. You probably want a full-featured network for your cloud servers, so please activate the Create a complete network containing a subnet and a router option. You will notice that a network address in CIDR notation is pre-configured for your network. You also get a couple of DNS servers, a Gateway, and a DHCP server. Scroll down a little bit if you have to. Assuming you want your cloud servers to reach hosts on the Internet, for the External network parameter make sure you select ext-net . Then, click the green Create button to initialize the new network. In a few seconds, the new network will be readily available. You now have to create a subnet for the new network. Let us call this subnet nordostbahnhof-subnet : openstack subnet create nordostbahnhof-subnet \\ --network nordostbahnhof --subnet-range 10 .20.30.0/24 Again, you get detailed information regarding the new subnet: +----------------------+--------------------------------------+ | Field | Value | +----------------------+--------------------------------------+ | allocation_pools | 10.20.30.2-10.20.30.254 | | cidr | 10.20.30.0/24 | | created_at | 2022-10-30T14:47:40Z | | description | | | dns_nameservers | | | dns_publish_fixed_ip | None | | enable_dhcp | True | | gateway_ip | 10.20.30.1 | | host_routes | | | id | 1b0822b3-62e8-4b40-92e8-8544c72d4c15 | | ip_version | 4 | | ipv6_address_mode | None | | ipv6_ra_mode | None | | name | nordostbahnhof-subnet | | network_id | 201d458b-9b47-4408-9736-980bec77d405 | | project_id | dfc700467396428bacba4376e72cc3e9 | | revision_number | 0 | | segment_id | None | | service_types | | | subnetpool_id | None | | tags | | | updated_at | 2022-10-30T14:47:40Z | +----------------------+--------------------------------------+ If you want servers connected to the nordostbahnhof network to have Internet access, you need a router in front of the network. Following our unofficial naming convention, go ahead and create a new router called nordostbahnhof-router : openstack router create nordostbahnhof-router As expected, you will see lots of information regarding the new router: +-------------------------+--------------------------------------+ | Field | Value | +-------------------------+--------------------------------------+ | admin_state_up | UP | | availability_zone_hints | | | availability_zones | | | created_at | 2022-10-30T15:36:26Z | | description | | | enable_ndp_proxy | None | | external_gateway_info | null | | flavor_id | None | | ha | True | | id | 566de991-fc0e-4f85-b6c4-5c87694781f7 | | name | nordostbahnhof-router | | project_id | dfc700467396428bacba4376e72cc3e9 | | revision_number | 1 | | routes | | | status | ACTIVE | | tags | | | tenant_id | dfc700467396428bacba4376e72cc3e9 | | updated_at | 2022-10-30T15:36:26Z | +-------------------------+--------------------------------------+ You want the nordostbahnhof-router connected to the external network. The name of this network is ext-net : openstack router set nordostbahnhof-router --external-gateway ext-net Please note that if the command above is successful, you will get no output on your terminal. There is one last step to take, and that is to connect router nordostbahnhof-router to the subnet nordostbahnhof-subnet of network nordostbahnhof : openstack router add subnet nordostbahnhof-router nordostbahnhof-subnet Again, if the command above is successful, you will get no output.","title":"Adding a subnet and a router"},{"location":"howto/openstack/neutron/new-network/#listing-networks-and-getting-information","text":"At any time, you may connect to the Cleura Cloud Management Panel, list all networks you have already created, and get detailed information for any of these networks. Alternatively, you may get all that information using the OpenStack CLI. Cleura Cloud Management Panel OpenStack CLI You may see all defined networks, in all supported regions, by selecting Networking > Networks (see the left-hand side pane on the Cleura Cloud Management Panel). For more information regarding a specific network, click the corresponding three-dot icon (right-hand side) and select View details . Then, you can glance over all the details regarding the selected network\u2019s ports, subnets, and routers. To list all available networks in a specific region, just type: openstack network list You can always ask for more specific results. For instance, to see all internal networks only, type the following: openstack network list --internal You can also get detailed information about a specific network: openstack network show nordostbahnhof At any time, type openstack network list --help or openstack network show --help to see how to get information regarding networks, and what specific pieces of information you can have.","title":"Listing networks and getting information"},{"location":"howto/openstack/neutron/vpnaas/","text":"Creating a VPN connection between regions Thanks to the Openstack Neutron VPN as a Service (VPNaaS) feature, you can bridge two different regions via a site-to-site IPSec VPN connection. This is made possible without setting up and configuring a virtual machine in any one of the regions. On the contrary, you can quickly establish such a connection using the Cleura Cloud Management Panel or the OpenStack CLI. Let us demonstrate the process following both approaches. Prerequisites Whether you choose to work from the Cleura Cloud Management Panel or with the OpenStack CLI, you need to have an account in Cleura Cloud. If you prefer to work with the OpenStack CLI , then in addition to the Python openstackclient module, you need to install the Python neutronclient module also. Use either the package manager of your operating system or pip : Debian/Ubuntu Mac OS X with Homebrew Python Package apt install python3-neutronclient This Python module is unavailable via brew , but you can install it via pip . pip install python-neutronclient Creating a VPN connection between two regions To create and establish such a connection from the Cleura Cloud Management Panel, fire up your favorite web browser, navigate to the Cleura Cloud Management Panel start page, and log into your Cleura Cloud account. Should you decide to follow the OpenStack CLI route instead, please make sure you have the appropriate RC file for each region involved. Cleura Cloud Management Panel OpenStack CLI On the top right-hand side of the Cleura Cloud Management Panel, click the Create button. A vertical pane titled Create will slide into view from the right-hand side of the browser window. You will notice several rounded boxes, each one for defining, configuring, and instantiating a different Cleura Cloud object. Go ahead and click the VPN box. A new pane titled Create a VPN Service will slide over. Between the two boxes, click the one titled Quick (Guided) Connect . Type in a name for the new site-to-site VPN connection. Select a region, project, and network for each of the two data centers involved. Look at the pre-shared key and, optionally, expand the Advanced Options section to see all presets. You do not have to change anything there. When you are ready, click the green Create button. The VPN connection between the two regions will be established in a few seconds. First, you need to have the RC files of the two regions you will be connecting. In the example that follows, we demonstrate establishing a site-to-site connection between regions fra1 and kna1 . This means that, while following through, before working in fra1 you need to source the RC file for fra1 , and before working in kna1 you need to source the RC file for kna1 . It helps to imagine the site-to-site connection schematically, with fra1 being on the left side and kna1 being on the right side of the connection. That is why we interchange the terms fra1 , left and kna1 , right . You also have to decide which subnets from either side you will connect. Additionally, you need to know the respective CIDR notations and routers. In the examples that follow, on the left side we have subnet subnet-fra1 with CIDR 10.15.25.0/24 and router router-fra1 , and on the right side we have subnet subnet-kna1 with CIDR 10.15.20.0/24 and router router-kna1 . For convenience, we have set the shell variables SUBNET_FRA1 and SUBNET_KNA1 : SUBNET_FRA1 = \"10.15.25.0/24\" SUBNET_KNA1 = \"10.15.20.0/24\" Prepare the left side (region fra1 ) Begin by creating a new IKE policy: openstack vpn ike policy create ike-pol-fra1 +-------------------------------+--------------------------------------+ | Field | Value | +-------------------------------+--------------------------------------+ | Authentication Algorithm | sha1 | | Description | | | Encryption Algorithm | aes-128 | | ID | 5782b141-afcc-4327-9ac5-b8cd2e110c6a | | IKE Version | v1 | | Lifetime | {'units': 'seconds', 'value': 3600} | | Name | ike-pol-fra1 | | Perfect Forward Secrecy (PFS) | group5 | | Phase1 Negotiation Mode | main | | Project | dfc700467396428bacba4376e72cc3e9 | | project_id | dfc700467396428bacba4376e72cc3e9 | +-------------------------------+--------------------------------------+ Then, create a new IPSec policy: openstack vpn ipsec policy create ipsec-pol-fra1 +-------------------------------+--------------------------------------+ | Field | Value | +-------------------------------+--------------------------------------+ | Authentication Algorithm | sha1 | | Description | | | Encapsulation Mode | tunnel | | Encryption Algorithm | aes-128 | | ID | 15ec761f-1642-49b6-b5a2-e43624c5752d | | Lifetime | {'units': 'seconds', 'value': 3600} | | Name | ipsec-pol-fra1 | | Perfect Forward Secrecy (PFS) | group5 | | Project | dfc700467396428bacba4376e72cc3e9 | | Transform Protocol | esp | | project_id | dfc700467396428bacba4376e72cc3e9 | +-------------------------------+--------------------------------------+ You are ready to create a new VPN service: openstack vpn service create --router router-fra1 vpn-service-fra1 +----------------+--------------------------------------+ | Field | Value | +----------------+--------------------------------------+ | Description | | | Flavor | None | | ID | d74d51f0-182d-4d88-952a-1d593ce696fd | | Name | vpn-service-fra1 | | Project | dfc700467396428bacba4376e72cc3e9 | | Router | 62f885d8-6b13-4161-89d1-003c4fafec55 | | State | True | | Status | PENDING_CREATE | | Subnet | None | | external_v4_ip | 198.51.100.50 | | external_v6_ip | 2a03:b000:701:5:f816:3eff:feb5:be0e | | project_id | dfc700467396428bacba4376e72cc3e9 | +----------------+--------------------------------------+ Notice in the command output that the Status is PENDING_CREATE . This is expected. Also, jot down the value of the external_v4_ip parameter. Better yet, set this value to a new variable, EXT_IP_FRA1 , for you will soon need it: EXT_IP_FRA1 = \"198.51.100.50\" The site-to-site connection you are about to create needs two end-point groups on the left, and two end-point groups on the right. More specifically, on either side of the connection, there should be one end-point group for the local subnet and one end-point group for the peer (remote) subnet. You are now on the left side of the connection (region fra1 ), so begin with the left local end-point group\u2026 openstack vpn endpoint group create \\ --type subnet --value subnet-fra1 local-epg-fra1 +-------------+------------------------------------------+ | Field | Value | +-------------+------------------------------------------+ | Description | | | Endpoints | ['df6fb6ca-4751-4b74-8b3e-5fbda0117cea'] | | ID | 51895e0e-fa3a-43d3-8037-5eea073fb77f | | Name | local-epg-fra1 | | Project | dfc700467396428bacba4376e72cc3e9 | | Type | subnet | | project_id | dfc700467396428bacba4376e72cc3e9 | +-------------+------------------------------------------+ \u2026and then move on to creating the left peer end-point group: openstack vpn endpoint group create \\ --type cidr --value $SUBNET_KNA1 peer-epg-fra1 +-------------+--------------------------------------+ | Field | Value | +-------------+--------------------------------------+ | Description | | | Endpoints | ['10.15.20.0/24'] | | ID | a96bb9ef-d0ec-4174-93ae-a8e655910f94 | | Name | peer-epg-fra1 | | Project | dfc700467396428bacba4376e72cc3e9 | | Type | cidr | | project_id | dfc700467396428bacba4376e72cc3e9 | +-------------+--------------------------------------+ Prepare the right side (region kna1 ) Before establishing a site-to-site VPN connection between the two regions, you must make similar preparations on the right side of the connection (region kna1 ). You should adjust all commands you entered above and execute them on the right side. For your convenience, these are all the adjusted commands with the respective outputs: Create a new IKE policy: openstack vpn ike policy create ike-pol-kna1 +-------------------------------+--------------------------------------+ | Field | Value | +-------------------------------+--------------------------------------+ | Authentication Algorithm | sha1 | | Description | | | Encryption Algorithm | aes-128 | | ID | 6af4f52c-6522-483d-bb70-b144657489f3 | | IKE Version | v1 | | Lifetime | {'units': 'seconds', 'value': 3600} | | Name | ike-pol-kna1 | | Perfect Forward Secrecy (PFS) | group5 | | Phase1 Negotiation Mode | main | | Project | 94109c764a754e24ac0f6b01aef82359 | | project_id | 94109c764a754e24ac0f6b01aef82359 | +-------------------------------+--------------------------------------+ Create a new IPSec policy: openstack vpn ipsec policy create ipsec-pol-kna1 +-------------------------------+--------------------------------------+ | Field | Value | +-------------------------------+--------------------------------------+ | Authentication Algorithm | sha1 | | Description | | | Encapsulation Mode | tunnel | | Encryption Algorithm | aes-128 | | ID | 8f9c2219-a931-46eb-b3f5-22d76cbc89d0 | | Lifetime | {'units': 'seconds', 'value': 3600} | | Name | ipsec-pol-kna1 | | Perfect Forward Secrecy (PFS) | group5 | | Project | 94109c764a754e24ac0f6b01aef82359 | | Transform Protocol | esp | | project_id | 94109c764a754e24ac0f6b01aef82359 | +-------------------------------+--------------------------------------+ Create a new VPN service: openstack vpn service create --router router-kna1 vpn-service-kna1 +----------------+--------------------------------------+ | Field | Value | +----------------+--------------------------------------+ | Description | | | Flavor | None | | ID | bb1a307d-6f8f-4a0a-83db-7c705403485d | | Name | vpn-service-kna1 | | Project | 94109c764a754e24ac0f6b01aef82359 | | Router | 5ac45739-a379-4936-8b1b-67d10e017f4d | | State | True | | Status | PENDING_CREATE | | Subnet | None | | external_v4_ip | 203.0.113.101 | | external_v6_ip | 2a00:16d8:0:3b:f816:3eff:fe0e:2074 | | project_id | 94109c764a754e24ac0f6b01aef82359 | +----------------+--------------------------------------+ For convenience, set the value of parameter external_v4_ip to a shell variable: EXT_IP_KNA1 = \"203.0.113.101\" Create a local end-point group: openstack vpn endpoint group create \\ --type subnet --value subnet-kna1 local-epg-kna1 +-------------+------------------------------------------+ | Field | Value | +-------------+------------------------------------------+ | Description | | | Endpoints | ['421d8fd2-dd7f-4f7c-9a51-42ef4a866dd9'] | | ID | c1937c3d-77e7-4f2c-842d-70b5e10df9a8 | | Name | local-epg-kna1 | | Project | 94109c764a754e24ac0f6b01aef82359 | | Type | subnet | | project_id | 94109c764a754e24ac0f6b01aef82359 | +-------------+------------------------------------------+ Create a peer (remote) end-point group: openstack vpn endpoint group create \\ --type cidr --value $SUBNET_FRA1 peer-epg-kna1 +-------------+--------------------------------------+ | Field | Value | +-------------+--------------------------------------+ | Description | | | Endpoints | ['10.15.25.0/24'] | | ID | 2e627315-02f0-4d68-8683-14230b166060 | | Name | peer-epg-kna1 | | Project | 94109c764a754e24ac0f6b01aef82359 | | Type | cidr | | project_id | 94109c764a754e24ac0f6b01aef82359 | +-------------+--------------------------------------+ Instantiate a pre-shared key Before establishing a site-to-site IPSec VPN connection, you must have a randomly generated pre-shared key. You may use openssl for generating a random string and immediately set it to a shell variable: PRE_SHARED_KEY = $( openssl rand -hex 24 ) The above is just an example. The key should not necessarily be a hexadecimal string, nor do you have to use openssl . Another option would be to use the fine pwgen tool, for example like this: PRE_SHARED_KEY = $( pwgen 64 1 ) Establish a left-to-right connection (region fra1 ) To create a VPN connection from left to right, i.e., from region fra1 to region kna1 , issue the following command: openstack vpn ipsec site connection create \\ --vpnservice vpn-service-fra1 \\ --ikepolicy ike-pol-fra1 \\ --ipsecpolicy ipsec-pol-fra1 \\ --local-endpoint-group local-epg-fra1 \\ --peer-address $EXT_IP_KNA1 \\ --peer-id $EXT_IP_KNA1 \\ --peer-endpoint-group peer-epg-fra1 \\ --psk $PRE_SHARED_KEY \\ vpn-conn-to-kna1 +--------------------------+----------------------------------------------------+ | Field | Value | +--------------------------+----------------------------------------------------+ | Authentication Algorithm | psk | | Description | | | ID | 5f44be31-0588-4f33-883d-9e2d97be55e1 | | IKE Policy | 5782b141-afcc-4327-9ac5-b8cd2e110c6a | | IPSec Policy | 15ec761f-1642-49b6-b5a2-e43624c5752d | | Initiator | bi-directional | | Local Endpoint Group ID | 51895e0e-fa3a-43d3-8037-5eea073fb77f | | Local ID | | | MTU | 1500 | | Name | vpn-conn-to-kna1 | | Peer Address | 203.0.113.101 | | Peer CIDRs | | | Peer Endpoint Group ID | a96bb9ef-d0ec-4174-93ae-a8e655910f94 | | Peer ID | 203.0.113.101 | | Pre-shared Key | de12db260ee1b9c0b9e624d910c9a9dbddec13dc24d60332 | | Project | dfc700467396428bacba4376e72cc3e9 | | Route Mode | static | | State | True | | Status | PENDING_CREATE | | VPN Service | d74d51f0-182d-4d88-952a-1d593ce696fd | | dpd | {'action': 'hold', 'interval': 30, 'timeout': 120} | | project_id | dfc700467396428bacba4376e72cc3e9 | +--------------------------+----------------------------------------------------+ Establish a right-to-left connection (region kna1 ) Similarly, to create a VPN connection from right to left, i.e., from region kna1 to region fra1 , issue the following command: openstack vpn ipsec site connection create \\ --vpnservice vpn-service-kna1 \\ --ikepolicy ike-pol-kna1 \\ --ipsecpolicy ipsec-pol-kna1 \\ --local-endpoint-group local-epg-kna1 \\ --peer-address $EXT_IP_FRA1 \\ --peer-id $EXT_IP_FRA1 \\ --peer-endpoint-group peer-epg-kna1 \\ --psk $PRE_SHARED_KEY \\ vpn-conn-to-fra1 +--------------------------+----------------------------------------------------+ | Field | Value | +--------------------------+----------------------------------------------------+ | Authentication Algorithm | psk | | Description | | | ID | 7705afc7-d0ff-444a-9474-3614e21d2399 | | IKE Policy | 6af4f52c-6522-483d-bb70-b144657489f3 | | IPSec Policy | 8f9c2219-a931-46eb-b3f5-22d76cbc89d0 | | Initiator | bi-directional | | Local Endpoint Group ID | c1937c3d-77e7-4f2c-842d-70b5e10df9a8 | | Local ID | | | MTU | 1500 | | Name | vpn-conn-to-fra1 | | Peer Address | 198.51.100.50 | | Peer CIDRs | | | Peer Endpoint Group ID | 2e627315-02f0-4d68-8683-14230b166060 | | Peer ID | 198.51.100.50 | | Pre-shared Key | de12db260ee1b9c0b9e624d910c9a9dbddec13dc24d60332 | | Project | 94109c764a754e24ac0f6b01aef82359 | | Route Mode | static | | State | True | | Status | PENDING_CREATE | | VPN Service | bb1a307d-6f8f-4a0a-83db-7c705403485d | | dpd | {'action': 'hold', 'interval': 30, 'timeout': 120} | | project_id | 94109c764a754e24ac0f6b01aef82359 | +--------------------------+----------------------------------------------------+ Viewing VPN connections and getting details No matter if you use the Cleura Cloud Management Panel or the OpenStack CLI, you may at any time list all VPN connections and get relevant details. Cleura Cloud Management Panel OpenStack CLI In the vertical pane on the left-hand side of the Cleura Cloud Management Panel, expand the Networking section and then the VPN Services subsection. From the available options, click VPN Services again. You will see two VPN connections in the main pane, each from one region to the other. For more information regarding a specific connection, click the corresponding three-dot icon (right-hand side) and select View details . Then, you can glance over all the details regarding, for example, the connection status and public IP address. You can list all IPSec VPN connections working from any of the two regions involved. See, for example, the view from fra1 : openstack vpn ipsec site connection list +--------------------------+------------------+---------------+--------------------------+--------+ | ID | Name | Peer Address | Authentication Algorithm | Status | +--------------------------+------------------+---------------+--------------------------+--------+ | 5f44be31-0588-4f33-883d- | vpn-conn-to-kna1 | 203.0.113.101 | psk | ACTIVE | | 9e2d97be55e1 | | | | | +--------------------------+------------------+---------------+--------------------------+--------+ If you want more information regarding a specific connection, type something like this: openstack vpn ipsec site connection show vpn-conn-to-kna1 +--------------------------+----------------------------------------------------+ | Field | Value | +--------------------------+----------------------------------------------------+ | Authentication Algorithm | psk | | Description | | | ID | 5f44be31-0588-4f33-883d-9e2d97be55e1 | | IKE Policy | 5782b141-afcc-4327-9ac5-b8cd2e110c6a | | IPSec Policy | 15ec761f-1642-49b6-b5a2-e43624c5752d | | Initiator | bi-directional | | Local Endpoint Group ID | 51895e0e-fa3a-43d3-8037-5eea073fb77f | | Local ID | | | MTU | 1500 | | Name | vpn-conn-to-kna1 | | Peer Address | 203.0.113.101 | | Peer CIDRs | | | Peer Endpoint Group ID | a96bb9ef-d0ec-4174-93ae-a8e655910f94 | | Peer ID | 203.0.113.101 | | Pre-shared Key | de12db260ee1b9c0b9e624d910c9a9dbddec13dc24d60332 | | Project | dfc700467396428bacba4376e72cc3e9 | | Route Mode | static | | State | True | | Status | ACTIVE | | VPN Service | d74d51f0-182d-4d88-952a-1d593ce696fd | | dpd | {'action': 'hold', 'interval': 30, 'timeout': 120} | | project_id | dfc700467396428bacba4376e72cc3e9 | +--------------------------+----------------------------------------------------+ Testing the site-to-site VPN connection One way to test the VPN connection is to have two servers (e.g., server-fra1 and server-kna1 ), each on a different region (e.g., fra1 and kna1 respectively), ping each other using private IP addresses. With no VPN connection between the two regions, pinging should not be possible: ubuntu@server-fra1:~$ ping -c 3 10 .15.20.148 PING 10.15.20.148 (10.15.20.148) 56(84) bytes of data. --- 10.15.20.148 ping statistics --- 3 packets transmitted, 0 received, 100% packet loss, time 2050ms ubuntu@server-kna1:~$ ping -c 3 10 .15.25.58 PING 10.15.25.58 (10.15.25.58) 56(84) bytes of data. --- 10.15.25.58 ping statistics --- 3 packets transmitted, 0 received, 100% packet loss, time 2045ms On the other hand, with a VPN connection established between the two regions, pinging should be all possible: ubuntu@server-fra1:~$ ping -c 3 10 .15.20.148 PING 10.15.20.148 (10.15.20.148) 56(84) bytes of data. 64 bytes from 10.15.20.148: icmp_seq=1 ttl=62 time=32.8 ms 64 bytes from 10.15.20.148: icmp_seq=2 ttl=62 time=32.5 ms 64 bytes from 10.15.20.148: icmp_seq=3 ttl=62 time=32.6 ms --- 10.15.20.148 ping statistics --- 3 packets transmitted, 3 received, 0% packet loss, time 2003ms rtt min/avg/max/mdev = 32.544/32.624/32.761/0.096 ms ubuntu@server-kna1:~$ ping -c 3 10 .15.25.58 PING 10.15.25.58 (10.15.25.58) 56(84) bytes of data. 64 bytes from 10.15.25.58: icmp_seq=1 ttl=62 time=33.3 ms 64 bytes from 10.15.25.58: icmp_seq=2 ttl=62 time=32.5 ms 64 bytes from 10.15.25.58: icmp_seq=3 ttl=62 time=32.6 ms --- 10.15.25.58 ping statistics --- 3 packets transmitted, 3 received, 0% packet loss, time 2003ms rtt min/avg/max/mdev = 32.533/32.832/33.336/0.358 ms Disabling an active connection You may, at any time, disable an active site-to-site VPN connection. Cleura Cloud Management Panel OpenStack CLI Currently, there is no way to disable an active connection from the Cleura Cloud Management Panel. If you want to disable an active connection, please use the OpenStack CLI. All you have to do is get on either side of the connection and disable the VPN connection across the other side. Suppose you are on the left side of the connection (region fra1 ), and for whatever reason, you want to disable the site-to-site connection between left and right (regions fra1 and kna1 ). First, you might want to remember the name of the VPN connection to the right: openstack vpn ipsec site connection list +--------------------------+------------------+---------------+--------------------------+--------+ | ID | Name | Peer Address | Authentication Algorithm | Status | +--------------------------+------------------+---------------+--------------------------+--------+ | 5f44be31-0588-4f33-883d- | vpn-conn-to-kna1 | 203.0.113.101 | psk | ACTIVE | | 9e2d97be55e1 | | | | | +--------------------------+------------------+---------------+--------------------------+--------+ That would be vpn-conn-to-kna1 , and according to the command output above, it is active. To disable it, type the following: openstack vpn ipsec site connection set --disable vpn-conn-to-kna1 Check if it is really disabled: openstack vpn ipsec site connection show vpn-conn-to-kna1 -c Status +--------+-------+ | Field | Value | +--------+-------+ | Status | DOWN | +--------+-------+ It looks like it is disabled \u2014 or DOWN . You will probably have to wait several seconds before seeing a status change. If you are impatient, try something like this: watch \"openstack vpn ipsec site connection show vpn-conn-to-kna1 -c Status\" Hit CTRL+C as soon as you see the status change you expect. Now, get on the right side of the connection (region kna1 ), optionally look for the name of the VPN connection to the left (in our example, that would be vpn-conn-to-fra1 ), and check its status: openstack vpn ipsec site connection show vpn-conn-to-fra1 -c Status +--------+-------+ | Field | Value | +--------+-------+ | Status | DOWN | +--------+-------+ It turns out that this direction of the connection is also disabled. To test that a previously enabled site-to-site connection is now disabled, select a server from one region and try to ping a server in another region. Suppose, for example, that a now-disabled connection involved regions fra1 and kna1 , and that we have servers server-fra1 (in fra1 ) and server-kna1 (in kna1 ). With the VPN connection between the two regions now disabled, pinging should not be possible: ubuntu@server-fra1:~$ ping -c 3 10 .15.20.148 PING 10.15.20.148 (10.15.20.148) 56(84) bytes of data. --- 10.15.20.148 ping statistics --- 3 packets transmitted, 0 received, 100% packet loss, time 2055ms ubuntu@server-kna1:~$ ping -c 3 10 .15.25.58 PING 10.15.25.58 (10.15.25.58) 56(84) bytes of data. --- 10.15.25.58 ping statistics --- 3 packets transmitted, 0 received, 100% packet loss, time 2050ms Enabling an inactive connection You can easily enable an inactive site-to-site VPN connection. Cleura Cloud Management Panel OpenStack CLI Currently, there is no way to enable an inactive connection from the Cleura Cloud Management Panel. If you want to re-enable an inactive connection, please use the OpenStack CLI. Make sure you hop on the side where you initially disabled the connection. According to the example scenario we described in the previous section, that would be the left side (region fra1 ), and the name of the disabled connection would be vpn-conn-to-kna1 . Make sure the connection status is DOWN : openstack vpn ipsec site connection show vpn-conn-to-kna1 -c Status +--------+-------+ | Field | Value | +--------+-------+ | Status | DOWN | +--------+-------+ Note that if you issued a similar command from the right side of the connection (region kna1 ), you would also get a DOWN status. Being on the left side, all you have to do to enable the inactive connection is type the following: openstack vpn ipsec site connection set --enable vpn-conn-to-kna1 Check the connection status \u2014 it should be ACTIVE : openstack vpn ipsec site connection show vpn-conn-to-kna1 -c Status +--------+--------+ | Field | Value | +--------+--------+ | Status | ACTIVE | +--------+--------+ You get the same status by issuing a similar command from the right side. Again, since you may have to wait several seconds before seeing the status change you expect, try something like this: watch \"openstack vpn ipsec site connection show vpn-conn-to-kna1 -c Status\" Hit CTRL+C to stop watching. To test that a previously disabled site-to-site connection is now enabled, select a server from one region and try to ping a server in another region. Suppose, for example, that a re-enabled connection involves regions fra1 and kna1 , and that we have servers server-fra1 (in fra1 ) and server-kna1 (in kna1 ). With the VPN connection between the two regions now re-established, pinging should be possible: ubuntu@server-fra1:~$ ping -c 3 10 .15.20.148 PING 10.15.20.148 (10.15.20.148) 56(84) bytes of data. 64 bytes from 10.15.20.148: icmp_seq=1 ttl=62 time=32.6 ms 64 bytes from 10.15.20.148: icmp_seq=2 ttl=62 time=32.6 ms 64 bytes from 10.15.20.148: icmp_seq=3 ttl=62 time=32.7 ms --- 10.15.20.148 ping statistics --- 3 packets transmitted, 3 received, 0% packet loss, time 2003ms rtt min/avg/max/mdev = 32.619/32.634/32.662/0.019 ms ubuntu@server-kna1:~$ ping -c 3 10 .15.25.58 PING 10.15.25.58 (10.15.25.58) 56(84) bytes of data. 64 bytes from 10.15.25.58: icmp_seq=1 ttl=62 time=32.8 ms 64 bytes from 10.15.25.58: icmp_seq=2 ttl=62 time=32.6 ms 64 bytes from 10.15.25.58: icmp_seq=3 ttl=62 time=33.4 ms --- 10.15.25.58 ping statistics --- 3 packets transmitted, 3 received, 0% packet loss, time 2003ms rtt min/avg/max/mdev = 32.560/32.899/33.357/0.336 ms","title":"Creating a VPN connection between regions"},{"location":"howto/openstack/neutron/vpnaas/#creating-a-vpn-connection-between-regions","text":"Thanks to the Openstack Neutron VPN as a Service (VPNaaS) feature, you can bridge two different regions via a site-to-site IPSec VPN connection. This is made possible without setting up and configuring a virtual machine in any one of the regions. On the contrary, you can quickly establish such a connection using the Cleura Cloud Management Panel or the OpenStack CLI. Let us demonstrate the process following both approaches.","title":"Creating a VPN connection between regions"},{"location":"howto/openstack/neutron/vpnaas/#prerequisites","text":"Whether you choose to work from the Cleura Cloud Management Panel or with the OpenStack CLI, you need to have an account in Cleura Cloud. If you prefer to work with the OpenStack CLI , then in addition to the Python openstackclient module, you need to install the Python neutronclient module also. Use either the package manager of your operating system or pip : Debian/Ubuntu Mac OS X with Homebrew Python Package apt install python3-neutronclient This Python module is unavailable via brew , but you can install it via pip . pip install python-neutronclient","title":"Prerequisites"},{"location":"howto/openstack/neutron/vpnaas/#creating-a-vpn-connection-between-two-regions","text":"To create and establish such a connection from the Cleura Cloud Management Panel, fire up your favorite web browser, navigate to the Cleura Cloud Management Panel start page, and log into your Cleura Cloud account. Should you decide to follow the OpenStack CLI route instead, please make sure you have the appropriate RC file for each region involved. Cleura Cloud Management Panel OpenStack CLI On the top right-hand side of the Cleura Cloud Management Panel, click the Create button. A vertical pane titled Create will slide into view from the right-hand side of the browser window. You will notice several rounded boxes, each one for defining, configuring, and instantiating a different Cleura Cloud object. Go ahead and click the VPN box. A new pane titled Create a VPN Service will slide over. Between the two boxes, click the one titled Quick (Guided) Connect . Type in a name for the new site-to-site VPN connection. Select a region, project, and network for each of the two data centers involved. Look at the pre-shared key and, optionally, expand the Advanced Options section to see all presets. You do not have to change anything there. When you are ready, click the green Create button. The VPN connection between the two regions will be established in a few seconds. First, you need to have the RC files of the two regions you will be connecting. In the example that follows, we demonstrate establishing a site-to-site connection between regions fra1 and kna1 . This means that, while following through, before working in fra1 you need to source the RC file for fra1 , and before working in kna1 you need to source the RC file for kna1 . It helps to imagine the site-to-site connection schematically, with fra1 being on the left side and kna1 being on the right side of the connection. That is why we interchange the terms fra1 , left and kna1 , right . You also have to decide which subnets from either side you will connect. Additionally, you need to know the respective CIDR notations and routers. In the examples that follow, on the left side we have subnet subnet-fra1 with CIDR 10.15.25.0/24 and router router-fra1 , and on the right side we have subnet subnet-kna1 with CIDR 10.15.20.0/24 and router router-kna1 . For convenience, we have set the shell variables SUBNET_FRA1 and SUBNET_KNA1 : SUBNET_FRA1 = \"10.15.25.0/24\" SUBNET_KNA1 = \"10.15.20.0/24\"","title":"Creating a VPN connection between two regions"},{"location":"howto/openstack/neutron/vpnaas/#prepare-the-left-side-region-fra1","text":"Begin by creating a new IKE policy: openstack vpn ike policy create ike-pol-fra1 +-------------------------------+--------------------------------------+ | Field | Value | +-------------------------------+--------------------------------------+ | Authentication Algorithm | sha1 | | Description | | | Encryption Algorithm | aes-128 | | ID | 5782b141-afcc-4327-9ac5-b8cd2e110c6a | | IKE Version | v1 | | Lifetime | {'units': 'seconds', 'value': 3600} | | Name | ike-pol-fra1 | | Perfect Forward Secrecy (PFS) | group5 | | Phase1 Negotiation Mode | main | | Project | dfc700467396428bacba4376e72cc3e9 | | project_id | dfc700467396428bacba4376e72cc3e9 | +-------------------------------+--------------------------------------+ Then, create a new IPSec policy: openstack vpn ipsec policy create ipsec-pol-fra1 +-------------------------------+--------------------------------------+ | Field | Value | +-------------------------------+--------------------------------------+ | Authentication Algorithm | sha1 | | Description | | | Encapsulation Mode | tunnel | | Encryption Algorithm | aes-128 | | ID | 15ec761f-1642-49b6-b5a2-e43624c5752d | | Lifetime | {'units': 'seconds', 'value': 3600} | | Name | ipsec-pol-fra1 | | Perfect Forward Secrecy (PFS) | group5 | | Project | dfc700467396428bacba4376e72cc3e9 | | Transform Protocol | esp | | project_id | dfc700467396428bacba4376e72cc3e9 | +-------------------------------+--------------------------------------+ You are ready to create a new VPN service: openstack vpn service create --router router-fra1 vpn-service-fra1 +----------------+--------------------------------------+ | Field | Value | +----------------+--------------------------------------+ | Description | | | Flavor | None | | ID | d74d51f0-182d-4d88-952a-1d593ce696fd | | Name | vpn-service-fra1 | | Project | dfc700467396428bacba4376e72cc3e9 | | Router | 62f885d8-6b13-4161-89d1-003c4fafec55 | | State | True | | Status | PENDING_CREATE | | Subnet | None | | external_v4_ip | 198.51.100.50 | | external_v6_ip | 2a03:b000:701:5:f816:3eff:feb5:be0e | | project_id | dfc700467396428bacba4376e72cc3e9 | +----------------+--------------------------------------+ Notice in the command output that the Status is PENDING_CREATE . This is expected. Also, jot down the value of the external_v4_ip parameter. Better yet, set this value to a new variable, EXT_IP_FRA1 , for you will soon need it: EXT_IP_FRA1 = \"198.51.100.50\" The site-to-site connection you are about to create needs two end-point groups on the left, and two end-point groups on the right. More specifically, on either side of the connection, there should be one end-point group for the local subnet and one end-point group for the peer (remote) subnet. You are now on the left side of the connection (region fra1 ), so begin with the left local end-point group\u2026 openstack vpn endpoint group create \\ --type subnet --value subnet-fra1 local-epg-fra1 +-------------+------------------------------------------+ | Field | Value | +-------------+------------------------------------------+ | Description | | | Endpoints | ['df6fb6ca-4751-4b74-8b3e-5fbda0117cea'] | | ID | 51895e0e-fa3a-43d3-8037-5eea073fb77f | | Name | local-epg-fra1 | | Project | dfc700467396428bacba4376e72cc3e9 | | Type | subnet | | project_id | dfc700467396428bacba4376e72cc3e9 | +-------------+------------------------------------------+ \u2026and then move on to creating the left peer end-point group: openstack vpn endpoint group create \\ --type cidr --value $SUBNET_KNA1 peer-epg-fra1 +-------------+--------------------------------------+ | Field | Value | +-------------+--------------------------------------+ | Description | | | Endpoints | ['10.15.20.0/24'] | | ID | a96bb9ef-d0ec-4174-93ae-a8e655910f94 | | Name | peer-epg-fra1 | | Project | dfc700467396428bacba4376e72cc3e9 | | Type | cidr | | project_id | dfc700467396428bacba4376e72cc3e9 | +-------------+--------------------------------------+","title":"Prepare the left side (region fra1)"},{"location":"howto/openstack/neutron/vpnaas/#prepare-the-right-side-region-kna1","text":"Before establishing a site-to-site VPN connection between the two regions, you must make similar preparations on the right side of the connection (region kna1 ). You should adjust all commands you entered above and execute them on the right side. For your convenience, these are all the adjusted commands with the respective outputs: Create a new IKE policy: openstack vpn ike policy create ike-pol-kna1 +-------------------------------+--------------------------------------+ | Field | Value | +-------------------------------+--------------------------------------+ | Authentication Algorithm | sha1 | | Description | | | Encryption Algorithm | aes-128 | | ID | 6af4f52c-6522-483d-bb70-b144657489f3 | | IKE Version | v1 | | Lifetime | {'units': 'seconds', 'value': 3600} | | Name | ike-pol-kna1 | | Perfect Forward Secrecy (PFS) | group5 | | Phase1 Negotiation Mode | main | | Project | 94109c764a754e24ac0f6b01aef82359 | | project_id | 94109c764a754e24ac0f6b01aef82359 | +-------------------------------+--------------------------------------+ Create a new IPSec policy: openstack vpn ipsec policy create ipsec-pol-kna1 +-------------------------------+--------------------------------------+ | Field | Value | +-------------------------------+--------------------------------------+ | Authentication Algorithm | sha1 | | Description | | | Encapsulation Mode | tunnel | | Encryption Algorithm | aes-128 | | ID | 8f9c2219-a931-46eb-b3f5-22d76cbc89d0 | | Lifetime | {'units': 'seconds', 'value': 3600} | | Name | ipsec-pol-kna1 | | Perfect Forward Secrecy (PFS) | group5 | | Project | 94109c764a754e24ac0f6b01aef82359 | | Transform Protocol | esp | | project_id | 94109c764a754e24ac0f6b01aef82359 | +-------------------------------+--------------------------------------+ Create a new VPN service: openstack vpn service create --router router-kna1 vpn-service-kna1 +----------------+--------------------------------------+ | Field | Value | +----------------+--------------------------------------+ | Description | | | Flavor | None | | ID | bb1a307d-6f8f-4a0a-83db-7c705403485d | | Name | vpn-service-kna1 | | Project | 94109c764a754e24ac0f6b01aef82359 | | Router | 5ac45739-a379-4936-8b1b-67d10e017f4d | | State | True | | Status | PENDING_CREATE | | Subnet | None | | external_v4_ip | 203.0.113.101 | | external_v6_ip | 2a00:16d8:0:3b:f816:3eff:fe0e:2074 | | project_id | 94109c764a754e24ac0f6b01aef82359 | +----------------+--------------------------------------+ For convenience, set the value of parameter external_v4_ip to a shell variable: EXT_IP_KNA1 = \"203.0.113.101\" Create a local end-point group: openstack vpn endpoint group create \\ --type subnet --value subnet-kna1 local-epg-kna1 +-------------+------------------------------------------+ | Field | Value | +-------------+------------------------------------------+ | Description | | | Endpoints | ['421d8fd2-dd7f-4f7c-9a51-42ef4a866dd9'] | | ID | c1937c3d-77e7-4f2c-842d-70b5e10df9a8 | | Name | local-epg-kna1 | | Project | 94109c764a754e24ac0f6b01aef82359 | | Type | subnet | | project_id | 94109c764a754e24ac0f6b01aef82359 | +-------------+------------------------------------------+ Create a peer (remote) end-point group: openstack vpn endpoint group create \\ --type cidr --value $SUBNET_FRA1 peer-epg-kna1 +-------------+--------------------------------------+ | Field | Value | +-------------+--------------------------------------+ | Description | | | Endpoints | ['10.15.25.0/24'] | | ID | 2e627315-02f0-4d68-8683-14230b166060 | | Name | peer-epg-kna1 | | Project | 94109c764a754e24ac0f6b01aef82359 | | Type | cidr | | project_id | 94109c764a754e24ac0f6b01aef82359 | +-------------+--------------------------------------+","title":"Prepare the right side (region kna1)"},{"location":"howto/openstack/neutron/vpnaas/#instantiate-a-pre-shared-key","text":"Before establishing a site-to-site IPSec VPN connection, you must have a randomly generated pre-shared key. You may use openssl for generating a random string and immediately set it to a shell variable: PRE_SHARED_KEY = $( openssl rand -hex 24 ) The above is just an example. The key should not necessarily be a hexadecimal string, nor do you have to use openssl . Another option would be to use the fine pwgen tool, for example like this: PRE_SHARED_KEY = $( pwgen 64 1 )","title":"Instantiate a pre-shared key"},{"location":"howto/openstack/neutron/vpnaas/#establish-a-left-to-right-connection-region-fra1","text":"To create a VPN connection from left to right, i.e., from region fra1 to region kna1 , issue the following command: openstack vpn ipsec site connection create \\ --vpnservice vpn-service-fra1 \\ --ikepolicy ike-pol-fra1 \\ --ipsecpolicy ipsec-pol-fra1 \\ --local-endpoint-group local-epg-fra1 \\ --peer-address $EXT_IP_KNA1 \\ --peer-id $EXT_IP_KNA1 \\ --peer-endpoint-group peer-epg-fra1 \\ --psk $PRE_SHARED_KEY \\ vpn-conn-to-kna1 +--------------------------+----------------------------------------------------+ | Field | Value | +--------------------------+----------------------------------------------------+ | Authentication Algorithm | psk | | Description | | | ID | 5f44be31-0588-4f33-883d-9e2d97be55e1 | | IKE Policy | 5782b141-afcc-4327-9ac5-b8cd2e110c6a | | IPSec Policy | 15ec761f-1642-49b6-b5a2-e43624c5752d | | Initiator | bi-directional | | Local Endpoint Group ID | 51895e0e-fa3a-43d3-8037-5eea073fb77f | | Local ID | | | MTU | 1500 | | Name | vpn-conn-to-kna1 | | Peer Address | 203.0.113.101 | | Peer CIDRs | | | Peer Endpoint Group ID | a96bb9ef-d0ec-4174-93ae-a8e655910f94 | | Peer ID | 203.0.113.101 | | Pre-shared Key | de12db260ee1b9c0b9e624d910c9a9dbddec13dc24d60332 | | Project | dfc700467396428bacba4376e72cc3e9 | | Route Mode | static | | State | True | | Status | PENDING_CREATE | | VPN Service | d74d51f0-182d-4d88-952a-1d593ce696fd | | dpd | {'action': 'hold', 'interval': 30, 'timeout': 120} | | project_id | dfc700467396428bacba4376e72cc3e9 | +--------------------------+----------------------------------------------------+","title":"Establish a left-to-right connection (region fra1)"},{"location":"howto/openstack/neutron/vpnaas/#establish-a-right-to-left-connection-region-kna1","text":"Similarly, to create a VPN connection from right to left, i.e., from region kna1 to region fra1 , issue the following command: openstack vpn ipsec site connection create \\ --vpnservice vpn-service-kna1 \\ --ikepolicy ike-pol-kna1 \\ --ipsecpolicy ipsec-pol-kna1 \\ --local-endpoint-group local-epg-kna1 \\ --peer-address $EXT_IP_FRA1 \\ --peer-id $EXT_IP_FRA1 \\ --peer-endpoint-group peer-epg-kna1 \\ --psk $PRE_SHARED_KEY \\ vpn-conn-to-fra1 +--------------------------+----------------------------------------------------+ | Field | Value | +--------------------------+----------------------------------------------------+ | Authentication Algorithm | psk | | Description | | | ID | 7705afc7-d0ff-444a-9474-3614e21d2399 | | IKE Policy | 6af4f52c-6522-483d-bb70-b144657489f3 | | IPSec Policy | 8f9c2219-a931-46eb-b3f5-22d76cbc89d0 | | Initiator | bi-directional | | Local Endpoint Group ID | c1937c3d-77e7-4f2c-842d-70b5e10df9a8 | | Local ID | | | MTU | 1500 | | Name | vpn-conn-to-fra1 | | Peer Address | 198.51.100.50 | | Peer CIDRs | | | Peer Endpoint Group ID | 2e627315-02f0-4d68-8683-14230b166060 | | Peer ID | 198.51.100.50 | | Pre-shared Key | de12db260ee1b9c0b9e624d910c9a9dbddec13dc24d60332 | | Project | 94109c764a754e24ac0f6b01aef82359 | | Route Mode | static | | State | True | | Status | PENDING_CREATE | | VPN Service | bb1a307d-6f8f-4a0a-83db-7c705403485d | | dpd | {'action': 'hold', 'interval': 30, 'timeout': 120} | | project_id | 94109c764a754e24ac0f6b01aef82359 | +--------------------------+----------------------------------------------------+","title":"Establish a right-to-left connection (region kna1)"},{"location":"howto/openstack/neutron/vpnaas/#viewing-vpn-connections-and-getting-details","text":"No matter if you use the Cleura Cloud Management Panel or the OpenStack CLI, you may at any time list all VPN connections and get relevant details. Cleura Cloud Management Panel OpenStack CLI In the vertical pane on the left-hand side of the Cleura Cloud Management Panel, expand the Networking section and then the VPN Services subsection. From the available options, click VPN Services again. You will see two VPN connections in the main pane, each from one region to the other. For more information regarding a specific connection, click the corresponding three-dot icon (right-hand side) and select View details . Then, you can glance over all the details regarding, for example, the connection status and public IP address. You can list all IPSec VPN connections working from any of the two regions involved. See, for example, the view from fra1 : openstack vpn ipsec site connection list +--------------------------+------------------+---------------+--------------------------+--------+ | ID | Name | Peer Address | Authentication Algorithm | Status | +--------------------------+------------------+---------------+--------------------------+--------+ | 5f44be31-0588-4f33-883d- | vpn-conn-to-kna1 | 203.0.113.101 | psk | ACTIVE | | 9e2d97be55e1 | | | | | +--------------------------+------------------+---------------+--------------------------+--------+ If you want more information regarding a specific connection, type something like this: openstack vpn ipsec site connection show vpn-conn-to-kna1 +--------------------------+----------------------------------------------------+ | Field | Value | +--------------------------+----------------------------------------------------+ | Authentication Algorithm | psk | | Description | | | ID | 5f44be31-0588-4f33-883d-9e2d97be55e1 | | IKE Policy | 5782b141-afcc-4327-9ac5-b8cd2e110c6a | | IPSec Policy | 15ec761f-1642-49b6-b5a2-e43624c5752d | | Initiator | bi-directional | | Local Endpoint Group ID | 51895e0e-fa3a-43d3-8037-5eea073fb77f | | Local ID | | | MTU | 1500 | | Name | vpn-conn-to-kna1 | | Peer Address | 203.0.113.101 | | Peer CIDRs | | | Peer Endpoint Group ID | a96bb9ef-d0ec-4174-93ae-a8e655910f94 | | Peer ID | 203.0.113.101 | | Pre-shared Key | de12db260ee1b9c0b9e624d910c9a9dbddec13dc24d60332 | | Project | dfc700467396428bacba4376e72cc3e9 | | Route Mode | static | | State | True | | Status | ACTIVE | | VPN Service | d74d51f0-182d-4d88-952a-1d593ce696fd | | dpd | {'action': 'hold', 'interval': 30, 'timeout': 120} | | project_id | dfc700467396428bacba4376e72cc3e9 | +--------------------------+----------------------------------------------------+","title":"Viewing VPN connections and getting details"},{"location":"howto/openstack/neutron/vpnaas/#testing-the-site-to-site-vpn-connection","text":"One way to test the VPN connection is to have two servers (e.g., server-fra1 and server-kna1 ), each on a different region (e.g., fra1 and kna1 respectively), ping each other using private IP addresses. With no VPN connection between the two regions, pinging should not be possible: ubuntu@server-fra1:~$ ping -c 3 10 .15.20.148 PING 10.15.20.148 (10.15.20.148) 56(84) bytes of data. --- 10.15.20.148 ping statistics --- 3 packets transmitted, 0 received, 100% packet loss, time 2050ms ubuntu@server-kna1:~$ ping -c 3 10 .15.25.58 PING 10.15.25.58 (10.15.25.58) 56(84) bytes of data. --- 10.15.25.58 ping statistics --- 3 packets transmitted, 0 received, 100% packet loss, time 2045ms On the other hand, with a VPN connection established between the two regions, pinging should be all possible: ubuntu@server-fra1:~$ ping -c 3 10 .15.20.148 PING 10.15.20.148 (10.15.20.148) 56(84) bytes of data. 64 bytes from 10.15.20.148: icmp_seq=1 ttl=62 time=32.8 ms 64 bytes from 10.15.20.148: icmp_seq=2 ttl=62 time=32.5 ms 64 bytes from 10.15.20.148: icmp_seq=3 ttl=62 time=32.6 ms --- 10.15.20.148 ping statistics --- 3 packets transmitted, 3 received, 0% packet loss, time 2003ms rtt min/avg/max/mdev = 32.544/32.624/32.761/0.096 ms ubuntu@server-kna1:~$ ping -c 3 10 .15.25.58 PING 10.15.25.58 (10.15.25.58) 56(84) bytes of data. 64 bytes from 10.15.25.58: icmp_seq=1 ttl=62 time=33.3 ms 64 bytes from 10.15.25.58: icmp_seq=2 ttl=62 time=32.5 ms 64 bytes from 10.15.25.58: icmp_seq=3 ttl=62 time=32.6 ms --- 10.15.25.58 ping statistics --- 3 packets transmitted, 3 received, 0% packet loss, time 2003ms rtt min/avg/max/mdev = 32.533/32.832/33.336/0.358 ms","title":"Testing the site-to-site VPN connection"},{"location":"howto/openstack/neutron/vpnaas/#disabling-an-active-connection","text":"You may, at any time, disable an active site-to-site VPN connection. Cleura Cloud Management Panel OpenStack CLI Currently, there is no way to disable an active connection from the Cleura Cloud Management Panel. If you want to disable an active connection, please use the OpenStack CLI. All you have to do is get on either side of the connection and disable the VPN connection across the other side. Suppose you are on the left side of the connection (region fra1 ), and for whatever reason, you want to disable the site-to-site connection between left and right (regions fra1 and kna1 ). First, you might want to remember the name of the VPN connection to the right: openstack vpn ipsec site connection list +--------------------------+------------------+---------------+--------------------------+--------+ | ID | Name | Peer Address | Authentication Algorithm | Status | +--------------------------+------------------+---------------+--------------------------+--------+ | 5f44be31-0588-4f33-883d- | vpn-conn-to-kna1 | 203.0.113.101 | psk | ACTIVE | | 9e2d97be55e1 | | | | | +--------------------------+------------------+---------------+--------------------------+--------+ That would be vpn-conn-to-kna1 , and according to the command output above, it is active. To disable it, type the following: openstack vpn ipsec site connection set --disable vpn-conn-to-kna1 Check if it is really disabled: openstack vpn ipsec site connection show vpn-conn-to-kna1 -c Status +--------+-------+ | Field | Value | +--------+-------+ | Status | DOWN | +--------+-------+ It looks like it is disabled \u2014 or DOWN . You will probably have to wait several seconds before seeing a status change. If you are impatient, try something like this: watch \"openstack vpn ipsec site connection show vpn-conn-to-kna1 -c Status\" Hit CTRL+C as soon as you see the status change you expect. Now, get on the right side of the connection (region kna1 ), optionally look for the name of the VPN connection to the left (in our example, that would be vpn-conn-to-fra1 ), and check its status: openstack vpn ipsec site connection show vpn-conn-to-fra1 -c Status +--------+-------+ | Field | Value | +--------+-------+ | Status | DOWN | +--------+-------+ It turns out that this direction of the connection is also disabled. To test that a previously enabled site-to-site connection is now disabled, select a server from one region and try to ping a server in another region. Suppose, for example, that a now-disabled connection involved regions fra1 and kna1 , and that we have servers server-fra1 (in fra1 ) and server-kna1 (in kna1 ). With the VPN connection between the two regions now disabled, pinging should not be possible: ubuntu@server-fra1:~$ ping -c 3 10 .15.20.148 PING 10.15.20.148 (10.15.20.148) 56(84) bytes of data. --- 10.15.20.148 ping statistics --- 3 packets transmitted, 0 received, 100% packet loss, time 2055ms ubuntu@server-kna1:~$ ping -c 3 10 .15.25.58 PING 10.15.25.58 (10.15.25.58) 56(84) bytes of data. --- 10.15.25.58 ping statistics --- 3 packets transmitted, 0 received, 100% packet loss, time 2050ms","title":"Disabling an active connection"},{"location":"howto/openstack/neutron/vpnaas/#enabling-an-inactive-connection","text":"You can easily enable an inactive site-to-site VPN connection. Cleura Cloud Management Panel OpenStack CLI Currently, there is no way to enable an inactive connection from the Cleura Cloud Management Panel. If you want to re-enable an inactive connection, please use the OpenStack CLI. Make sure you hop on the side where you initially disabled the connection. According to the example scenario we described in the previous section, that would be the left side (region fra1 ), and the name of the disabled connection would be vpn-conn-to-kna1 . Make sure the connection status is DOWN : openstack vpn ipsec site connection show vpn-conn-to-kna1 -c Status +--------+-------+ | Field | Value | +--------+-------+ | Status | DOWN | +--------+-------+ Note that if you issued a similar command from the right side of the connection (region kna1 ), you would also get a DOWN status. Being on the left side, all you have to do to enable the inactive connection is type the following: openstack vpn ipsec site connection set --enable vpn-conn-to-kna1 Check the connection status \u2014 it should be ACTIVE : openstack vpn ipsec site connection show vpn-conn-to-kna1 -c Status +--------+--------+ | Field | Value | +--------+--------+ | Status | ACTIVE | +--------+--------+ You get the same status by issuing a similar command from the right side. Again, since you may have to wait several seconds before seeing the status change you expect, try something like this: watch \"openstack vpn ipsec site connection show vpn-conn-to-kna1 -c Status\" Hit CTRL+C to stop watching. To test that a previously disabled site-to-site connection is now enabled, select a server from one region and try to ping a server in another region. Suppose, for example, that a re-enabled connection involves regions fra1 and kna1 , and that we have servers server-fra1 (in fra1 ) and server-kna1 (in kna1 ). With the VPN connection between the two regions now re-established, pinging should be possible: ubuntu@server-fra1:~$ ping -c 3 10 .15.20.148 PING 10.15.20.148 (10.15.20.148) 56(84) bytes of data. 64 bytes from 10.15.20.148: icmp_seq=1 ttl=62 time=32.6 ms 64 bytes from 10.15.20.148: icmp_seq=2 ttl=62 time=32.6 ms 64 bytes from 10.15.20.148: icmp_seq=3 ttl=62 time=32.7 ms --- 10.15.20.148 ping statistics --- 3 packets transmitted, 3 received, 0% packet loss, time 2003ms rtt min/avg/max/mdev = 32.619/32.634/32.662/0.019 ms ubuntu@server-kna1:~$ ping -c 3 10 .15.25.58 PING 10.15.25.58 (10.15.25.58) 56(84) bytes of data. 64 bytes from 10.15.25.58: icmp_seq=1 ttl=62 time=32.8 ms 64 bytes from 10.15.25.58: icmp_seq=2 ttl=62 time=32.6 ms 64 bytes from 10.15.25.58: icmp_seq=3 ttl=62 time=33.4 ms --- 10.15.25.58 ping statistics --- 3 packets transmitted, 3 received, 0% packet loss, time 2003ms rtt min/avg/max/mdev = 32.560/32.899/33.357/0.336 ms","title":"Enabling an inactive connection"},{"location":"howto/openstack/nova/config-drive/","text":"Launching a server with a configuration drive Background: OpenStack metadata discovery OpenStack Compute uses metadata to inject custom configurations to servers on boot. You can add custom scripts, install packages, and add SSH keys to the servers using metadata. By default, metadata discovery in Cleura Cloud uses an HTTP data source that booting servers connect to. Sometimes this is undesirable or \u2014 for specific server/networking configurations \u2014 unreliable. Under those circumstances, you can use an alternate configuration source. Store metadata on a configuration drive A configuration drive (config drive) is a read-only virtual drive that is attached to a server during boot. The server can then mount the drive and read files from it. Configuration drives are used as a data source for cloud-init . Enable the configuration drive on server creation ( openstack CLI) To enable the configuration drive, you need to pass the parameter --use-config-drive to the openstack server create command. In the following example, replace the image, flavor, keypair, and network reference, as well as the server name, to match your desired configuration. openstack server create \\ --use-config-drive \\ --image \"Ubuntu 20.04 Focal Fossa\" \\ --flavor b.1c2gb \\ --keypair mykey --nic net-id = 3a747038-ee59-404c-973d-5f795e8ebb73 \\ myserver Once the server launches, you can monitor its configuration process by monitoring the server console log: openstack console log show myserver","title":"Launching a server with a configuration drive"},{"location":"howto/openstack/nova/config-drive/#launching-a-server-with-a-configuration-drive","text":"","title":"Launching a server with a configuration drive"},{"location":"howto/openstack/nova/config-drive/#background-openstack-metadata-discovery","text":"OpenStack Compute uses metadata to inject custom configurations to servers on boot. You can add custom scripts, install packages, and add SSH keys to the servers using metadata. By default, metadata discovery in Cleura Cloud uses an HTTP data source that booting servers connect to. Sometimes this is undesirable or \u2014 for specific server/networking configurations \u2014 unreliable. Under those circumstances, you can use an alternate configuration source.","title":"Background: OpenStack metadata discovery"},{"location":"howto/openstack/nova/config-drive/#store-metadata-on-a-configuration-drive","text":"A configuration drive (config drive) is a read-only virtual drive that is attached to a server during boot. The server can then mount the drive and read files from it. Configuration drives are used as a data source for cloud-init .","title":"Store metadata on a configuration drive"},{"location":"howto/openstack/nova/config-drive/#enable-the-configuration-drive-on-server-creation-openstack-cli","text":"To enable the configuration drive, you need to pass the parameter --use-config-drive to the openstack server create command. In the following example, replace the image, flavor, keypair, and network reference, as well as the server name, to match your desired configuration. openstack server create \\ --use-config-drive \\ --image \"Ubuntu 20.04 Focal Fossa\" \\ --flavor b.1c2gb \\ --keypair mykey --nic net-id = 3a747038-ee59-404c-973d-5f795e8ebb73 \\ myserver Once the server launches, you can monitor its configuration process by monitoring the server console log: openstack console log show myserver","title":"Enable the configuration drive on server creation (openstack\u00a0CLI)"},{"location":"howto/openstack/nova/new-server/","text":"Creating new servers Once you have an account in Cleura Cloud , you can create virtual machines \u2014 henceforth simply servers \u2014 using either the Cleura Cloud Management Panel or the OpenStack CLI. Let us demonstrate the creation of a new server, following both approaches. Prerequisites You need to have at least one network in the region you are interested in. Additionally, if you prefer to work with the OpenStack CLI, then make sure to properly enable it first . Creating a server To create a server from the Cleura Cloud Management Panel, fire up your favorite web browser, navigate to the Cleura Cloud Management Panel start page, and log into your Cleura Cloud account. On the other hand, if you prefer to work with the OpenStack CLI, please do not forget to source the RC file first . Cleura Cloud Management Panel OpenStack CLI On the top right-hand side of the Cleura Cloud Management Panel, click the Create button. A new pane titled Create will slide into view from the right-hand side of the browser window. You will notice several rounded boxes on that pane, each for defining, configuring, and instantiating a different Cleura Cloud object. Go ahead and click the Server box. A new pane titled Create a Server will slide over. At the top, type in a name for the new server and select one of the available regions. In the Boot source section below, click the dropdown menu on the left and make sure you select Boot from image , so you can choose one of the readily available OS images to boot the new server off of. To pick one of the images, click on the dropdown menu on the right. For this how-to guide, we have chosen ubuntu in general and Ubuntu 22.04 Jammy Jellyfish 20220810 in particular. Next, make sure Boot Target is set to Volume (Recommended) . Regarding the server\u2019s CPU core count and amount of memory, set the Flavor accordingly. The default flavor specifies a server with 1 CPU core and 1GB of RAM. You can start with that or select a different configuration by clicking the dropdown menu at the right of Flavor . Please note that, depending on the chosen flavor, the estimated monthly cost of the server changes. (While a server is shut off you are still getting charged for it, but less so.) At any time, this estimated cost is displayed in the green rectangular area at the top. Something else that affects the cost is the size of the root device. Take a look at the Size parameter below, and notice the default (in gibibytes ). You may leave the root device size unchanged, or modify it to be lower or higher than the default. When, at a later time, you decide to delete the server, you can do so but keep its boot volume (you may want, for example, to attach the exact same volume to a new server). Just leave the Delete on termination option disabled if you want this kind of flexibility. On the other hand, if you want your root volume to be automatically deleted when the server terminates, enable Delete on termination . Use this option with caution. Finally, you may enable Disaster recovery for the server. If you do, then daily server snapshots will be created, and you will have the option for easy and fast rollups to previous snapshots. Please be aware that enabling this option increases the server\u2019s monthly estimated cost (again, it is displayed in the green rectangular area at the top). Regarding networking, select one of the available networks to attach the new server to. If you want the server accessible from the Internet, do not forget to enable the I want an external IP for my server option. In the section below, set Security Groups to default . If you already have one or more public keys in your Cleura Cloud account, you can now select a key to be included in the ~/.ssh/authorized_keys file of the server\u2019s default user. That way, you can securely log into the remote user\u2019s account without typing a password. If there are no public keys to choose from, activate the Password login enabled option and set a password for a specific user (with a username you define). A configuration script is automatically prepared based on the choices you have already made. That script runs during system boot and performs housekeeping tasks like user account creation, enabling acceptable authentication methods, and configuring remote package repositories. Click on Advanced Options to see the default script. It is now time to create your Cleura Cloud server; click the green Create button, and the new server will be readily available in a few seconds. An openstack command for creating a server may look like this: openstack server create \\ --flavor $FLAVOR_NAME \\ --image $IMAGE_NAME \\ --boot-from-volume $VOL_SIZE \\ --network $NETWORK_NAME \\ --security-group $SEC_GROUP_NAME \\ --key-name $KEY_NAME \\ --wait \\ $SERVER_NAME Each variable represents a piece of information we have to look for or, in the cases of KEY_NAME and SERVER_NAME , arbitrarily define. Let us begin with the flavors ( FLAVOR_NAME ), which describe combinations of CPU core count and memory size. Each server has a distinct flavor, and to see all available flavors type: openstack flavor list You will get a pretty long list of flavors. For our demonstration, we suggest you go with b.1c1gb . A server with this particular flavor will have one CPU core and one gibibyte of RAM. Go ahead and set FLAVOR_NAME accordingly: FLAVOR_NAME = \"b.1c1gb\" Your server should have an image to boot off of ( IMAGE_NAME ). For a list of all available images in Cleura Cloud, type: openstack image list This time you get a shorter list, but you can still filter for images with the OS you prefer. For example, filter for Ubuntu: openstack image list --tag \"os:ubuntu\" Continue with the Ubuntu 22.04 Jammy Jellyfish 20220810 image: IMAGE_NAME = \"Ubuntu 22.04 Jammy Jellyfish 20220810\" Before you go on, decide on the capacity (in gibibytes) of the server\u2019s boot volume ( VOL_SIZE ). We suggest you start with 20 gibibytes: VOL_SIZE = \"20\" You need at least one network in the region you\u2019re about to create your new server ( NETWORK_NAME ). To get the names of all available (internal) networks, type: openstack network list --internal -c Name +----------------+ | Name | +----------------+ | nordostbahnhof | +----------------+ Set the NETWORK_NAME variable accordingly: NETWORK_NAME = \"nordostbahnhof\" Regarding the security group ( SEC_GROUP_NAME ), unless you have already created one yourself, you will find only one per region: openstack security group list -c Name -c Description +---------+------------------------+ | Name | Description | +---------+------------------------+ | default | Default security group | +---------+------------------------+ Go ahead and set SEC_GROUP_NAME : SEC_GROUP_NAME = \"default\" You most likely want a server you can remotely connect to via SSH without typing a password. Upload one of our public keys to your Cleura Cloud account: openstack keypair create --public-key ~/.ssh/id_ed25519.pub bahnhof In the example above, we uploaded the public key ~/.ssh/id_ed25519.pub to our Cleura Cloud account and named it bahnhof . Follow our example and do not forget to set the KEY_NAME : KEY_NAME = \"bahnhof\" By the way, check all uploaded public keys\u2026 openstack keypair list \u2026and get more information regarding the one you just uploaded: openstack keypair show bahnhof You are almost ready to create your new server. Decide on a name\u2026 SERVER_NAME = \"zug\" # just an example \u2026and then go ahead and create it: openstack server create \\ --flavor b.1c1gb \\ --image $IMAGE_NAME \\ --boot-from-volume 20 \\ --network nordostbahnhof \\ --security-group default \\ --key-name bahnhof \\ --wait \\ zug (For clarity\u2019s sake, and with the exception of IMAGE_NAME , we used the actual values and not the variables we so meticulously set.) The --wait parameter is optional. Whenever you choose to use it, you get back control of your terminal only after the server is readily available in Cleura Cloud. To connect to your server remotely, you need to create a floating IP for the external network in the Cleura Cloud, and then assign this IP to your server. First, create the floating IP: openstack floating ip create ext-net See all floating IPs\u2026 openstack floating ip list \u2026and assign the one you just created to your server: openstack server add floating ip zug 198 .51.100.12 The username of the default user account in the Ubuntu image is ubuntu , so now you can connect to your remote server via SSH without typing a password: ssh ubuntu@198.51.100.12 Viewing information about the newly created server Cleura Cloud Management Panel OpenStack CLI From the Cleura Cloud Management Panel you may, at any time, see all servers and get detailed information regarding each one of them; expand the left-hand side vertical pane, click Compute , then Servers , and, in the central pane, select the region you want. To see all available servers in the region, type: openstack server list You can always get specific information on a particular server: openstack server show zug Connecting to the server console Cleura Cloud Management Panel OpenStack CLI While viewing information regarding your server, you may get its public IP address (e.g., from the Addresses tab) and connect to it remotely. Alternatively, you may launch a web console and log in; click on the three-dot icon on the right of the server header, and from the pop-up menu that appears select Remote Console . A new window pops up, and that\u2019s your web console to your Cleura Cloud server. Please note that this window cannot be resized but can be opened on a new browser window or tab. You may have access to the web console of your server, and you need the corresponding URL for it: openstack console url show zug Usage of the web console is discouraged, though. Instead, securely connect to your server via SSH.","title":"Creating new servers"},{"location":"howto/openstack/nova/new-server/#creating-new-servers","text":"Once you have an account in Cleura Cloud , you can create virtual machines \u2014 henceforth simply servers \u2014 using either the Cleura Cloud Management Panel or the OpenStack CLI. Let us demonstrate the creation of a new server, following both approaches.","title":"Creating new servers"},{"location":"howto/openstack/nova/new-server/#prerequisites","text":"You need to have at least one network in the region you are interested in. Additionally, if you prefer to work with the OpenStack CLI, then make sure to properly enable it first .","title":"Prerequisites"},{"location":"howto/openstack/nova/new-server/#creating-a-server","text":"To create a server from the Cleura Cloud Management Panel, fire up your favorite web browser, navigate to the Cleura Cloud Management Panel start page, and log into your Cleura Cloud account. On the other hand, if you prefer to work with the OpenStack CLI, please do not forget to source the RC file first . Cleura Cloud Management Panel OpenStack CLI On the top right-hand side of the Cleura Cloud Management Panel, click the Create button. A new pane titled Create will slide into view from the right-hand side of the browser window. You will notice several rounded boxes on that pane, each for defining, configuring, and instantiating a different Cleura Cloud object. Go ahead and click the Server box. A new pane titled Create a Server will slide over. At the top, type in a name for the new server and select one of the available regions. In the Boot source section below, click the dropdown menu on the left and make sure you select Boot from image , so you can choose one of the readily available OS images to boot the new server off of. To pick one of the images, click on the dropdown menu on the right. For this how-to guide, we have chosen ubuntu in general and Ubuntu 22.04 Jammy Jellyfish 20220810 in particular. Next, make sure Boot Target is set to Volume (Recommended) . Regarding the server\u2019s CPU core count and amount of memory, set the Flavor accordingly. The default flavor specifies a server with 1 CPU core and 1GB of RAM. You can start with that or select a different configuration by clicking the dropdown menu at the right of Flavor . Please note that, depending on the chosen flavor, the estimated monthly cost of the server changes. (While a server is shut off you are still getting charged for it, but less so.) At any time, this estimated cost is displayed in the green rectangular area at the top. Something else that affects the cost is the size of the root device. Take a look at the Size parameter below, and notice the default (in gibibytes ). You may leave the root device size unchanged, or modify it to be lower or higher than the default. When, at a later time, you decide to delete the server, you can do so but keep its boot volume (you may want, for example, to attach the exact same volume to a new server). Just leave the Delete on termination option disabled if you want this kind of flexibility. On the other hand, if you want your root volume to be automatically deleted when the server terminates, enable Delete on termination . Use this option with caution. Finally, you may enable Disaster recovery for the server. If you do, then daily server snapshots will be created, and you will have the option for easy and fast rollups to previous snapshots. Please be aware that enabling this option increases the server\u2019s monthly estimated cost (again, it is displayed in the green rectangular area at the top). Regarding networking, select one of the available networks to attach the new server to. If you want the server accessible from the Internet, do not forget to enable the I want an external IP for my server option. In the section below, set Security Groups to default . If you already have one or more public keys in your Cleura Cloud account, you can now select a key to be included in the ~/.ssh/authorized_keys file of the server\u2019s default user. That way, you can securely log into the remote user\u2019s account without typing a password. If there are no public keys to choose from, activate the Password login enabled option and set a password for a specific user (with a username you define). A configuration script is automatically prepared based on the choices you have already made. That script runs during system boot and performs housekeeping tasks like user account creation, enabling acceptable authentication methods, and configuring remote package repositories. Click on Advanced Options to see the default script. It is now time to create your Cleura Cloud server; click the green Create button, and the new server will be readily available in a few seconds. An openstack command for creating a server may look like this: openstack server create \\ --flavor $FLAVOR_NAME \\ --image $IMAGE_NAME \\ --boot-from-volume $VOL_SIZE \\ --network $NETWORK_NAME \\ --security-group $SEC_GROUP_NAME \\ --key-name $KEY_NAME \\ --wait \\ $SERVER_NAME Each variable represents a piece of information we have to look for or, in the cases of KEY_NAME and SERVER_NAME , arbitrarily define. Let us begin with the flavors ( FLAVOR_NAME ), which describe combinations of CPU core count and memory size. Each server has a distinct flavor, and to see all available flavors type: openstack flavor list You will get a pretty long list of flavors. For our demonstration, we suggest you go with b.1c1gb . A server with this particular flavor will have one CPU core and one gibibyte of RAM. Go ahead and set FLAVOR_NAME accordingly: FLAVOR_NAME = \"b.1c1gb\" Your server should have an image to boot off of ( IMAGE_NAME ). For a list of all available images in Cleura Cloud, type: openstack image list This time you get a shorter list, but you can still filter for images with the OS you prefer. For example, filter for Ubuntu: openstack image list --tag \"os:ubuntu\" Continue with the Ubuntu 22.04 Jammy Jellyfish 20220810 image: IMAGE_NAME = \"Ubuntu 22.04 Jammy Jellyfish 20220810\" Before you go on, decide on the capacity (in gibibytes) of the server\u2019s boot volume ( VOL_SIZE ). We suggest you start with 20 gibibytes: VOL_SIZE = \"20\" You need at least one network in the region you\u2019re about to create your new server ( NETWORK_NAME ). To get the names of all available (internal) networks, type: openstack network list --internal -c Name +----------------+ | Name | +----------------+ | nordostbahnhof | +----------------+ Set the NETWORK_NAME variable accordingly: NETWORK_NAME = \"nordostbahnhof\" Regarding the security group ( SEC_GROUP_NAME ), unless you have already created one yourself, you will find only one per region: openstack security group list -c Name -c Description +---------+------------------------+ | Name | Description | +---------+------------------------+ | default | Default security group | +---------+------------------------+ Go ahead and set SEC_GROUP_NAME : SEC_GROUP_NAME = \"default\" You most likely want a server you can remotely connect to via SSH without typing a password. Upload one of our public keys to your Cleura Cloud account: openstack keypair create --public-key ~/.ssh/id_ed25519.pub bahnhof In the example above, we uploaded the public key ~/.ssh/id_ed25519.pub to our Cleura Cloud account and named it bahnhof . Follow our example and do not forget to set the KEY_NAME : KEY_NAME = \"bahnhof\" By the way, check all uploaded public keys\u2026 openstack keypair list \u2026and get more information regarding the one you just uploaded: openstack keypair show bahnhof You are almost ready to create your new server. Decide on a name\u2026 SERVER_NAME = \"zug\" # just an example \u2026and then go ahead and create it: openstack server create \\ --flavor b.1c1gb \\ --image $IMAGE_NAME \\ --boot-from-volume 20 \\ --network nordostbahnhof \\ --security-group default \\ --key-name bahnhof \\ --wait \\ zug (For clarity\u2019s sake, and with the exception of IMAGE_NAME , we used the actual values and not the variables we so meticulously set.) The --wait parameter is optional. Whenever you choose to use it, you get back control of your terminal only after the server is readily available in Cleura Cloud. To connect to your server remotely, you need to create a floating IP for the external network in the Cleura Cloud, and then assign this IP to your server. First, create the floating IP: openstack floating ip create ext-net See all floating IPs\u2026 openstack floating ip list \u2026and assign the one you just created to your server: openstack server add floating ip zug 198 .51.100.12 The username of the default user account in the Ubuntu image is ubuntu , so now you can connect to your remote server via SSH without typing a password: ssh ubuntu@198.51.100.12","title":"Creating a server"},{"location":"howto/openstack/nova/new-server/#viewing-information-about-the-newly-created-server","text":"Cleura Cloud Management Panel OpenStack CLI From the Cleura Cloud Management Panel you may, at any time, see all servers and get detailed information regarding each one of them; expand the left-hand side vertical pane, click Compute , then Servers , and, in the central pane, select the region you want. To see all available servers in the region, type: openstack server list You can always get specific information on a particular server: openstack server show zug","title":"Viewing information about the newly created server"},{"location":"howto/openstack/nova/new-server/#connecting-to-the-server-console","text":"Cleura Cloud Management Panel OpenStack CLI While viewing information regarding your server, you may get its public IP address (e.g., from the Addresses tab) and connect to it remotely. Alternatively, you may launch a web console and log in; click on the three-dot icon on the right of the server header, and from the pop-up menu that appears select Remote Console . A new window pops up, and that\u2019s your web console to your Cleura Cloud server. Please note that this window cannot be resized but can be opened on a new browser window or tab. You may have access to the web console of your server, and you need the corresponding URL for it: openstack console url show zug Usage of the web console is discouraged, though. Instead, securely connect to your server via SSH.","title":"Connecting to the server console"},{"location":"howto/openstack/nova/resize-server/","text":"Resizing a server This guide will walk you through the required steps to change the number of CPU cores and the amount of memory your server has access to, this is done by changing the server\u2019s flavor . Resize (or Server resize) is the ability to change the flavor of a server, thus allowing it to upscale or downscale according to user needs. A resize operation is a two-step process for the user: Initiate the resize. Either confirm (verify) success and release the old server, or declare a revert to release the new server and restart the old one. Prerequisites You need to have a server you wish to resize. Additionally, if you prefer to work with the OpenStack CLI, then make sure to properly enable it first . Listing available flavors Cleura Cloud Management Panel OpenStack CLI Navigate to the server list. Find the server you want to resize in the list, and on the right-hand side click on its menu button. Click on Modify Server . On this panel near the top, find the section called Flavor . This is the current flavor used by the server. Press on the dropdown menu to see all available flavors. To list all available flavors you can simply run openstack flavor list , but that will return a very long unsorted list, instead we recommend the following command: openstack flavor list -c Name -f value | grep '[0-9]c[0-9]' | sort -V The printout is a simple and clean list, sorted by the compute type, the number of cores and then by the amount of memory. b.1c1gb b.1c2gb b.1c4gb b.2c2gb b.2c4gb b.2c8gb b.2c16gb b.4c4gb ... Initiating the resize Choose a new flavor that you want your server to use instead. A resize is only possible with flavors using the same prefix letter. Most commonly you will have a b. flavor, thus you must select another b. flavor. Cleura Cloud Management Panel OpenStack CLI Once selected, the Resize button will appear. Click on it to start the resize. While the resize is ongoing you will see a spinning circle saying Resize is in progress . To start the resize use the following command: openstack server resize --flavor <new_flavor> <server_id> While the resize is ongoing the server should have the OS-EXT-STS:task_state of resize_migrating and the status of RESIZE . openstack server show -c OS-EXT-STS:task_state -c OS-EXT-STS:vm_state -c status <server_id> +-----------------------+------------------+ | Field | Value | +-----------------------+------------------+ | OS-EXT-STS:task_state | resize_migrating | | OS-EXT-STS:vm_state | active | | status | RESIZE | +-----------------------+------------------+ You may proceed with the next step once your server status is VERIFY_RESIZE . +-----------------------+---------------+ | Field | Value | +-----------------------+---------------+ | OS-EXT-STS:task_state | None | | OS-EXT-STS:vm_state | resized | | status | VERIFY_RESIZE | +-----------------------+---------------+ The resize process might take a minute or more. Cleura Cloud will now make a restore point in case the resize process fails. It would then restore your server to the state it was before the resize. Confirming the resize Your server is now using the new flavor you selected earlier, and you need to make sure the server is working as intended after the resize. Once you are certain your server is working as intended, you should confirm the resize. If you do not confirm the resize, your server will automatically have the resize confirmed after 24 hours. Cleura Cloud Management Panel OpenStack CLI This is done by clicking the Confirm button. If your server is not working as intended, or you simply regret the resize, instead click Cancel . This is done by using the following command: openstack server resize confirm <server_id> Alternatively, if your server is not working as intended, revert the resize with the following command: openstack server resize revert <server_id> This concludes the process of resizing a server in Cleura Cloud.","title":"Resizing a server"},{"location":"howto/openstack/nova/resize-server/#resizing-a-server","text":"This guide will walk you through the required steps to change the number of CPU cores and the amount of memory your server has access to, this is done by changing the server\u2019s flavor . Resize (or Server resize) is the ability to change the flavor of a server, thus allowing it to upscale or downscale according to user needs. A resize operation is a two-step process for the user: Initiate the resize. Either confirm (verify) success and release the old server, or declare a revert to release the new server and restart the old one.","title":"Resizing a server"},{"location":"howto/openstack/nova/resize-server/#prerequisites","text":"You need to have a server you wish to resize. Additionally, if you prefer to work with the OpenStack CLI, then make sure to properly enable it first .","title":"Prerequisites"},{"location":"howto/openstack/nova/resize-server/#listing-available-flavors","text":"Cleura Cloud Management Panel OpenStack CLI Navigate to the server list. Find the server you want to resize in the list, and on the right-hand side click on its menu button. Click on Modify Server . On this panel near the top, find the section called Flavor . This is the current flavor used by the server. Press on the dropdown menu to see all available flavors. To list all available flavors you can simply run openstack flavor list , but that will return a very long unsorted list, instead we recommend the following command: openstack flavor list -c Name -f value | grep '[0-9]c[0-9]' | sort -V The printout is a simple and clean list, sorted by the compute type, the number of cores and then by the amount of memory. b.1c1gb b.1c2gb b.1c4gb b.2c2gb b.2c4gb b.2c8gb b.2c16gb b.4c4gb ...","title":"Listing available flavors"},{"location":"howto/openstack/nova/resize-server/#initiating-the-resize","text":"Choose a new flavor that you want your server to use instead. A resize is only possible with flavors using the same prefix letter. Most commonly you will have a b. flavor, thus you must select another b. flavor. Cleura Cloud Management Panel OpenStack CLI Once selected, the Resize button will appear. Click on it to start the resize. While the resize is ongoing you will see a spinning circle saying Resize is in progress . To start the resize use the following command: openstack server resize --flavor <new_flavor> <server_id> While the resize is ongoing the server should have the OS-EXT-STS:task_state of resize_migrating and the status of RESIZE . openstack server show -c OS-EXT-STS:task_state -c OS-EXT-STS:vm_state -c status <server_id> +-----------------------+------------------+ | Field | Value | +-----------------------+------------------+ | OS-EXT-STS:task_state | resize_migrating | | OS-EXT-STS:vm_state | active | | status | RESIZE | +-----------------------+------------------+ You may proceed with the next step once your server status is VERIFY_RESIZE . +-----------------------+---------------+ | Field | Value | +-----------------------+---------------+ | OS-EXT-STS:task_state | None | | OS-EXT-STS:vm_state | resized | | status | VERIFY_RESIZE | +-----------------------+---------------+ The resize process might take a minute or more. Cleura Cloud will now make a restore point in case the resize process fails. It would then restore your server to the state it was before the resize.","title":"Initiating the resize"},{"location":"howto/openstack/nova/resize-server/#confirming-the-resize","text":"Your server is now using the new flavor you selected earlier, and you need to make sure the server is working as intended after the resize. Once you are certain your server is working as intended, you should confirm the resize. If you do not confirm the resize, your server will automatically have the resize confirmed after 24 hours. Cleura Cloud Management Panel OpenStack CLI This is done by clicking the Confirm button. If your server is not working as intended, or you simply regret the resize, instead click Cancel . This is done by using the following command: openstack server resize confirm <server_id> Alternatively, if your server is not working as intended, revert the resize with the following command: openstack server resize revert <server_id> This concludes the process of resizing a server in Cleura Cloud.","title":"Confirming the resize"},{"location":"howto/openstack/octavia/tls-lb/","text":"HTTPS-terminating load balancers In Cleura Cloud\u2019s load balancing service, OpenStack Octavia , you can configure load balancers so that they manage HTTPS termination. That is to say that the load balancer encrypts and decrypts HTTPS traffic, and forwards HTTP to and from a backend web server. To do so, the load balancer must have access to encryption credentials (such as certificates and private keys), which it stores in Barbican. PKCS #12 Certificate Bundles The PKCS #12 archive format includes SSL certificates, certificate chains, and private keys all in one bundle. Most certificate providers give you the option of downloading certificate credentials using the PKCS #12 format. In case your certificate provider has made your certificate chain and key available separately, using the PEM format, you can easily convert it to PKCS #12 using the following openssl command: openssl pkcs12 -export -inkey key.pem -in fullchain.pem -out bundle.p12 When prompted for an export password, use a blank one. Creating Barbican secrets from PKCS #12 bundles To create a secret from a stored PKCS #12 bundle, you need pass in the contents of the bundle, pre-encoded with Base64 , as the secret\u2019s payload. openstack secret store \\ --name = 'tls_secret1' \\ -t 'application/octet-stream' \\ -e 'base64' \\ --payload = \" $( base64 < server.p12 ) \" +---------------+---------------------------------------------------------------------------------+ | Field | Value | +---------------+---------------------------------------------------------------------------------+ | Secret href | https://kna1.citycloud.com:9311/v1/secrets/69bd82f5-60c9-4764-99ec-7a3dff05d2aa | | Name | tls_secret1 | | Created | None | | Status | None | | Content types | {'default': 'application/octet-stream'} | | Algorithm | aes | | Bit length | 256 | | Secret type | opaque | | Mode | cbc | | Expiration | None | +---------------+---------------------------------------------------------------------------------+ Creating HTTPS-enabled load balancer listeners Once you have created your secret containing your certificate data, you can create a load balancer listener with the following properties: It uses the TERMINATED_HTTPS protocol, It sets its \u201cdefault TLS container\u201d to the Barbican secret containing the PKCS #12 bundle, It listens on the standard HTTPS port, 443. You create such a listener with the following command: openstack loadbalancer listener create \\ --protocol-port 443 \\ --protocol TERMINATED_HTTPS \\ --name listener1 \\ --default-tls-container-ref = https://kna1.citycloud.com:9311/v1/secrets/dacfbec1-fbed-403f-a4dc-303e28942dae \\ <loadbalancer-name-or-id> +-----------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+ | Field | Value | +-----------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+ | admin_state_up | True | | connection_limit | -1 | | created_at | 2021-01-20T11:51:46 | | default_pool_id | None | | default_tls_container_ref | https://kna1.citycloud.com:9311/v1/secrets/dacfbec1-fbed-403f-a4dc-303e28942dae | | description | | | id | 4ec6b23d-d08a-4de0-9e12-54ac690ee1ec | | insert_headers | None | | l7policies | | | loadbalancers | 2c2a0760-c3a8-48d2-bdd0-288c3d33a43f | | name | listener1 | | operating_status | OFFLINE | | project_id | 4a9484063d4c40d29301ad745c0e2c69 | | protocol | TERMINATED_HTTPS | | protocol_port | 443 | | provisioning_status | PENDING_CREATE | | sni_container_refs | [] | | timeout_client_data | 50000 | | timeout_member_connect | 5000 | | timeout_member_data | 50000 | | timeout_tcp_inspect | 0 | | updated_at | None | | client_ca_tls_container_ref | None | | client_authentication | NONE | | client_crl_container_ref | None | | allowed_cidrs | None | | tls_ciphers | TLS_AES_256_GCM_SHA384:TLS_CHACHA20_POLY1305_SHA256:TLS_AES_128_GCM_SHA256:DHE-RSA-AES256-GCM-SHA384:DHE-RSA-AES128-GCM-SHA256:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-RSA-AES128-GCM-SHA256:DHE-RSA-AES256-SHA256:DHE-RSA-AES128-SHA256:ECDHE-RSA-AES256-SHA384:ECDHE-RSA-AES128-SHA256 | | tls_versions | | +-----------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+ Updating the TLS certificate for a HTTPS listener When the certificate associated with a TERMINATED_HTTPS listener is about to expire, you will need to replace it. You can do this online, with no user-noticeable interruption to your service. Create a new PKCS#12 bundle from the updated key, certificate, and CA certificate. Create a new Barbican secret from the bundle. List the listener(s) associated with your load balancer: openstack loadbalancer listener list \\ --loadbalancer <loadbalancer-name-or-id> For all listeners using the TERMINATED_HTTPS protocol, run the following command: openstack loadbalancer listener set \\ --default-tls-container-ref = https://kna1.citycloud.com:9311/v1/secrets/e2d8acc1-c6b9-4c01-9373-cc167b075c25 \\ <listener-name-or-id> Once all your load balancer listeners have completed the update, you may proceed to delete the old, now-unused secret: openstack secret delete \\ https://kna1.citycloud.com:9311/v1/secrets/dacfbec1-fbed-403f-a4dc-303e28942dae","title":"HTTPS-terminating load balancers"},{"location":"howto/openstack/octavia/tls-lb/#https-terminating-load-balancers","text":"In Cleura Cloud\u2019s load balancing service, OpenStack Octavia , you can configure load balancers so that they manage HTTPS termination. That is to say that the load balancer encrypts and decrypts HTTPS traffic, and forwards HTTP to and from a backend web server. To do so, the load balancer must have access to encryption credentials (such as certificates and private keys), which it stores in Barbican.","title":"HTTPS-terminating load balancers"},{"location":"howto/openstack/octavia/tls-lb/#pkcs-12-certificate-bundles","text":"The PKCS #12 archive format includes SSL certificates, certificate chains, and private keys all in one bundle. Most certificate providers give you the option of downloading certificate credentials using the PKCS #12 format. In case your certificate provider has made your certificate chain and key available separately, using the PEM format, you can easily convert it to PKCS #12 using the following openssl command: openssl pkcs12 -export -inkey key.pem -in fullchain.pem -out bundle.p12 When prompted for an export password, use a blank one.","title":"PKCS #12 Certificate Bundles"},{"location":"howto/openstack/octavia/tls-lb/#creating-barbican-secrets-from-pkcs-12-bundles","text":"To create a secret from a stored PKCS #12 bundle, you need pass in the contents of the bundle, pre-encoded with Base64 , as the secret\u2019s payload. openstack secret store \\ --name = 'tls_secret1' \\ -t 'application/octet-stream' \\ -e 'base64' \\ --payload = \" $( base64 < server.p12 ) \" +---------------+---------------------------------------------------------------------------------+ | Field | Value | +---------------+---------------------------------------------------------------------------------+ | Secret href | https://kna1.citycloud.com:9311/v1/secrets/69bd82f5-60c9-4764-99ec-7a3dff05d2aa | | Name | tls_secret1 | | Created | None | | Status | None | | Content types | {'default': 'application/octet-stream'} | | Algorithm | aes | | Bit length | 256 | | Secret type | opaque | | Mode | cbc | | Expiration | None | +---------------+---------------------------------------------------------------------------------+","title":"Creating Barbican secrets from PKCS #12 bundles"},{"location":"howto/openstack/octavia/tls-lb/#creating-https-enabled-load-balancer-listeners","text":"Once you have created your secret containing your certificate data, you can create a load balancer listener with the following properties: It uses the TERMINATED_HTTPS protocol, It sets its \u201cdefault TLS container\u201d to the Barbican secret containing the PKCS #12 bundle, It listens on the standard HTTPS port, 443. You create such a listener with the following command: openstack loadbalancer listener create \\ --protocol-port 443 \\ --protocol TERMINATED_HTTPS \\ --name listener1 \\ --default-tls-container-ref = https://kna1.citycloud.com:9311/v1/secrets/dacfbec1-fbed-403f-a4dc-303e28942dae \\ <loadbalancer-name-or-id> +-----------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+ | Field | Value | +-----------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+ | admin_state_up | True | | connection_limit | -1 | | created_at | 2021-01-20T11:51:46 | | default_pool_id | None | | default_tls_container_ref | https://kna1.citycloud.com:9311/v1/secrets/dacfbec1-fbed-403f-a4dc-303e28942dae | | description | | | id | 4ec6b23d-d08a-4de0-9e12-54ac690ee1ec | | insert_headers | None | | l7policies | | | loadbalancers | 2c2a0760-c3a8-48d2-bdd0-288c3d33a43f | | name | listener1 | | operating_status | OFFLINE | | project_id | 4a9484063d4c40d29301ad745c0e2c69 | | protocol | TERMINATED_HTTPS | | protocol_port | 443 | | provisioning_status | PENDING_CREATE | | sni_container_refs | [] | | timeout_client_data | 50000 | | timeout_member_connect | 5000 | | timeout_member_data | 50000 | | timeout_tcp_inspect | 0 | | updated_at | None | | client_ca_tls_container_ref | None | | client_authentication | NONE | | client_crl_container_ref | None | | allowed_cidrs | None | | tls_ciphers | TLS_AES_256_GCM_SHA384:TLS_CHACHA20_POLY1305_SHA256:TLS_AES_128_GCM_SHA256:DHE-RSA-AES256-GCM-SHA384:DHE-RSA-AES128-GCM-SHA256:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-RSA-AES128-GCM-SHA256:DHE-RSA-AES256-SHA256:DHE-RSA-AES128-SHA256:ECDHE-RSA-AES256-SHA384:ECDHE-RSA-AES128-SHA256 | | tls_versions | | +-----------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+","title":"Creating HTTPS-enabled load balancer listeners"},{"location":"howto/openstack/octavia/tls-lb/#updating-the-tls-certificate-for-a-https-listener","text":"When the certificate associated with a TERMINATED_HTTPS listener is about to expire, you will need to replace it. You can do this online, with no user-noticeable interruption to your service. Create a new PKCS#12 bundle from the updated key, certificate, and CA certificate. Create a new Barbican secret from the bundle. List the listener(s) associated with your load balancer: openstack loadbalancer listener list \\ --loadbalancer <loadbalancer-name-or-id> For all listeners using the TERMINATED_HTTPS protocol, run the following command: openstack loadbalancer listener set \\ --default-tls-container-ref = https://kna1.citycloud.com:9311/v1/secrets/e2d8acc1-c6b9-4c01-9373-cc167b075c25 \\ <listener-name-or-id> Once all your load balancer listeners have completed the update, you may proceed to delete the old, now-unused secret: openstack secret delete \\ https://kna1.citycloud.com:9311/v1/secrets/dacfbec1-fbed-403f-a4dc-303e28942dae","title":"Updating the TLS certificate for a HTTPS listener"},{"location":"reference/","text":"Reference This is our reference section. It serves to provide general reference information about Cleura Cloud services. Feature and service availability Our Feature Support Matrix lists cloud features and their availability across Cleura Cloud regions. The Flavors reference explains our naming convention for pre-defined CPU/RAM/disk configurations (\u201cflavors\u201d) for server instances, and their availability across Cleura Cloud regions. Our API Service Version Matrix lists the open source software versions running in our Cleura Cloud regions.","title":"Reference"},{"location":"reference/#reference","text":"This is our reference section. It serves to provide general reference information about Cleura Cloud services.","title":"Reference"},{"location":"reference/#feature-and-service-availability","text":"Our Feature Support Matrix lists cloud features and their availability across Cleura Cloud regions. The Flavors reference explains our naming convention for pre-defined CPU/RAM/disk configurations (\u201cflavors\u201d) for server instances, and their availability across Cleura Cloud regions. Our API Service Version Matrix lists the open source software versions running in our Cleura Cloud regions.","title":"Feature and service availability"},{"location":"reference/features/","text":"Feature support matrix Services in Cleura Cloud constantly evolve, and we gradually add features to regions as they become available and mature. This page lists the cloud features available in each Cleura Cloud region. Public Cloud : features supported in our Cleura Public Cloud regions. Compliant Cloud : features supported in our Cleura Compliant Cloud regions.","title":"Feature support matrix"},{"location":"reference/features/#feature-support-matrix","text":"Services in Cleura Cloud constantly evolve, and we gradually add features to regions as they become available and mature. This page lists the cloud features available in each Cleura Cloud region. Public Cloud : features supported in our Cleura Public Cloud regions. Compliant Cloud : features supported in our Cleura Compliant Cloud regions.","title":"Feature support matrix"},{"location":"reference/features/compliant/","text":"Compliant Cloud Feature is in production and fully supported Feature is in deployment, not yet supported Feature is deprecated, being phased out Feature is not available Virtualization Sto1HS Sto2HS Dedicated CPU Virtual GPU Block storage Sto1HS Sto2HS Highly available storage High-performance local storage Volume encryption Object storage Sto1HS Sto2HS S3 API S3 SSE-C Swift API Networking (Layer 2/3) Sto1HS Sto2HS IPv4 (with NAT) IPv6 VPN (IPsec with PSK) Load Balancers Sto1HS Sto2HS Transport layer (TCP/UDP) Application layer (HTTP) Application layer ( HTTPS, with secrets management for TLS certificates )","title":"Compliant Cloud"},{"location":"reference/features/compliant/#compliant-cloud","text":"Feature is in production and fully supported Feature is in deployment, not yet supported Feature is deprecated, being phased out Feature is not available","title":"Compliant Cloud"},{"location":"reference/features/compliant/#virtualization","text":"Sto1HS Sto2HS Dedicated CPU Virtual GPU","title":"Virtualization"},{"location":"reference/features/compliant/#block-storage","text":"Sto1HS Sto2HS Highly available storage High-performance local storage Volume encryption","title":"Block storage"},{"location":"reference/features/compliant/#object-storage","text":"Sto1HS Sto2HS S3 API S3 SSE-C Swift API","title":"Object storage"},{"location":"reference/features/compliant/#networking-layer-23","text":"Sto1HS Sto2HS IPv4 (with NAT) IPv6 VPN (IPsec with PSK)","title":"Networking (Layer 2/3)"},{"location":"reference/features/compliant/#load-balancers","text":"Sto1HS Sto2HS Transport layer (TCP/UDP) Application layer (HTTP) Application layer ( HTTPS, with secrets management for TLS certificates )","title":"Load Balancers"},{"location":"reference/features/public/","text":"Public Cloud Feature is in production and fully supported Feature is in deployment, not yet supported Feature is deprecated, being phased out Feature is not available Virtualization Kna1 Sto2 Fra1 Dx1 Tky1 Dedicated CPU Virtual GPU Block storage Kna1 Sto2 Fra1 Dx1 Tky1 Highly available storage High-performance local storage Volume encryption Object storage Kna1 Sto2 Fra1 Dx1 Tky1 S3 API S3 SSE-C Swift API Networking (Layer 2/3) Kna1 Sto2 Fra1 Dx1 Tky1 IPv4 (with NAT) IPv6 VPN (IPsec with PSK) Load Balancers Kna1 Sto2 Fra1 Dx1 Tky1 Transport layer (TCP/UDP) Application layer (HTTP) Application layer ( HTTPS, with secrets management for TLS certificates ) Kubernetes management Kna1 Sto2 Fra1 Dx1 Tky1 OpenStack Magnum Gardener","title":"Public Cloud"},{"location":"reference/features/public/#public-cloud","text":"Feature is in production and fully supported Feature is in deployment, not yet supported Feature is deprecated, being phased out Feature is not available","title":"Public Cloud"},{"location":"reference/features/public/#virtualization","text":"Kna1 Sto2 Fra1 Dx1 Tky1 Dedicated CPU Virtual GPU","title":"Virtualization"},{"location":"reference/features/public/#block-storage","text":"Kna1 Sto2 Fra1 Dx1 Tky1 Highly available storage High-performance local storage Volume encryption","title":"Block storage"},{"location":"reference/features/public/#object-storage","text":"Kna1 Sto2 Fra1 Dx1 Tky1 S3 API S3 SSE-C Swift API","title":"Object storage"},{"location":"reference/features/public/#networking-layer-23","text":"Kna1 Sto2 Fra1 Dx1 Tky1 IPv4 (with NAT) IPv6 VPN (IPsec with PSK)","title":"Networking (Layer 2/3)"},{"location":"reference/features/public/#load-balancers","text":"Kna1 Sto2 Fra1 Dx1 Tky1 Transport layer (TCP/UDP) Application layer (HTTP) Application layer ( HTTPS, with secrets management for TLS certificates )","title":"Load Balancers"},{"location":"reference/features/public/#kubernetes-management","text":"Kna1 Sto2 Fra1 Dx1 Tky1 OpenStack Magnum Gardener","title":"Kubernetes management"},{"location":"reference/flavors/","text":"Flavors Any server instance running in Cleura Cloud has a flavor , which defines the number of virtual CPU cores, the amount of virtual RAM, and other performance-related factors. Naming convention Flavor names in Cleura Cloud follow a convention, which can be summarized as X.YcZgb : X stands for a lowercase letter identifying the compute tier , with b representing the general-purpose tier. It is always followed by a full-stop ( . ). Y stands for the number of virtual CPU cores. This number is always followed by the letter c . Z stands for the allocated amount of virtual RAM, in gibibytes . This number is always followed by the string gb . For example, the flavor named b.4c32gb would be used for a general-purpose compute instance with 4 cores and 32 GiB RAM. Compute tiers Cleura Cloud defines the following compute tiers: b : General purpose. This is the default compute tier. Instances launched with matching flavors use highly available network-attached storage. This makes them flexible to migrate within the Cleura Cloud infrastructure, without interruption. Some limitations apply to instances with attached encrypted volumes . s : High-performance local storage. Instances launched with matching flavors use local, directly-attached storage. This generally provides higher throughput and lower latency for I/O intensive applications, but instances launched with these flavors must configure their own high availability and data replication. c : Dedicated CPU. Instances launched with matching flavors are guaranteed to run on compute hardware where CPU cores are allocated to instances on a one-to-one basis and one virtual core maps directly to a physical CPU core. g : Virtual GPU. Instances launched with matching flavors have access to a GPU . Some tiers are only available in select Cleura Cloud regions. For details on tier availability, see the Feature support matrix . The general-purpose tier is always available to all Cleura Cloud customers. For access to other tiers, contact our Service Center .","title":"Flavors"},{"location":"reference/flavors/#flavors","text":"Any server instance running in Cleura Cloud has a flavor , which defines the number of virtual CPU cores, the amount of virtual RAM, and other performance-related factors.","title":"Flavors"},{"location":"reference/flavors/#naming-convention","text":"Flavor names in Cleura Cloud follow a convention, which can be summarized as X.YcZgb : X stands for a lowercase letter identifying the compute tier , with b representing the general-purpose tier. It is always followed by a full-stop ( . ). Y stands for the number of virtual CPU cores. This number is always followed by the letter c . Z stands for the allocated amount of virtual RAM, in gibibytes . This number is always followed by the string gb . For example, the flavor named b.4c32gb would be used for a general-purpose compute instance with 4 cores and 32 GiB RAM.","title":"Naming convention"},{"location":"reference/flavors/#compute-tiers","text":"Cleura Cloud defines the following compute tiers: b : General purpose. This is the default compute tier. Instances launched with matching flavors use highly available network-attached storage. This makes them flexible to migrate within the Cleura Cloud infrastructure, without interruption. Some limitations apply to instances with attached encrypted volumes . s : High-performance local storage. Instances launched with matching flavors use local, directly-attached storage. This generally provides higher throughput and lower latency for I/O intensive applications, but instances launched with these flavors must configure their own high availability and data replication. c : Dedicated CPU. Instances launched with matching flavors are guaranteed to run on compute hardware where CPU cores are allocated to instances on a one-to-one basis and one virtual core maps directly to a physical CPU core. g : Virtual GPU. Instances launched with matching flavors have access to a GPU . Some tiers are only available in select Cleura Cloud regions. For details on tier availability, see the Feature support matrix . The general-purpose tier is always available to all Cleura Cloud customers. For access to other tiers, contact our Service Center .","title":"Compute tiers"},{"location":"reference/versions/","text":"Service version matrix Services in Cleura Cloud are updated on a regular basis and on a rolling schedule. This section lists the cloud API service versions available in each Cleura Cloud region. Public Cloud : versions running in our Cleura Public Cloud regions. Compliant Cloud : versions running in our Cleura Compliant Cloud regions. OpenStack Services OpenStack releases are named, in alphabetical order, and occur on a six-month release schedule. In Cleura Public Cloud we upgrade OpenStack releases annually; this means that we deploy every other OpenStack release and skip the intervening one. Cleura Cloud currently runs OpenStack Xena . Ceph Services Ceph major releases are also named, in alphabetical order, and occur on a roughly annual schedule. Cleura Cloud currently runs Ceph Pacific .","title":"Service version matrix"},{"location":"reference/versions/#service-version-matrix","text":"Services in Cleura Cloud are updated on a regular basis and on a rolling schedule. This section lists the cloud API service versions available in each Cleura Cloud region. Public Cloud : versions running in our Cleura Public Cloud regions. Compliant Cloud : versions running in our Cleura Compliant Cloud regions.","title":"Service version matrix"},{"location":"reference/versions/#openstack-services","text":"OpenStack releases are named, in alphabetical order, and occur on a six-month release schedule. In Cleura Public Cloud we upgrade OpenStack releases annually; this means that we deploy every other OpenStack release and skip the intervening one. Cleura Cloud currently runs OpenStack Xena .","title":"OpenStack Services"},{"location":"reference/versions/#ceph-services","text":"Ceph major releases are also named, in alphabetical order, and occur on a roughly annual schedule. Cleura Cloud currently runs Ceph Pacific .","title":"Ceph Services"},{"location":"reference/versions/compliant/","text":"Compliant Cloud OpenStack Services Sto1HS Sto2HS Barbican (secret storage) Xena Xena Cinder (block storage) Xena Xena Glance (image management) Xena Xena Heat (orchestration) Xena Xena Keystone (identity management) Xena Xena Magnum (container management) Xena Xena Neutron (networking) Xena Xena Nova (server virtualization) Xena Xena Octavia (load balancing) Xena Xena Ceph Services Sto1HS Sto2HS Block storage (for OpenStack) Pacific Pacific Object storage (Swift API) Pacific Pacific Object storage (S3 API) Pacific Pacific","title":"Compliant Cloud"},{"location":"reference/versions/compliant/#compliant-cloud","text":"","title":"Compliant Cloud"},{"location":"reference/versions/compliant/#openstack-services","text":"Sto1HS Sto2HS Barbican (secret storage) Xena Xena Cinder (block storage) Xena Xena Glance (image management) Xena Xena Heat (orchestration) Xena Xena Keystone (identity management) Xena Xena Magnum (container management) Xena Xena Neutron (networking) Xena Xena Nova (server virtualization) Xena Xena Octavia (load balancing) Xena Xena","title":"OpenStack Services"},{"location":"reference/versions/compliant/#ceph-services","text":"Sto1HS Sto2HS Block storage (for OpenStack) Pacific Pacific Object storage (Swift API) Pacific Pacific Object storage (S3 API) Pacific Pacific","title":"Ceph Services"},{"location":"reference/versions/public/","text":"Public Cloud OpenStack Services Kna1 Sto2 Fra1 Dx1 Tky1 Barbican (secret storage) Xena Xena Xena Xena Xena Cinder (block storage) Xena Xena Xena Xena Xena Glance (image management) Xena Xena Xena Xena Xena Heat (orchestration) Xena Xena Xena Xena Xena Keystone (identity management) Xena Xena Xena Xena Xena Magnum (container management) Xena Xena Xena Xena Xena Neutron (networking) Xena Xena Xena Xena Xena Nova (server virtualization) Xena Xena Xena Xena Xena Octavia (load balancing) Xena Xena Xena Xena Xena Ceph Services Kna1 Sto2 Fra1 Dx1 Tky1 Block storage (for OpenStack) Pacific Pacific Pacific Pacific Pacific Object storage (Swift API) Pacific Pacific Pacific Object storage (S3 API) Pacific Pacific Pacific","title":"Public Cloud"},{"location":"reference/versions/public/#public-cloud","text":"","title":"Public Cloud"},{"location":"reference/versions/public/#openstack-services","text":"Kna1 Sto2 Fra1 Dx1 Tky1 Barbican (secret storage) Xena Xena Xena Xena Xena Cinder (block storage) Xena Xena Xena Xena Xena Glance (image management) Xena Xena Xena Xena Xena Heat (orchestration) Xena Xena Xena Xena Xena Keystone (identity management) Xena Xena Xena Xena Xena Magnum (container management) Xena Xena Xena Xena Xena Neutron (networking) Xena Xena Xena Xena Xena Nova (server virtualization) Xena Xena Xena Xena Xena Octavia (load balancing) Xena Xena Xena Xena Xena","title":"OpenStack Services"},{"location":"reference/versions/public/#ceph-services","text":"Kna1 Sto2 Fra1 Dx1 Tky1 Block storage (for OpenStack) Pacific Pacific Pacific Pacific Pacific Object storage (Swift API) Pacific Pacific Pacific Object storage (S3 API) Pacific Pacific Pacific","title":"Ceph Services"},{"location":"tutorials/","text":"About our tutorials Our tutorials are gentle introductions to Cleura Cloud. They generally require very little prior knowledge and assume only that you have access to a browser, or to a terminal. We group these into two major categories: Browser-based tutorials get you started on Cleura Cloud using the Cleura Cloud Management Panel . Terminal-based tutorials introduce you to command-line interfaces (CLIs) and their interaction with Cleura Cloud\u2019s web-based Application Programming Interfaces (APIs). This section does not include detailed walkthroughs of specific technical tasks. For those, please see our How-To Guides section. If you find our tutorials helpful, you might also be interested in our self-paced online training courses, available from our course booking site .","title":"About our tutorials"},{"location":"tutorials/#about-our-tutorials","text":"Our tutorials are gentle introductions to Cleura Cloud. They generally require very little prior knowledge and assume only that you have access to a browser, or to a terminal. We group these into two major categories: Browser-based tutorials get you started on Cleura Cloud using the Cleura Cloud Management Panel . Terminal-based tutorials introduce you to command-line interfaces (CLIs) and their interaction with Cleura Cloud\u2019s web-based Application Programming Interfaces (APIs). This section does not include detailed walkthroughs of specific technical tasks. For those, please see our How-To Guides section. If you find our tutorials helpful, you might also be interested in our self-paced online training courses, available from our course booking site .","title":"About our tutorials"}]}