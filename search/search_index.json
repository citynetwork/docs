{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Start Here This is the Cleura Beta documentation web site. We are currently in the process of migrating our Knowledge Base and other documentation to this site. If you want to help, here\u2019s how!","title":"Start Here"},{"location":"#start-here","text":"This is the Cleura Beta documentation web site. We are currently in the process of migrating our Knowledge Base and other documentation to this site. If you want to help, here\u2019s how!","title":"Start Here"},{"location":"concepts/","text":"Concepts and Background This section contains conceptual and background information about Cleura and the services we support. This is not so much about how you do something (for that, please see our How-To Guides ), more about why things work in a certain way, or why we have implemented them in a particular way in Cleura.","title":"Concepts and Background"},{"location":"concepts/#concepts-and-background","text":"This section contains conceptual and background information about Cleura and the services we support. This is not so much about how you do something (for that, please see our How-To Guides ), more about why things work in a certain way, or why we have implemented them in a particular way in Cleura.","title":"Concepts and Background"},{"location":"contrib/","text":"Contribution Guide See something on this site that is inaccurate, missing, or that could simply be improved? There are multiple ways for you to help make this site better, and we welcome all of them. You can make modifications and contributions using Git , and we apply certain checks to ensure consistent documentation quality. Technical Writing Resources Whether you are an experienced technical writer, a regular (or not-so-regular) open source contributor, or you\u2019re making your very first writing contribution, there are a ton of helpful resources on technical writing. Here are a few: Digital Ocean \u2019s Technical Writing Guidelines Red Hat \u2019s Writing Style Guide Gareth Dwyer \u2019s Technical Writing repository Bolaji Ayodeji \u2019s Awesome Technical Writing collection Markdown The documentation on this site uses Markdown . Markdown is a documentation format that is rich enough to be useful for good technical documentation, and yet simpler and easier to learn than other formats like reStructuredText or DocBook XML. If you\u2019re unfamiliar with Markdown, you can read up on its basics in this classic article by John Gruber if you\u2019re interested, but chances are that you\u2019ll also find all the information you\u2019ll need in this cheat sheet by Adam Pritchard , or the Start Writing guide from GitHub . Or you simply look at the source of one of the pages on this site (try the Edit button on this one!) and figure it out as you go along \u2014 it\u2019s really pretty straightforward. License With the sole exception of trademarks like \u201cCleura\u201d and the Cleura logo, the content on this site is available under the Creative Commons Attribution-ShareAlike 4.0 International license , as you can see from the icon at the bottom of each page. Please keep in mind that you are making your contribution under those terms.","title":"Contribution Guide"},{"location":"contrib/#contribution-guide","text":"See something on this site that is inaccurate, missing, or that could simply be improved? There are multiple ways for you to help make this site better, and we welcome all of them. You can make modifications and contributions using Git , and we apply certain checks to ensure consistent documentation quality.","title":"Contribution Guide"},{"location":"contrib/#technical-writing-resources","text":"Whether you are an experienced technical writer, a regular (or not-so-regular) open source contributor, or you\u2019re making your very first writing contribution, there are a ton of helpful resources on technical writing. Here are a few: Digital Ocean \u2019s Technical Writing Guidelines Red Hat \u2019s Writing Style Guide Gareth Dwyer \u2019s Technical Writing repository Bolaji Ayodeji \u2019s Awesome Technical Writing collection","title":"Technical Writing Resources"},{"location":"contrib/#markdown","text":"The documentation on this site uses Markdown . Markdown is a documentation format that is rich enough to be useful for good technical documentation, and yet simpler and easier to learn than other formats like reStructuredText or DocBook XML. If you\u2019re unfamiliar with Markdown, you can read up on its basics in this classic article by John Gruber if you\u2019re interested, but chances are that you\u2019ll also find all the information you\u2019ll need in this cheat sheet by Adam Pritchard , or the Start Writing guide from GitHub . Or you simply look at the source of one of the pages on this site (try the Edit button on this one!) and figure it out as you go along \u2014 it\u2019s really pretty straightforward.","title":"Markdown"},{"location":"contrib/#license","text":"With the sole exception of trademarks like \u201cCleura\u201d and the Cleura logo, the content on this site is available under the Creative Commons Attribution-ShareAlike 4.0 International license , as you can see from the icon at the bottom of each page. Please keep in mind that you are making your contribution under those terms.","title":"License"},{"location":"contrib/modifications/","text":"Modifying content on this site You have two options for editing content: directly in your browser using GitHub, or using a Git-based workflow from your local work environment. Modifying content from your browser Every page on this site has an Edit button \ud83d\udd8d\ufe0f. If you click it, it\u2019ll take you straight to the corresponding source page in GitHub. Then, you can follow GitHub\u2019s documentation on how to propose changes to another user\u2019s repository. Modifying content using Git The Git repository for this site lives at https://github.com/citynetwork/docs . You can fork that repository , make the proposed changes in your fork, and then send us a standard GitHub pull request . For this purpose, use git in combination with either GitHub\u2019s web interface, or the gh command-line interface (CLI). First, create a fork of the documentation repository: git client and web browser gh client Open https://github.com/citynetwork/docs and click the Fork button. When you create your new fork, it\u2019s fine to leave the Copy the main branch only option enabled. Then, proceed to create a new local checkout of your fork: git clone git@github.com:<yourusername>/<your-repo-fork> cleura-docs cd cleura-docs gh repo fork --clone https://github.com/citynetwork/docs -- cleura-docs cd cleura-docs Next, create a local topic branch and make your modifications: git checkout -b <your-topic-branch-name> # edit your files git add <files-to-add> git commit Please see our notes on commit messages . Finally, create a pull request (PR) from your changes: git client and web browser gh client Run the following git command (assuming origin is the remote that points to your fork): git push origin <your-topic-branch-name> Then, open your browser to the URL suggested by the git push command, and proceed to create a pull request. gh pr create --fill Monitoring changes as you edit To see your changes as you work on them, you can use tox . Having created a topic branch with your modifications, run: cd cleura-docs git checkout <your-topic-branch-name> tox -e serve A local copy of the documentation will then run on your local machine and be accessible from http://localhost:8000 in your browser. When you are planning to make several changes in rapid succession, you may want to speed up rendering the site after each change. You may do so by disabling a plugin that checks all links (including external links) for accessibility: cd cleura-docs export DOCS_ENABLE_HTMLPROOFER = false tox -e serve","title":"Modifying content on this site"},{"location":"contrib/modifications/#modifying-content-on-this-site","text":"You have two options for editing content: directly in your browser using GitHub, or using a Git-based workflow from your local work environment.","title":"Modifying content on this site"},{"location":"contrib/modifications/#modifying-content-from-your-browser","text":"Every page on this site has an Edit button \ud83d\udd8d\ufe0f. If you click it, it\u2019ll take you straight to the corresponding source page in GitHub. Then, you can follow GitHub\u2019s documentation on how to propose changes to another user\u2019s repository.","title":"Modifying content from your browser"},{"location":"contrib/modifications/#modifying-content-using-git","text":"The Git repository for this site lives at https://github.com/citynetwork/docs . You can fork that repository , make the proposed changes in your fork, and then send us a standard GitHub pull request . For this purpose, use git in combination with either GitHub\u2019s web interface, or the gh command-line interface (CLI). First, create a fork of the documentation repository: git client and web browser gh client Open https://github.com/citynetwork/docs and click the Fork button. When you create your new fork, it\u2019s fine to leave the Copy the main branch only option enabled. Then, proceed to create a new local checkout of your fork: git clone git@github.com:<yourusername>/<your-repo-fork> cleura-docs cd cleura-docs gh repo fork --clone https://github.com/citynetwork/docs -- cleura-docs cd cleura-docs Next, create a local topic branch and make your modifications: git checkout -b <your-topic-branch-name> # edit your files git add <files-to-add> git commit Please see our notes on commit messages . Finally, create a pull request (PR) from your changes: git client and web browser gh client Run the following git command (assuming origin is the remote that points to your fork): git push origin <your-topic-branch-name> Then, open your browser to the URL suggested by the git push command, and proceed to create a pull request. gh pr create --fill","title":"Modifying content using Git"},{"location":"contrib/modifications/#monitoring-changes-as-you-edit","text":"To see your changes as you work on them, you can use tox . Having created a topic branch with your modifications, run: cd cleura-docs git checkout <your-topic-branch-name> tox -e serve A local copy of the documentation will then run on your local machine and be accessible from http://localhost:8000 in your browser. When you are planning to make several changes in rapid succession, you may want to speed up rendering the site after each change. You may do so by disabling a plugin that checks all links (including external links) for accessibility: cd cleura-docs export DOCS_ENABLE_HTMLPROOFER = false tox -e serve","title":"Monitoring changes as you edit"},{"location":"contrib/quality/","text":"Quality checks There are a few checks that we apply to the configuration of this site. These checks run automatically via GitHub Actions workflows when you send your PR : We check the commit message with gitlint , and enforce the Conventional Commits commit message style. We check whether the documentation still builds correctly, with your change applied. We check to make sure that no internal or external links in the documentation are dead. This is one example where the checks might fail through no fault of yours \u2014 some external link may have disappeared between the most recent change and your contribution, by pure coincidence. When that happens, we\u2019ll fix it together. We check some YAML conventions with yamllint . However, most contributions would probably only touch Markdown files and not YAML, so you\u2019re unlikely to trip over this. If you\u2019re working in your local Git repository and your work environment has tox installed, you can also run the checks locally: tox You can also configure your local checkout to run quality checks on each commit. To do that, run: git config core.hooksPath .githooks","title":"Quality checks"},{"location":"contrib/quality/#quality-checks","text":"There are a few checks that we apply to the configuration of this site. These checks run automatically via GitHub Actions workflows when you send your PR : We check the commit message with gitlint , and enforce the Conventional Commits commit message style. We check whether the documentation still builds correctly, with your change applied. We check to make sure that no internal or external links in the documentation are dead. This is one example where the checks might fail through no fault of yours \u2014 some external link may have disappeared between the most recent change and your contribution, by pure coincidence. When that happens, we\u2019ll fix it together. We check some YAML conventions with yamllint . However, most contributions would probably only touch Markdown files and not YAML, so you\u2019re unlikely to trip over this. If you\u2019re working in your local Git repository and your work environment has tox installed, you can also run the checks locally: tox You can also configure your local checkout to run quality checks on each commit. To do that, run: git config core.hooksPath .githooks","title":"Quality checks"},{"location":"howto/","text":"About our How-To guides In this section you\u2019ll find details about how you can accomplish specific tasks in Cleura and the services we support. There are several categories of How-To guides, and they tend to be focused on a specific cloud technology. Getting Started How-Tos help you create an account in Cleura Cloud, and start using our services. Kubernetes How-Tos covering how you can create and manage your Kubernetes deployments using Cleura Cloud Control Panel. Object storage How-Tos dealing with the S3 and Swift object storage APIs, and how you can use them for object storage in Cleura. OpenStack CLI/API How-Tos covering tasks that you can accomplish with the OpenStack command line interfaces and application programming interfaces. They generally do not depend on any adjacent services or tools, just your Cleura OpenStack credentials, the openstack client, and/or the native OpenStack APIs.","title":"About our How-To guides"},{"location":"howto/#about-our-how-to-guides","text":"In this section you\u2019ll find details about how you can accomplish specific tasks in Cleura and the services we support. There are several categories of How-To guides, and they tend to be focused on a specific cloud technology. Getting Started How-Tos help you create an account in Cleura Cloud, and start using our services. Kubernetes How-Tos covering how you can create and manage your Kubernetes deployments using Cleura Cloud Control Panel. Object storage How-Tos dealing with the S3 and Swift object storage APIs, and how you can use them for object storage in Cleura. OpenStack CLI/API How-Tos covering tasks that you can accomplish with the OpenStack command line interfaces and application programming interfaces. They generally do not depend on any adjacent services or tools, just your Cleura OpenStack credentials, the openstack client, and/or the native OpenStack APIs.","title":"About our How-To guides"},{"location":"howto/getting-started/create-account/","text":"Creating a new account in Cleura Cloud To gain access to the Cleura Cloud Control Panel, you first have to create a new account. For that, navigate to https://cleura.cloud . At the bottom right-hand side of the page, click on the Create account button. Select the new account type (that would be Company or Private ), carefully type in a valid email address, and choose your country. At your leisure, please read the City Network General Terms And Conditions and our Data Processing Agreement . Agree to these documents (select Yes ), check the I\u2019m not a robot box, and then click on the Create button. This will redirect you to the Cleura Cloud Control Panel, and since you are logging in from a new account for the first time, you now have to take three simple steps. Step 1 - Confirm your email . Check your inbox or your SPAM/junk folder for an email from no-reply@cleura.com with the subject Thank you for your registration - Cleura Cloud . Open that email and click on the link in the message body. Step 2 - Account information . After clicking on the confirmation link you move on to step two, where you enter all relevant information that uniquely identifies the brand-new account. Type in, for example, a username for the account user, and make sure you define a strong password for them. (A password manager may come in handy.) Please note that all fields are mandatory, so take a little time and fill them in accordingly. Should you have a rebate code, do not forget to click on I have a rebate code and type it in below. When you are done, click on the Save button. Step 3 - Account verification . While the new account is being created, and before it becomes fully operational, you have to take one last step toward verification. You do that either by entering valid credit card information or by placing a simple phone call. Should you choose to verify by credit card, rest assured that no charge will take place \u2014 no money will be drawn from the card, in other words. On the other hand, if you prefer to verify by phone, you may certainly do so during business hours (08:00 \u2013 17:00 CET/CEST UTC+1/UTC+2). If you choose to call, please remember that you will be asked for the username of the new account, so have that piece of info handy. After the account verification is complete, you are greeted by the Cleura Cloud Control Panel. Feel free to follow through the introductory guide to the environment \u2014 that will not take long \u2014 or skip it and start taking advantage of the Cleura Cloud without delay.","title":"Creating a new account in Cleura Cloud"},{"location":"howto/getting-started/create-account/#creating-a-new-account-in-cleura-cloud","text":"To gain access to the Cleura Cloud Control Panel, you first have to create a new account. For that, navigate to https://cleura.cloud . At the bottom right-hand side of the page, click on the Create account button. Select the new account type (that would be Company or Private ), carefully type in a valid email address, and choose your country. At your leisure, please read the City Network General Terms And Conditions and our Data Processing Agreement . Agree to these documents (select Yes ), check the I\u2019m not a robot box, and then click on the Create button. This will redirect you to the Cleura Cloud Control Panel, and since you are logging in from a new account for the first time, you now have to take three simple steps. Step 1 - Confirm your email . Check your inbox or your SPAM/junk folder for an email from no-reply@cleura.com with the subject Thank you for your registration - Cleura Cloud . Open that email and click on the link in the message body. Step 2 - Account information . After clicking on the confirmation link you move on to step two, where you enter all relevant information that uniquely identifies the brand-new account. Type in, for example, a username for the account user, and make sure you define a strong password for them. (A password manager may come in handy.) Please note that all fields are mandatory, so take a little time and fill them in accordingly. Should you have a rebate code, do not forget to click on I have a rebate code and type it in below. When you are done, click on the Save button. Step 3 - Account verification . While the new account is being created, and before it becomes fully operational, you have to take one last step toward verification. You do that either by entering valid credit card information or by placing a simple phone call. Should you choose to verify by credit card, rest assured that no charge will take place \u2014 no money will be drawn from the card, in other words. On the other hand, if you prefer to verify by phone, you may certainly do so during business hours (08:00 \u2013 17:00 CET/CEST UTC+1/UTC+2). If you choose to call, please remember that you will be asked for the username of the new account, so have that piece of info handy. After the account verification is complete, you are greeted by the Cleura Cloud Control Panel. Feel free to follow through the introductory guide to the environment \u2014 that will not take long \u2014 or skip it and start taking advantage of the Cleura Cloud without delay.","title":"Creating a new account in Cleura Cloud"},{"location":"howto/getting-started/enable-openstack-cli/","text":"Enabling the OpenStack CLI The OpenStack Command Line Interface (CLI) tool, also known as OpenStack Client (OSC) or simply openstack , conveniently provides access to various OpenStack APIs. Using the OpenStack CLI tool, you can remotely create and manage the lifecycle of objects related, for example, to Compute, Networking, or Storage. Before installing openstack to your local laptop or workstation, you first need to have an OpenStack user in your Cleura account. Next, you create and download a special RC file onto your computer, modify it to reflect your OpenStack user\u2019s credentials, and source it. Only then will you be able to use any installed openstack client. Creating an OpenStack user From your favorite web browser, navigate to the Cleura Cloud page, and login into your Cleura account. Please make sure the left-hand side pane on the Cleura Cloud Control Panel is fully visible, click the Users category to expand it, and click on Openstack Users . Then, at the top right-hand side of the Cleura Cloud Control Panel, click once more the Add new Openstack user option. A new pane will slide into view, titled Create Openstack User . Type in a username and a password for the new OpenStack user. To ensure you typed the password correctly, you must re-type it below. This password should be adequately strong, and thus a password manager may come in handy. Scroll down a bit, so the Regions section is in full view. Expand one or more of the available regions you want your new user to have access to. For each one of the expanded regions, select one or more Projects . For each project, activate one or more Roles . (Hint: For an overview of the rights that roles provide, hover the mouse pointer over the exclamation mark icon by the Roles .) Optionally, type in a description for the new OpenStack user. Then, create the user by clicking the green Create button below the Description box. The new OpenStack user will be ready in just a few seconds. At any time, you can view all available OpenStack users by going to the left-hand side pane on the Cleura Cloud Control Panel and selecting Users > Openstack Users . Creating and downloading an RC file On the Cleura Cloud Control Panel expand the left-hand side pane, click Users and then Openstack Users . You will then see, listed in the main pane titled Openstack Users , all available users. Click on the three-dotted round icon on the right of the user you want to create an RC file for. From the pop-up that appears, select Generate RC file . The RC file will be generated automatically. Before downloading it onto your local computer, you must select one of the available projects to relate the RC file to. Do so and then click the blue Download button. A \u201cSave as\u201d dialog window appears, specific to the operating system you are currently using. Select a convenient location and save your RC file. Modifying and sourcing the RC file The general naming for RC files goes like this: your_username--region_name--project_name--rc So, assuming your username is olafsdottir , and the RC file has been created for the fra1 region and the katla project, your RC file name should be this: olafsdottir--fra1--katla--rc Take a look at the contents of this file \u2014 they should be like this: export OS_USERNAME = olafsdottir export OS_PASSWORD = <your password goes here> export OS_AUTH_URL = https://fra1.citycloud.com:5000 export OS_USER_DOMAIN_NAME = ... export OS_PROJECT_DOMAIN_NAME = ... export OS_REGION_NAME = Fra1 export OS_PROJECT_NAME = \"katla\" export OS_TENANT_NAME = \"katla\" export OS_AUTH_VERSION = 3 export OS_IDENTITY_API_VERSION = 3 Before you source the RC file, and thus initialize all relevant environment variables, make sure to edit the file and put your OpenStack user password in place of <your password goes here> . Also, change the permissions of the file, so it is readable and writable by your local user only: chmod 600 olafsdottir--fra1--katla--rc Then, go ahead and source it: source olafsdottir--fra1--katla--rc Installing the OpenStack CLI If you do not have the OpenStack CLI tool readily available, use your operating system\u2019s package manager or pip to install it. Some examples follow. Debian/Ubuntu Mac OS X with Homebrew Python package apt update && apt install python3-openstackclient brew install openstackclient pip install python-openstackclient Testing access Provided you have already sourced your RC file, you can now use the openstack command line tool to access various OpenStack APIs on the Cleura Cloud. To make sure your local installation of openstack works as expected, type: openstack token issue If openstack can indeed connect to the Cleura Cloud OpenStack APIs, then you will get information, in tabular format, regarding the issuance of a new token. To get general help regarding openstack , type: openstack --help When you need help on a specific command, type something like openstack help command .","title":"Enabling the OpenStack CLI"},{"location":"howto/getting-started/enable-openstack-cli/#enabling-the-openstack-cli","text":"The OpenStack Command Line Interface (CLI) tool, also known as OpenStack Client (OSC) or simply openstack , conveniently provides access to various OpenStack APIs. Using the OpenStack CLI tool, you can remotely create and manage the lifecycle of objects related, for example, to Compute, Networking, or Storage. Before installing openstack to your local laptop or workstation, you first need to have an OpenStack user in your Cleura account. Next, you create and download a special RC file onto your computer, modify it to reflect your OpenStack user\u2019s credentials, and source it. Only then will you be able to use any installed openstack client.","title":"Enabling the OpenStack CLI"},{"location":"howto/getting-started/enable-openstack-cli/#creating-an-openstack-user","text":"From your favorite web browser, navigate to the Cleura Cloud page, and login into your Cleura account. Please make sure the left-hand side pane on the Cleura Cloud Control Panel is fully visible, click the Users category to expand it, and click on Openstack Users . Then, at the top right-hand side of the Cleura Cloud Control Panel, click once more the Add new Openstack user option. A new pane will slide into view, titled Create Openstack User . Type in a username and a password for the new OpenStack user. To ensure you typed the password correctly, you must re-type it below. This password should be adequately strong, and thus a password manager may come in handy. Scroll down a bit, so the Regions section is in full view. Expand one or more of the available regions you want your new user to have access to. For each one of the expanded regions, select one or more Projects . For each project, activate one or more Roles . (Hint: For an overview of the rights that roles provide, hover the mouse pointer over the exclamation mark icon by the Roles .) Optionally, type in a description for the new OpenStack user. Then, create the user by clicking the green Create button below the Description box. The new OpenStack user will be ready in just a few seconds. At any time, you can view all available OpenStack users by going to the left-hand side pane on the Cleura Cloud Control Panel and selecting Users > Openstack Users .","title":"Creating an OpenStack user"},{"location":"howto/getting-started/enable-openstack-cli/#creating-and-downloading-an-rc-file","text":"On the Cleura Cloud Control Panel expand the left-hand side pane, click Users and then Openstack Users . You will then see, listed in the main pane titled Openstack Users , all available users. Click on the three-dotted round icon on the right of the user you want to create an RC file for. From the pop-up that appears, select Generate RC file . The RC file will be generated automatically. Before downloading it onto your local computer, you must select one of the available projects to relate the RC file to. Do so and then click the blue Download button. A \u201cSave as\u201d dialog window appears, specific to the operating system you are currently using. Select a convenient location and save your RC file.","title":"Creating and downloading an RC file"},{"location":"howto/getting-started/enable-openstack-cli/#modifying-and-sourcing-the-rc-file","text":"The general naming for RC files goes like this: your_username--region_name--project_name--rc So, assuming your username is olafsdottir , and the RC file has been created for the fra1 region and the katla project, your RC file name should be this: olafsdottir--fra1--katla--rc Take a look at the contents of this file \u2014 they should be like this: export OS_USERNAME = olafsdottir export OS_PASSWORD = <your password goes here> export OS_AUTH_URL = https://fra1.citycloud.com:5000 export OS_USER_DOMAIN_NAME = ... export OS_PROJECT_DOMAIN_NAME = ... export OS_REGION_NAME = Fra1 export OS_PROJECT_NAME = \"katla\" export OS_TENANT_NAME = \"katla\" export OS_AUTH_VERSION = 3 export OS_IDENTITY_API_VERSION = 3 Before you source the RC file, and thus initialize all relevant environment variables, make sure to edit the file and put your OpenStack user password in place of <your password goes here> . Also, change the permissions of the file, so it is readable and writable by your local user only: chmod 600 olafsdottir--fra1--katla--rc Then, go ahead and source it: source olafsdottir--fra1--katla--rc","title":"Modifying and sourcing the RC file"},{"location":"howto/getting-started/enable-openstack-cli/#installing-the-openstack-cli","text":"If you do not have the OpenStack CLI tool readily available, use your operating system\u2019s package manager or pip to install it. Some examples follow. Debian/Ubuntu Mac OS X with Homebrew Python package apt update && apt install python3-openstackclient brew install openstackclient pip install python-openstackclient","title":"Installing the OpenStack CLI"},{"location":"howto/getting-started/enable-openstack-cli/#testing-access","text":"Provided you have already sourced your RC file, you can now use the openstack command line tool to access various OpenStack APIs on the Cleura Cloud. To make sure your local installation of openstack works as expected, type: openstack token issue If openstack can indeed connect to the Cleura Cloud OpenStack APIs, then you will get information, in tabular format, regarding the issuance of a new token. To get general help regarding openstack , type: openstack --help When you need help on a specific command, type something like openstack help command .","title":"Testing access"},{"location":"howto/kubernetes/","text":"Kubernetes in Cleura In Cleura you can run Kubernetes in various ways. Cleura Cloud Control Panel includes management interfaces for Gardener and OpenStack Magnum . Gardener Gardener is a Kubernetes-native system that provides automated management and operation of Kubernetes clusters as a service. It allows you to create clusters and automatically handle their lifecycle operations, including configurable maintenance windows, hibernation schedules, and automatic updates to Kubernetes control plane and worker nodes. You can read more about Gardener and its capabilities on its documentation website . To learn how to use Gardener in the Cleura Cloud Control Panel, refer to Creating Kubernetes clusters using Cleura Cloud Control Panel . Magnum Magnum lets you create clusters via the OpenStack APIs. To do that, you base your configuration on a Cluster Template. In the template you define parameters that describe how the cluster will be constructed, for example worker flavors. In each our regions we offer predefined public Cluster Templates with ready to use configurations. To learn more about the templates, check out the Magnum documentation . Once you have chosen or created your Cluster Template, you move on to create a cluster based on that template. When you create the cluster, you have the possibility to define the number of nodes in your cluster, if you would like to have multiple master nodes with a load balancer in front etc.","title":"Kubernetes in Cleura"},{"location":"howto/kubernetes/#kubernetes-in-cleura","text":"In Cleura you can run Kubernetes in various ways. Cleura Cloud Control Panel includes management interfaces for Gardener and OpenStack Magnum .","title":"Kubernetes in Cleura"},{"location":"howto/kubernetes/#gardener","text":"Gardener is a Kubernetes-native system that provides automated management and operation of Kubernetes clusters as a service. It allows you to create clusters and automatically handle their lifecycle operations, including configurable maintenance windows, hibernation schedules, and automatic updates to Kubernetes control plane and worker nodes. You can read more about Gardener and its capabilities on its documentation website . To learn how to use Gardener in the Cleura Cloud Control Panel, refer to Creating Kubernetes clusters using Cleura Cloud Control Panel .","title":"Gardener"},{"location":"howto/kubernetes/#magnum","text":"Magnum lets you create clusters via the OpenStack APIs. To do that, you base your configuration on a Cluster Template. In the template you define parameters that describe how the cluster will be constructed, for example worker flavors. In each our regions we offer predefined public Cluster Templates with ready to use configurations. To learn more about the templates, check out the Magnum documentation . Once you have chosen or created your Cluster Template, you move on to create a cluster based on that template. When you create the cluster, you have the possibility to define the number of nodes in your cluster, if you would like to have multiple master nodes with a load balancer in front etc.","title":"Magnum"},{"location":"howto/kubernetes/gardener/create-shoot-cluster/","text":"Creating Kubernetes clusters using Cleura Cloud Control Panel If you want to create a Kubernetes cluster, you can do it via Cleura Cloud Control Panel using Gardener. This how-to shows you how to do that, and how to deploy a sample application on such a cluster. Prerequisites To access the cluster from your computer, you will need kubectl installed on your machine. Creating a Kubernetes cluster in Cleura Cloud Control Panel To get started, navigate to https://cleura.cloud , and in the side panel choose Kubernetes \u2192 Managed Kubernetes . You will see a Gardener page, in which you can create and manage your clusters. Click Create Kubernetes cluster . In Gardener\u2019s terminology, a Kubernetes cluster is referred as a Shoot cluster . You can see the name \u201cShoot\u201d in various places throughout the panel\u2019s UI, so it is good to know what it means. To learn more, check out Gardener architecture . In the opened form, fill in the name of the cluster and a region to see the rest of the options. Hover over question mark icons at each form field to learn more about it. For the purposes of this how-to, you can leave everything at default values and click Create at the bottom. In the form you can see a section about worker groups. This name refers to Kubernetes worker nodes. In the list of clusters, you will see your new Gardener shoot bootstrapping. The icon on the left marks the progress. Creating the cluster can take up to several minutes. Extract kubeconfig file from Shoot cluster When the Shoot cluster is up and running, you need to get a kubeconfig file to be able to access it. To do that, click on the cluster to expand its properties, and open Kubeconfig . You should now see the file\u2019s contents. You have the option to Copy Config or Rotate Kubeconfig if your credentials got compromised. Copy the content of the kubeconfig and insert it into ~/.kube/config . Create the directory and the file if needed. By default, Kubectl searches for its configuration in ~/.kube/config , but you can modify this behaviour if needed. More info here . Check if your kubectl uses the proper configuration by running: kubectl config view You should see something like this: apiVersion : v1 clusters : - cluster : certificate-authority-data : DATA+OMITTED server : https://api.test-cluster.p40698.staging-k8s.cleura.cloud name : shoot--p40698--test-cluster contexts : - context : cluster : shoot--p40698--test-cluster user : shoot--p40698--test-cluster-token name : shoot--p40698--test-cluster current-context : shoot--p40698--test-cluster kind : Config preferences : { } users : - name : shoot--p40698--test-cluster-token user : token : REDACTED Access your cluster with kubectl and deploy an application Check your available nodes by running: kubectl get nodes You should see Gardener\u2019s worker node that is available: NAME STATUS ROLES AGE VERSION shoot--p40698--test-cluster-czg4zf-z1-5d7b5-bfl7p Ready <none> 156m v1.24.3 Create a sample deployment with a Hello World application: kubectl create deployment hello-node --image = registry.k8s.io/echoserver:1.4 kubectl expose deployment hello-node --type = LoadBalancer --port = 8080 To access the created app, list the available services: kubectl get services You should get the load balancer service with its external IP and port number: NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE hello-node LoadBalancer 100.69.16.106 <External IP> 8080:32039/TCP 34m kubernetes ClusterIP 100.64.0.1 <none> 443/TCP 3h46m Open a browser and open <External IP>:8080 . You should see the page of the Hello World app.","title":"Creating Kubernetes clusters using Cleura Cloud Control Panel"},{"location":"howto/kubernetes/gardener/create-shoot-cluster/#creating-kubernetes-clusters-using-cleura-cloud-control-panel","text":"If you want to create a Kubernetes cluster, you can do it via Cleura Cloud Control Panel using Gardener. This how-to shows you how to do that, and how to deploy a sample application on such a cluster.","title":"Creating Kubernetes clusters using Cleura Cloud Control Panel"},{"location":"howto/kubernetes/gardener/create-shoot-cluster/#prerequisites","text":"To access the cluster from your computer, you will need kubectl installed on your machine.","title":"Prerequisites"},{"location":"howto/kubernetes/gardener/create-shoot-cluster/#creating-a-kubernetes-cluster-in-cleura-cloud-control-panel","text":"To get started, navigate to https://cleura.cloud , and in the side panel choose Kubernetes \u2192 Managed Kubernetes . You will see a Gardener page, in which you can create and manage your clusters. Click Create Kubernetes cluster . In Gardener\u2019s terminology, a Kubernetes cluster is referred as a Shoot cluster . You can see the name \u201cShoot\u201d in various places throughout the panel\u2019s UI, so it is good to know what it means. To learn more, check out Gardener architecture . In the opened form, fill in the name of the cluster and a region to see the rest of the options. Hover over question mark icons at each form field to learn more about it. For the purposes of this how-to, you can leave everything at default values and click Create at the bottom. In the form you can see a section about worker groups. This name refers to Kubernetes worker nodes. In the list of clusters, you will see your new Gardener shoot bootstrapping. The icon on the left marks the progress. Creating the cluster can take up to several minutes.","title":"Creating a Kubernetes cluster in Cleura Cloud Control Panel"},{"location":"howto/kubernetes/gardener/create-shoot-cluster/#extract-kubeconfig-file-from-shoot-cluster","text":"When the Shoot cluster is up and running, you need to get a kubeconfig file to be able to access it. To do that, click on the cluster to expand its properties, and open Kubeconfig . You should now see the file\u2019s contents. You have the option to Copy Config or Rotate Kubeconfig if your credentials got compromised. Copy the content of the kubeconfig and insert it into ~/.kube/config . Create the directory and the file if needed. By default, Kubectl searches for its configuration in ~/.kube/config , but you can modify this behaviour if needed. More info here . Check if your kubectl uses the proper configuration by running: kubectl config view You should see something like this: apiVersion : v1 clusters : - cluster : certificate-authority-data : DATA+OMITTED server : https://api.test-cluster.p40698.staging-k8s.cleura.cloud name : shoot--p40698--test-cluster contexts : - context : cluster : shoot--p40698--test-cluster user : shoot--p40698--test-cluster-token name : shoot--p40698--test-cluster current-context : shoot--p40698--test-cluster kind : Config preferences : { } users : - name : shoot--p40698--test-cluster-token user : token : REDACTED","title":"Extract kubeconfig file from Shoot cluster"},{"location":"howto/kubernetes/gardener/create-shoot-cluster/#access-your-cluster-with-kubectl-and-deploy-an-application","text":"Check your available nodes by running: kubectl get nodes You should see Gardener\u2019s worker node that is available: NAME STATUS ROLES AGE VERSION shoot--p40698--test-cluster-czg4zf-z1-5d7b5-bfl7p Ready <none> 156m v1.24.3 Create a sample deployment with a Hello World application: kubectl create deployment hello-node --image = registry.k8s.io/echoserver:1.4 kubectl expose deployment hello-node --type = LoadBalancer --port = 8080 To access the created app, list the available services: kubectl get services You should get the load balancer service with its external IP and port number: NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE hello-node LoadBalancer 100.69.16.106 <External IP> 8080:32039/TCP 34m kubernetes ClusterIP 100.64.0.1 <none> 443/TCP 3h46m Open a browser and open <External IP>:8080 . You should see the page of the Hello World app.","title":"Access your cluster with kubectl and deploy an application"},{"location":"howto/object-storage/s3/credentials/","text":"Working with S3-compatible credentials When you want to interact with object storage in Cleura using tools that support an Amazon S3 compatible API (such as s3cmd , rclone , the aws CLI, or the Python boto3 library), you need an S3-compatible access key ID and secret key. Creating credentials You can create a set of S3-compatible credentials with the following command: openstack ec2 credentials create This will return an Access and Secret key that you can use to populate the AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY environment variables (or whichever configuration options your application requires). Your S3-compatible credentials are always scoped to your Cleura region and project . You cannot reuse an access and secret key across multiple regions or projects. Also, your credentials are only \u201cS3-compatible\u201d in the sense that they use the same format as AWS S3 does. They are never valid against AWS S3 itself. Listing credentials You can list any previously-created credentials with: openstack ec2 credentials list Configuring your S3 API client Once you have obtained your S3-compatible access and secret key, you need to configure your S3 client with it. How exactly you do that depends on your preferred client: aws mc s3cmd Create a new profile, named after your Cleura region: aws configure set \\ --profile <region> \\ aws_access_key_id <access-key> aws configure set \\ --profile <region> \\ aws_secret_access_key <secret-key> For the aws CLI, you cannot define a region\u2019s endpoint in the profile. As such, you must add the --endpoint-url=https://s3-<region>.citycloud.com:8080 option to each aws s3api call. Create a new alias, named after your Cleura region: mc alias set <region> \\ https://s3-<region>.citycloud.com:8080 \\ <access-key> <secret-key> Once you have configured an alias like this, you are able to run bucket operations with mc using the alias/bucket syntax. s3cmd does not support configuration profiles, so you need to use a separate configuration file for each Cleura region you want to use: s3cmd -c ~/.s3cfg-<region> --configure Set your Access Key and Secret Key when prompted. Leave Default Region unchanged. Set S3 Endpoint to s3-<region>.citycloud.com:8080 . Set DNS-style bucket+hostname:port template for accessing a bucket to s3-<region>.citycloud.com:8080 as well. Set Use HTTPS protocol to Yes (the default). Configure GnuPG encryption and your HTTP proxy server, if needed. Test access with your supplied credentials. On subsequent invocations of the s3cmd CLI, always add the -c ~/.s3cfg-<region> option. Deleting credentials If at any time you need to delete a set of AWS-compatible credentials, you can do so with the following command: openstack ec2 credentials delete <access-key-id> Deleting a set of S3-compatible credentials will immediately revoke access for any applications that were using it.","title":"Working with S3-compatible credentials"},{"location":"howto/object-storage/s3/credentials/#working-with-s3-compatible-credentials","text":"When you want to interact with object storage in Cleura using tools that support an Amazon S3 compatible API (such as s3cmd , rclone , the aws CLI, or the Python boto3 library), you need an S3-compatible access key ID and secret key.","title":"Working with S3-compatible credentials"},{"location":"howto/object-storage/s3/credentials/#creating-credentials","text":"You can create a set of S3-compatible credentials with the following command: openstack ec2 credentials create This will return an Access and Secret key that you can use to populate the AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY environment variables (or whichever configuration options your application requires). Your S3-compatible credentials are always scoped to your Cleura region and project . You cannot reuse an access and secret key across multiple regions or projects. Also, your credentials are only \u201cS3-compatible\u201d in the sense that they use the same format as AWS S3 does. They are never valid against AWS S3 itself.","title":"Creating credentials"},{"location":"howto/object-storage/s3/credentials/#listing-credentials","text":"You can list any previously-created credentials with: openstack ec2 credentials list","title":"Listing credentials"},{"location":"howto/object-storage/s3/credentials/#configuring-your-s3-api-client","text":"Once you have obtained your S3-compatible access and secret key, you need to configure your S3 client with it. How exactly you do that depends on your preferred client: aws mc s3cmd Create a new profile, named after your Cleura region: aws configure set \\ --profile <region> \\ aws_access_key_id <access-key> aws configure set \\ --profile <region> \\ aws_secret_access_key <secret-key> For the aws CLI, you cannot define a region\u2019s endpoint in the profile. As such, you must add the --endpoint-url=https://s3-<region>.citycloud.com:8080 option to each aws s3api call. Create a new alias, named after your Cleura region: mc alias set <region> \\ https://s3-<region>.citycloud.com:8080 \\ <access-key> <secret-key> Once you have configured an alias like this, you are able to run bucket operations with mc using the alias/bucket syntax. s3cmd does not support configuration profiles, so you need to use a separate configuration file for each Cleura region you want to use: s3cmd -c ~/.s3cfg-<region> --configure Set your Access Key and Secret Key when prompted. Leave Default Region unchanged. Set S3 Endpoint to s3-<region>.citycloud.com:8080 . Set DNS-style bucket+hostname:port template for accessing a bucket to s3-<region>.citycloud.com:8080 as well. Set Use HTTPS protocol to Yes (the default). Configure GnuPG encryption and your HTTP proxy server, if needed. Test access with your supplied credentials. On subsequent invocations of the s3cmd CLI, always add the -c ~/.s3cfg-<region> option.","title":"Configuring your S3 API client"},{"location":"howto/object-storage/s3/credentials/#deleting-credentials","text":"If at any time you need to delete a set of AWS-compatible credentials, you can do so with the following command: openstack ec2 credentials delete <access-key-id> Deleting a set of S3-compatible credentials will immediately revoke access for any applications that were using it.","title":"Deleting credentials"},{"location":"howto/object-storage/s3/expiry/","text":"Object expiry Object expiry requires that you configure your environment with working S3-compatible credentials . You can set a bucket\u2019s lifecycle configuration such that it automatically deletes objects after a certain number of days. First, you need to create a JSON file, lifecycle.json , that contains the lifecycle configuration rule. Be sure to set Days to your desired value: { \"Rules\" : [{ \"ID\" : \"cleanup\" , \"Status\" : \"Enabled\" , \"Prefix\" : \"\" , \"Expiration\" : { \"Days\" : 5 } }] } Then, apply this lifecycle configuration to your bucket using one of the following commands: aws mc s3cmd aws --profile <region> \\ --endpoint-url = https://s3-<region>.citycloud.com:8080 \\ s3api put-bucket-lifecycle-configuration \\ --lifecycle-configuration file://lifecycle.json \\ --bucket <bucket-name> mc ilm import <region>/<bucket-name> < lifecycle.json s3cmd -c ~/.s3cfg-<region> setlifecycle lifecycle.json s3://<bucket-name>","title":"Object expiry"},{"location":"howto/object-storage/s3/expiry/#object-expiry","text":"Object expiry requires that you configure your environment with working S3-compatible credentials . You can set a bucket\u2019s lifecycle configuration such that it automatically deletes objects after a certain number of days. First, you need to create a JSON file, lifecycle.json , that contains the lifecycle configuration rule. Be sure to set Days to your desired value: { \"Rules\" : [{ \"ID\" : \"cleanup\" , \"Status\" : \"Enabled\" , \"Prefix\" : \"\" , \"Expiration\" : { \"Days\" : 5 } }] } Then, apply this lifecycle configuration to your bucket using one of the following commands: aws mc s3cmd aws --profile <region> \\ --endpoint-url = https://s3-<region>.citycloud.com:8080 \\ s3api put-bucket-lifecycle-configuration \\ --lifecycle-configuration file://lifecycle.json \\ --bucket <bucket-name> mc ilm import <region>/<bucket-name> < lifecycle.json s3cmd -c ~/.s3cfg-<region> setlifecycle lifecycle.json s3://<bucket-name>","title":"Object expiry"},{"location":"howto/object-storage/s3/sse-c/","text":"Client-side encryption (SSE-C) You can use objects encryption via S3 API, according to the Amazon SSE-C specification. This means that you need to provide an encryption/decryption key with each request to the object. You can store the encryption key in Barbican, and provide it to the S3 client at runtime. Below we will provide more detailed explanation regarding how to use this in your workloads. Requirements This guide assumes familiarity with the following tools: python-openstackclient (with the python-barbicanclient plugin), pwgen , rclone version 1.54 or later. Create encryption details According to SSE-C specification, in order to use server-side encryption, any S3 client needs to provide three pieces of information, which it includes in the request headers for each S3 request being made: Encryption algorithm: the only valid option here is AES256. Encryption key: a generated random key that we will store in Barbican. It should be valid AES key, which means that key length must be 32 bytes. Encryption key checksum: MD5 checksum of the encryption key. It\u2019s used for integrity checks. In order to generate encryption key and store it in Barbican, proceed as follows. Generate secret: secret_raw=$(pwgen 32 1) Store secret in Barbican: barbican_secret_url=$(openstack secret store --name objectSecret --algorithm aes --bit-length 256 --payload ${secret_raw} -f value -c 'Secret href') Retrieve secret from Barbican: secret=$(openstack secret get ${barbican_secret_url} -p -c Payload -f value) Managing encrypted objects in S3 (with rclone ) SSE-C encryption has been implemented/fixed with version 1.54. Prior rclone versions won\u2019t work here. Download and install the latest rclone for your distribution: https://rclone.org/downloads/ Create or retrieve your access key ID and secret key . Create a configuration file named ~/.rclone.conf , with the following content: [cleura] type = s3 provider = Ceph env_auth = false access_key_id = <access key id> secret_access_key = <secret key> endpoint = <region>.citycloud.com:8080 acl = private sse_customer_algorithm = AES256 Create an S3 bucket: rclone mkdir cleura:encrypted Sync a directory to the S3 bucket, encrypting the files it contains on upload: rclone sync ~/media/ cleura:encrypted \\ --s3-sse-customer-key=${secret} Retrieve a file from S3 and decrypt it: rclone copy cleura:encrypted/file.png \\ --s3-sse-customer-key=${secret} For more examples on how to use rclone, please use its reference documentation: https://rclone.org/docs/#subcommands","title":"Client-side encryption (SSE-C)"},{"location":"howto/object-storage/s3/sse-c/#client-side-encryption-sse-c","text":"You can use objects encryption via S3 API, according to the Amazon SSE-C specification. This means that you need to provide an encryption/decryption key with each request to the object. You can store the encryption key in Barbican, and provide it to the S3 client at runtime. Below we will provide more detailed explanation regarding how to use this in your workloads.","title":"Client-side encryption (SSE-C)"},{"location":"howto/object-storage/s3/sse-c/#requirements","text":"This guide assumes familiarity with the following tools: python-openstackclient (with the python-barbicanclient plugin), pwgen , rclone version 1.54 or later.","title":"Requirements"},{"location":"howto/object-storage/s3/sse-c/#create-encryption-details","text":"According to SSE-C specification, in order to use server-side encryption, any S3 client needs to provide three pieces of information, which it includes in the request headers for each S3 request being made: Encryption algorithm: the only valid option here is AES256. Encryption key: a generated random key that we will store in Barbican. It should be valid AES key, which means that key length must be 32 bytes. Encryption key checksum: MD5 checksum of the encryption key. It\u2019s used for integrity checks. In order to generate encryption key and store it in Barbican, proceed as follows. Generate secret: secret_raw=$(pwgen 32 1) Store secret in Barbican: barbican_secret_url=$(openstack secret store --name objectSecret --algorithm aes --bit-length 256 --payload ${secret_raw} -f value -c 'Secret href') Retrieve secret from Barbican: secret=$(openstack secret get ${barbican_secret_url} -p -c Payload -f value)","title":"Create encryption details"},{"location":"howto/object-storage/s3/sse-c/#managing-encrypted-objects-in-s3-with-rclone","text":"SSE-C encryption has been implemented/fixed with version 1.54. Prior rclone versions won\u2019t work here. Download and install the latest rclone for your distribution: https://rclone.org/downloads/ Create or retrieve your access key ID and secret key . Create a configuration file named ~/.rclone.conf , with the following content: [cleura] type = s3 provider = Ceph env_auth = false access_key_id = <access key id> secret_access_key = <secret key> endpoint = <region>.citycloud.com:8080 acl = private sse_customer_algorithm = AES256 Create an S3 bucket: rclone mkdir cleura:encrypted Sync a directory to the S3 bucket, encrypting the files it contains on upload: rclone sync ~/media/ cleura:encrypted \\ --s3-sse-customer-key=${secret} Retrieve a file from S3 and decrypt it: rclone copy cleura:encrypted/file.png \\ --s3-sse-customer-key=${secret} For more examples on how to use rclone, please use its reference documentation: https://rclone.org/docs/#subcommands","title":"Managing encrypted objects in S3 (with rclone)"},{"location":"howto/object-storage/s3/versioning/","text":"Object versioning Object versioning requires that you configure your environment with working S3-compatible credentials . Enabling bucket versioning To enable versioning in a bucket, use one of the following commands: aws mc s3cmd aws --profile <region> \\ --endpoint-url = https://s3-<region>.citycloud.com:8080 \\ s3api put-bucket-versioning \\ --versioning-configuration Status = Enabled \\ --bucket <bucket-name> mc version enable <region>/<bucket-name> This functionality is not available with the s3cmd command. Checking bucket versioning status To check whether object versioning is enabled on a bucket, use one of the following commands: aws mc s3cmd aws --profile <region> \\ --endpoint-url = https://s3-<region>.citycloud.com:8080 \\ s3api get-bucket-versioning \\ --bucket <bucket-name> mc version info <region>/<bucket-name> This functionality is not available with the s3cmd command. Creating a versioned object Once object versioning is enabled on a bucket, the normal object creation and replacement commands behave in a manner different from that in unversioned buckets: If the object does not already exist, it is created (as in an unversioned bucket). If the object does already exist, it is not replaced. Instead, a new version appears in addition to the old one. aws mc s3cmd aws --profile <region> \\ --endpoint-url = https://s3-<region>.citycloud.com:8080 \\ s3api put-object \\ --bucket <bucket-name> \\ --key <object-name> \\ --body <local-filename> mc cp \\ <local-filename> \\ <region>/<bucket-name>/<object-name> s3cmd put <local-filename> s3://<bucket> Listing object versions In a bucket that has versioning enabled, you may list the versions available for an object: aws mc s3cmd aws --profile <region> \\ --endpoint-url = https://s3-<region>.citycloud.com:8080 \\ s3api list-object-versions \\ --bucket <bucket-name> \\ --key <object-name> mc stat --versions <region>/<bucket-name> This functionality may be impacted by bugs in several versions of the mc client. This functionality is not available with the s3cmd command. Retrieving a versioned object To download a specific version of an object in a bucket, use one of the following commands: aws mc s3cmd aws --profile <region> \\ --endpoint-url = https://s3-<region>.citycloud.com:8080 \\ s3api get-object \\ --bucket <bucket-name> \\ --key <object-name> \\ --version-id <versionid> \\ <local-filename> mc cp \\ --version-id <versionid> \\ <region>/<bucket-name>/<object-name> \\ <local-filename> This functionality is not available with the s3cmd command. When you download an object from a versioned bucket without specifying a version identifier, your S3 client will download the latest version of that object. Deleting a versioned object Like the commands to create objects, the commands to delete them behave differently once object versioning is enabled on a bucket. The command to delete an object will normally not delete it, but revert it to the prior version. The exception to this rule is when there is only a single version of the object left in the bucket, in which case object removal does occur. aws mc s3cmd aws --profile <region> \\ --endpoint-url = https://s3-<region>.citycloud.com:8080 \\ s3api delete-object \\ --bucket <bucket-name> \\ --key <object-name> mc rm \\ <region>/<bucket-name>/<object-name> s3cmd del s3://<bucket-name>/<object-name> You also have the option of deleting not the latest version, but a specific object version: aws mc s3cmd aws --profile <region> \\ --endpoint-url = https://s3-<region>.citycloud.com:8080 \\ s3api delete-object \\ --version-id <versionid> \\ --bucket <bucket-name> \\ --key <object-name> mc rm \\ --version-id <versionid> \\ <region>/<bucket-name>/<object-name> This functionality is not available with the s3cmd command.","title":"Object versioning"},{"location":"howto/object-storage/s3/versioning/#object-versioning","text":"Object versioning requires that you configure your environment with working S3-compatible credentials .","title":"Object versioning"},{"location":"howto/object-storage/s3/versioning/#enabling-bucket-versioning","text":"To enable versioning in a bucket, use one of the following commands: aws mc s3cmd aws --profile <region> \\ --endpoint-url = https://s3-<region>.citycloud.com:8080 \\ s3api put-bucket-versioning \\ --versioning-configuration Status = Enabled \\ --bucket <bucket-name> mc version enable <region>/<bucket-name> This functionality is not available with the s3cmd command.","title":"Enabling bucket versioning"},{"location":"howto/object-storage/s3/versioning/#checking-bucket-versioning-status","text":"To check whether object versioning is enabled on a bucket, use one of the following commands: aws mc s3cmd aws --profile <region> \\ --endpoint-url = https://s3-<region>.citycloud.com:8080 \\ s3api get-bucket-versioning \\ --bucket <bucket-name> mc version info <region>/<bucket-name> This functionality is not available with the s3cmd command.","title":"Checking bucket versioning status"},{"location":"howto/object-storage/s3/versioning/#creating-a-versioned-object","text":"Once object versioning is enabled on a bucket, the normal object creation and replacement commands behave in a manner different from that in unversioned buckets: If the object does not already exist, it is created (as in an unversioned bucket). If the object does already exist, it is not replaced. Instead, a new version appears in addition to the old one. aws mc s3cmd aws --profile <region> \\ --endpoint-url = https://s3-<region>.citycloud.com:8080 \\ s3api put-object \\ --bucket <bucket-name> \\ --key <object-name> \\ --body <local-filename> mc cp \\ <local-filename> \\ <region>/<bucket-name>/<object-name> s3cmd put <local-filename> s3://<bucket>","title":"Creating a versioned object"},{"location":"howto/object-storage/s3/versioning/#listing-object-versions","text":"In a bucket that has versioning enabled, you may list the versions available for an object: aws mc s3cmd aws --profile <region> \\ --endpoint-url = https://s3-<region>.citycloud.com:8080 \\ s3api list-object-versions \\ --bucket <bucket-name> \\ --key <object-name> mc stat --versions <region>/<bucket-name> This functionality may be impacted by bugs in several versions of the mc client. This functionality is not available with the s3cmd command.","title":"Listing object versions"},{"location":"howto/object-storage/s3/versioning/#retrieving-a-versioned-object","text":"To download a specific version of an object in a bucket, use one of the following commands: aws mc s3cmd aws --profile <region> \\ --endpoint-url = https://s3-<region>.citycloud.com:8080 \\ s3api get-object \\ --bucket <bucket-name> \\ --key <object-name> \\ --version-id <versionid> \\ <local-filename> mc cp \\ --version-id <versionid> \\ <region>/<bucket-name>/<object-name> \\ <local-filename> This functionality is not available with the s3cmd command. When you download an object from a versioned bucket without specifying a version identifier, your S3 client will download the latest version of that object.","title":"Retrieving a versioned object"},{"location":"howto/object-storage/s3/versioning/#deleting-a-versioned-object","text":"Like the commands to create objects, the commands to delete them behave differently once object versioning is enabled on a bucket. The command to delete an object will normally not delete it, but revert it to the prior version. The exception to this rule is when there is only a single version of the object left in the bucket, in which case object removal does occur. aws mc s3cmd aws --profile <region> \\ --endpoint-url = https://s3-<region>.citycloud.com:8080 \\ s3api delete-object \\ --bucket <bucket-name> \\ --key <object-name> mc rm \\ <region>/<bucket-name>/<object-name> s3cmd del s3://<bucket-name>/<object-name> You also have the option of deleting not the latest version, but a specific object version: aws mc s3cmd aws --profile <region> \\ --endpoint-url = https://s3-<region>.citycloud.com:8080 \\ s3api delete-object \\ --version-id <versionid> \\ --bucket <bucket-name> \\ --key <object-name> mc rm \\ --version-id <versionid> \\ <region>/<bucket-name>/<object-name> This functionality is not available with the s3cmd command.","title":"Deleting a versioned object"},{"location":"howto/openstack/barbican/","text":"Using Barbican for secret storage Barbican is OpenStack\u2019s secret storage facility. In Cleura, Barbican is supported for the following purposes: Generic secret storage , encryption for persistent volumes , certificate storage for HTTPS load balancers . To manage secrets with Barbican, you will need the openstack command line interface (CLI), and its Barbican plugin. You can install them both with the following commands: pip install python-openstackclient python-barbicanclient On Debian/Ubuntu platforms, you may also install these utilities via their APT packages: apt install python3-openstackclient python3-barbicanclient","title":"Using Barbican for secret storage"},{"location":"howto/openstack/barbican/#using-barbican-for-secret-storage","text":"Barbican is OpenStack\u2019s secret storage facility. In Cleura, Barbican is supported for the following purposes: Generic secret storage , encryption for persistent volumes , certificate storage for HTTPS load balancers . To manage secrets with Barbican, you will need the openstack command line interface (CLI), and its Barbican plugin. You can install them both with the following commands: pip install python-openstackclient python-barbicanclient On Debian/Ubuntu platforms, you may also install these utilities via their APT packages: apt install python3-openstackclient python3-barbicanclient","title":"Using Barbican for secret storage"},{"location":"howto/openstack/barbican/generic-secret/","text":"Generic secret storage The simplest way to use Barbican is to create and retrieve a securely stored, generic secret. How to store a generic secret It is possible to store any secret data with Barbican. The command below will create a secret of the type passphrase , named mysecret , which contains the passphrase my very secret passphrase . openstack secret store \\ --secret-type passphrase \\ -p \"my very secret passphrase\" \\ -n mysecret The example output below uses Cleura\u2019s Fra1 region. In other regions, the secret URIs will differ. +---------------+--------------------------------------------------------------------------------+ | Field | Value | +---------------+--------------------------------------------------------------------------------+ | Secret href | https://fra1.citycloud.com:9311/v1/secrets/33ef0985-f89e-4bf0-b318-887ecac0cba | | Name | mysecret | | Created | None | | Status | None | | Content types | None | | Algorithm | aes | | Bit length | 256 | | Secret type | passphrase | | Mode | cbc | | Expiration | None | +---------------+--------------------------------------------------------------------------------+ Note that passphrase type secrets are symmetrically encrypted, using the AES encryption algorithm with a 256-bit key length. You can select other bit lengths and algorithms with the -b and -a command line options, if desired. How to retrieve secrets Secrets are stored in Barbican in an encrypted format. You can see a list of secrets created for your user with the following command: openstack secret list +--------------------------------------------------------------------------------+----------+---------------------------+--------+-----------------------------------------+-----------+------------+-------------+------+------------+ | Secret href | Name | Created | Status | Content types | Algorithm | Bit length | Secret type | Mode | Expiration | +--------------------------------------------------------------------------------+----------+---------------------------+--------+-----------------------------------------+-----------+------------+-------------+------+------------+ | https://fra1.citycloud.com:9311/v1/secrets/33ef0985-f89e-4bf0-b318-887ecac0cba | mysecret | 2021-04-29T10:33:18+00:00 | ACTIVE | {'default': 'application/octet-stream'} | aes | 256 | passphrase | cbc | None | | https://fra1.citycloud.com:9311/v1/secrets/ad628532-53b8-4d2f-91e5-0097b51da4e | None | 2021-04-27T13:52:10+00:00 | ACTIVE | {'default': 'application/octet-stream'} | aes | 256 | symmetric | None | None | +--------------------------------------------------------------------------------+----------+---------------------------+--------+-----------------------------------------+-----------+------------+-------------+------+------------+ You can retrieve the decrypted secret with the openstack secret get command, adding the -p (or --payload ) option: $ openstack secret get -p \\ https://fra1.citycloud.com:9311/v1/secrets/33ef0985-f89e-4bf0-b318-887ecac0cba +---------+---------------------------+ | Field | Value | +---------+---------------------------+ | Payload | my very secret passphrase | +---------+---------------------------+ Unlike many other OpenStack services, which allow you to retrieve object references by name or UUID, Barbican only lets you retrieve secrets by their full URI . That URI must include the https://<region>.citycloud.com:9311/v1/secrets/ prefix.","title":"Generic secret storage"},{"location":"howto/openstack/barbican/generic-secret/#generic-secret-storage","text":"The simplest way to use Barbican is to create and retrieve a securely stored, generic secret.","title":"Generic secret storage"},{"location":"howto/openstack/barbican/generic-secret/#how-to-store-a-generic-secret","text":"It is possible to store any secret data with Barbican. The command below will create a secret of the type passphrase , named mysecret , which contains the passphrase my very secret passphrase . openstack secret store \\ --secret-type passphrase \\ -p \"my very secret passphrase\" \\ -n mysecret The example output below uses Cleura\u2019s Fra1 region. In other regions, the secret URIs will differ. +---------------+--------------------------------------------------------------------------------+ | Field | Value | +---------------+--------------------------------------------------------------------------------+ | Secret href | https://fra1.citycloud.com:9311/v1/secrets/33ef0985-f89e-4bf0-b318-887ecac0cba | | Name | mysecret | | Created | None | | Status | None | | Content types | None | | Algorithm | aes | | Bit length | 256 | | Secret type | passphrase | | Mode | cbc | | Expiration | None | +---------------+--------------------------------------------------------------------------------+ Note that passphrase type secrets are symmetrically encrypted, using the AES encryption algorithm with a 256-bit key length. You can select other bit lengths and algorithms with the -b and -a command line options, if desired.","title":"How to store a generic secret"},{"location":"howto/openstack/barbican/generic-secret/#how-to-retrieve-secrets","text":"Secrets are stored in Barbican in an encrypted format. You can see a list of secrets created for your user with the following command: openstack secret list +--------------------------------------------------------------------------------+----------+---------------------------+--------+-----------------------------------------+-----------+------------+-------------+------+------------+ | Secret href | Name | Created | Status | Content types | Algorithm | Bit length | Secret type | Mode | Expiration | +--------------------------------------------------------------------------------+----------+---------------------------+--------+-----------------------------------------+-----------+------------+-------------+------+------------+ | https://fra1.citycloud.com:9311/v1/secrets/33ef0985-f89e-4bf0-b318-887ecac0cba | mysecret | 2021-04-29T10:33:18+00:00 | ACTIVE | {'default': 'application/octet-stream'} | aes | 256 | passphrase | cbc | None | | https://fra1.citycloud.com:9311/v1/secrets/ad628532-53b8-4d2f-91e5-0097b51da4e | None | 2021-04-27T13:52:10+00:00 | ACTIVE | {'default': 'application/octet-stream'} | aes | 256 | symmetric | None | None | +--------------------------------------------------------------------------------+----------+---------------------------+--------+-----------------------------------------+-----------+------------+-------------+------+------------+ You can retrieve the decrypted secret with the openstack secret get command, adding the -p (or --payload ) option: $ openstack secret get -p \\ https://fra1.citycloud.com:9311/v1/secrets/33ef0985-f89e-4bf0-b318-887ecac0cba +---------+---------------------------+ | Field | Value | +---------+---------------------------+ | Payload | my very secret passphrase | +---------+---------------------------+ Unlike many other OpenStack services, which allow you to retrieve object references by name or UUID, Barbican only lets you retrieve secrets by their full URI . That URI must include the https://<region>.citycloud.com:9311/v1/secrets/ prefix.","title":"How to retrieve secrets"},{"location":"howto/openstack/barbican/share-secret/","text":"Sharing secrets via ACLs Normally, a Barbican secret is only available to the OpenStack API user that created it. However, under some circumstances it may be desirable to make a secret available to another user. To do so, you will need the secret\u2019s URI , the other user\u2019s OpenStack API user ID. Any Cleura user can always retrieve their own user ID with the following command: openstack token issue -f value -c user_id Once you have assembled this information, you can proceed with the openstack acl user add command: openstack acl user add \\ --user <user_id> \\ --operation-type read \\ https://region.citycloud.com:9311/v1/secrets/<secret_id> If you want to unshare the secret again, you simply use the corresponding openstack acl user remove command: openstack acl user remove \\ --user <user_id> \\ --operation-type read \\ https://region.citycloud.com:9311/v1/secrets/<secret_id>","title":"Sharing secrets via ACLs"},{"location":"howto/openstack/barbican/share-secret/#sharing-secrets-via-acls","text":"Normally, a Barbican secret is only available to the OpenStack API user that created it. However, under some circumstances it may be desirable to make a secret available to another user. To do so, you will need the secret\u2019s URI , the other user\u2019s OpenStack API user ID. Any Cleura user can always retrieve their own user ID with the following command: openstack token issue -f value -c user_id Once you have assembled this information, you can proceed with the openstack acl user add command: openstack acl user add \\ --user <user_id> \\ --operation-type read \\ https://region.citycloud.com:9311/v1/secrets/<secret_id> If you want to unshare the secret again, you simply use the corresponding openstack acl user remove command: openstack acl user remove \\ --user <user_id> \\ --operation-type read \\ https://region.citycloud.com:9311/v1/secrets/<secret_id>","title":"Sharing secrets via ACLs"},{"location":"howto/openstack/cinder/encrypted-volumes/","text":"Encrypted volumes When using Barbican for block storage encryption, you ensure that data in persistent storage volumes is stored in an encrypted fashion. That encryption is transparent to virtual machines (instances) that you attach the volume to. Creating an encrypted volume For the creation of an encrypted volume, you need to provide a specific volume type. You can retrieve the list of available volume types with the following command: openstack volume type list +--------------------------------------+-----------------------+-----------+ | ID | Name | Is Public | +--------------------------------------+-----------------------+-----------+ | a479a6b0-b283-41a5-b38b-5b08e7f902ca | volumes_hdd_encrypted | True | | d9dfa98a-238d-4ca0-9abf-701fceb05623 | __DEFAULT__ | True | | 86796611-fb12-4628-b6b1-e09469e301d7 | volumes_hdd | True | +--------------------------------------+-----------------------+-----------+ In Cleura, all volume types that support encryption use the suffix _encrypted . To create a volume with encryption, you need to explicitly specify the --type option to the openstack volume create command. The following example creates a volume using the volumes_hdd_encrypted type, naming it enc_drive and setting its size to 10 GiB: openstack volume create \\ --type volumes_hdd_encrypted \\ --size 10 \\ enc_drive +---------------------+--------------------------------------+ | Field | Value | +---------------------+--------------------------------------+ | attachments | [] | | availability_zone | nova | | bootable | false | | consistencygroup_id | None | | created_at | 2021-04-27T13:52:10.000000 | | description | None | | encrypted | True | | id | 33211b21-8d4f-48e9-b76f-ec73ffd19def | | multiattach | False | | name | enc_drive | | properties | | | replication_status | None | | size | 10 | | snapshot_id | None | | source_volid | None | | status | creating | | type | volumes_hdd_encrypted | | updated_at | None | | user_id | 966ad341f4e14920b5f589f900246ccc | +---------------------+--------------------------------------+ Upon volume creation, this will create a one-off encryption key, which is stored in Barbican and applies to this one volume only. In other words, the key created for this volume will be unable to decrypt any other volumes except the one it was created for. Retrieving a volume\u2019s encryption key Once you have created an encrypted volume, you may retrieve a reference to the Barbican secret that represents its encryption key. You do this with the following command: openstack volume show \\ --os-volume-api-version 3 .66 \\ -f value \\ -c encryption_key_id \\ enc_drive Instead of the volume name, you can of course also specify its UUID: openstack volume show \\ --os-volume-api-version 3 .66 \\ -f value \\ -c encryption_key_id \\ 33211b21-8d4f-48e9-b76f-ec73ffd19def Deleting an encrypted volume When you decide you no longer need an encrypted volume and want to delete it, you can do so with the openstack volume delete command. As long as you do this with the same user account as the one that created the volume, this will succeed without further intervention. However, if you are trying to delete a volume that was created by a different user, you\u2019ll run into the limitation that the secret associated with the volume is owned by that user. As a result, the deletion of the encrypted volume using your own user credentials will fail. There are two options to work around this limitation: You can switch to the user credentials of the user that created the volume (if you have access to them), and proceed with the deletion. You can ask the user that created the volume to add you to the Access Control List (ACL) for the secret . This will enable you to read the secret, and to delete the volume using your own credentials. Block device encryption caveats Once a volume is configured to use encryption and is also attached to an instance in Cleura, some caveats apply that you might want to keep in mind. Sometimes, automatically or through administrator intervention, we move one of your instances to another physical machine. This process is known as live migration, and it normally does not interrupt the instance\u2019s functionality at all \u2014 typically, neither you nor the application users notice that live migration has even happened. This is a very common occurrence when we do routine upgrades of the Cleura platform, during our pre-announced maintenance windows. The same considerations apply to physical node failure. If the physical machine running your instance fails, we can automatically recover it onto another machine \u2014 an action known as evacuation. Live migration or evacuation including encrypted volumes does, however, require that whoever does the migration also has at least read access to the volume\u2019s encryption secret. This means that you have two options: If you do trust us to include your instances in live migrations and evacuations, even if they attach encrypted volumes, then you can add our administrative account to the Access Control List (ACL) for your secrets . If you don\u2019t want to share your secrets but you still want to use encrypted volumes, you should build your own mechanism or process (preferably automated) so that your instances recover in case they become non-functional.","title":"Encrypted volumes"},{"location":"howto/openstack/cinder/encrypted-volumes/#encrypted-volumes","text":"When using Barbican for block storage encryption, you ensure that data in persistent storage volumes is stored in an encrypted fashion. That encryption is transparent to virtual machines (instances) that you attach the volume to.","title":"Encrypted volumes"},{"location":"howto/openstack/cinder/encrypted-volumes/#creating-an-encrypted-volume","text":"For the creation of an encrypted volume, you need to provide a specific volume type. You can retrieve the list of available volume types with the following command: openstack volume type list +--------------------------------------+-----------------------+-----------+ | ID | Name | Is Public | +--------------------------------------+-----------------------+-----------+ | a479a6b0-b283-41a5-b38b-5b08e7f902ca | volumes_hdd_encrypted | True | | d9dfa98a-238d-4ca0-9abf-701fceb05623 | __DEFAULT__ | True | | 86796611-fb12-4628-b6b1-e09469e301d7 | volumes_hdd | True | +--------------------------------------+-----------------------+-----------+ In Cleura, all volume types that support encryption use the suffix _encrypted . To create a volume with encryption, you need to explicitly specify the --type option to the openstack volume create command. The following example creates a volume using the volumes_hdd_encrypted type, naming it enc_drive and setting its size to 10 GiB: openstack volume create \\ --type volumes_hdd_encrypted \\ --size 10 \\ enc_drive +---------------------+--------------------------------------+ | Field | Value | +---------------------+--------------------------------------+ | attachments | [] | | availability_zone | nova | | bootable | false | | consistencygroup_id | None | | created_at | 2021-04-27T13:52:10.000000 | | description | None | | encrypted | True | | id | 33211b21-8d4f-48e9-b76f-ec73ffd19def | | multiattach | False | | name | enc_drive | | properties | | | replication_status | None | | size | 10 | | snapshot_id | None | | source_volid | None | | status | creating | | type | volumes_hdd_encrypted | | updated_at | None | | user_id | 966ad341f4e14920b5f589f900246ccc | +---------------------+--------------------------------------+ Upon volume creation, this will create a one-off encryption key, which is stored in Barbican and applies to this one volume only. In other words, the key created for this volume will be unable to decrypt any other volumes except the one it was created for.","title":"Creating an encrypted volume"},{"location":"howto/openstack/cinder/encrypted-volumes/#retrieving-a-volumes-encryption-key","text":"Once you have created an encrypted volume, you may retrieve a reference to the Barbican secret that represents its encryption key. You do this with the following command: openstack volume show \\ --os-volume-api-version 3 .66 \\ -f value \\ -c encryption_key_id \\ enc_drive Instead of the volume name, you can of course also specify its UUID: openstack volume show \\ --os-volume-api-version 3 .66 \\ -f value \\ -c encryption_key_id \\ 33211b21-8d4f-48e9-b76f-ec73ffd19def","title":"Retrieving a volume\u2019s encryption key"},{"location":"howto/openstack/cinder/encrypted-volumes/#deleting-an-encrypted-volume","text":"When you decide you no longer need an encrypted volume and want to delete it, you can do so with the openstack volume delete command. As long as you do this with the same user account as the one that created the volume, this will succeed without further intervention. However, if you are trying to delete a volume that was created by a different user, you\u2019ll run into the limitation that the secret associated with the volume is owned by that user. As a result, the deletion of the encrypted volume using your own user credentials will fail. There are two options to work around this limitation: You can switch to the user credentials of the user that created the volume (if you have access to them), and proceed with the deletion. You can ask the user that created the volume to add you to the Access Control List (ACL) for the secret . This will enable you to read the secret, and to delete the volume using your own credentials.","title":"Deleting an encrypted volume"},{"location":"howto/openstack/cinder/encrypted-volumes/#block-device-encryption-caveats","text":"Once a volume is configured to use encryption and is also attached to an instance in Cleura, some caveats apply that you might want to keep in mind. Sometimes, automatically or through administrator intervention, we move one of your instances to another physical machine. This process is known as live migration, and it normally does not interrupt the instance\u2019s functionality at all \u2014 typically, neither you nor the application users notice that live migration has even happened. This is a very common occurrence when we do routine upgrades of the Cleura platform, during our pre-announced maintenance windows. The same considerations apply to physical node failure. If the physical machine running your instance fails, we can automatically recover it onto another machine \u2014 an action known as evacuation. Live migration or evacuation including encrypted volumes does, however, require that whoever does the migration also has at least read access to the volume\u2019s encryption secret. This means that you have two options: If you do trust us to include your instances in live migrations and evacuations, even if they attach encrypted volumes, then you can add our administrative account to the Access Control List (ACL) for your secrets . If you don\u2019t want to share your secrets but you still want to use encrypted volumes, you should build your own mechanism or process (preferably automated) so that your instances recover in case they become non-functional.","title":"Block device encryption caveats"},{"location":"howto/openstack/neutron/multiple-public-ips/","text":"Assigning multiple public (floating) IPs to a server In Cleura, we do not pass external networks to the compute nodes. This means that you, as a user, can not directly attach a server to the public network. In order to provide connectivity to the public network (for IPv4), you need to use floating IPs. A floating IP is created in the public subnet, and is mapped to the specific network port. All traffic comes through a virtual router. For some scenarios, you might need to have more than one public IP assigned to a server. But in case of 1-to-1 NAT (which is how the floating IP is implemented under the hood) you can not assign more than one external IP to the internal one. And adding a new port to the VM is also not an option, since this would result in asymmetric routing, as replies will go through the first interface for which a default route is set. Instead, you must first configure an additional private (\u201cfixed\u201d) IP address for your port, then associate a public (\u201cfloating\u201d) IP address to map to it. Add an extra IP to the port Assume you already have a network port inside your private network: $ openstack port show 51dae637-ad79-4ba9-9e41-78e5e0f3332c -c fixed_ips +-----------+--------------------------------------------------------------------------+ | Field | Value | +-----------+--------------------------------------------------------------------------+ | fixed_ips | ip_address='10.2.0.58', subnet_id='5efeae9f-06b8-41a5-987f-085e8c7113a6' | +-----------+--------------------------------------------------------------------------+ And you also have a floating IP associated with it: $ openstack floating ip list -c ID -c \"Floating IP Address\" -c \"Fixed IP Address\" -c Port +--------------------------------------+---------------------+------------------+--------------------------------------+ | ID | Floating IP Address | Fixed IP Address | Port | +--------------------------------------+---------------------+------------------+--------------------------------------+ | 989f8a96-4ab4-4190-83e4-25b71d309ea9 | 192.0.2.169 | 10.2.0.58 | 51dae637-ad79-4ba9-9e41-78e5e0f3332c | | c45a5eaf-2f3a-4679-89fe-266a5cbe840a | 198.51.100.12 | None | None | +--------------------------------------+---------------------+------------------+--------------------------------------+ Then what you need to do, is to add extra IP address to your existing port: $ openstack port set --fixed-ip subnet=5efeae9f-06b8-41a5-987f-085e8c7113a6 51dae637-ad79-4ba9-9e41-78e5e0f3332c You can then confirm that the port does have two entries in its fixed_ips list: $ openstack port show 51dae637-ad79-4ba9-9e41-78e5e0f3332c -c fixed_ips +-----------+---------------------------------------------------------------------------+ | Field | Value | +-----------+---------------------------------------------------------------------------+ | fixed_ips | ip_address='10.2.0.228', subnet_id='5efeae9f-06b8-41a5-987f-085e8c7113a6' | | | ip_address='10.2.0.58', subnet_id='5efeae9f-06b8-41a5-987f-085e8c7113a6' | +-----------+---------------------------------------------------------------------------+ Don\u2019t forget to configure new IP as an alias to the interface inside your VM! When you have an IP address on your port that is not yet assigned to any floating IP, you can assign it to the new floating IP. Proceed with: $ openstack floating ip set c45a5eaf-2f3a-4679-89fe-266a5cbe840a --port 51dae637-ad79-4ba9-9e41-78e5e0f3332c --fixed-ip-address 10.2.0.228 Then, list the floating (public) IP addresses, together with their fixed (private) counterparts: $ openstack floating ip list -c ID -c \"Floating IP Address\" -c \"Fixed IP Address\" -c Port +--------------------------------------+---------------------+------------------+--------------------------------------+ | ID | Floating IP Address | Fixed IP Address | Port | +--------------------------------------+---------------------+------------------+--------------------------------------+ | 989f8a96-4ab4-4190-83e4-25b71d309ea9 | 192.0.2.169 | 10.2.0.58 | 51dae637-ad79-4ba9-9e41-78e5e0f3332c | | c45a5eaf-2f3a-4679-89fe-266a5cbe840a | 198.51.100.12 | 10.2.0.228 | 51dae637-ad79-4ba9-9e41-78e5e0f3332c | +--------------------------------------+---------------------+------------------+--------------------------------------+ Now your server is accessible through two different public IP addresses.","title":"Assigning multiple public (floating) IPs to a server"},{"location":"howto/openstack/neutron/multiple-public-ips/#assigning-multiple-public-floating-ips-to-a-server","text":"In Cleura, we do not pass external networks to the compute nodes. This means that you, as a user, can not directly attach a server to the public network. In order to provide connectivity to the public network (for IPv4), you need to use floating IPs. A floating IP is created in the public subnet, and is mapped to the specific network port. All traffic comes through a virtual router. For some scenarios, you might need to have more than one public IP assigned to a server. But in case of 1-to-1 NAT (which is how the floating IP is implemented under the hood) you can not assign more than one external IP to the internal one. And adding a new port to the VM is also not an option, since this would result in asymmetric routing, as replies will go through the first interface for which a default route is set. Instead, you must first configure an additional private (\u201cfixed\u201d) IP address for your port, then associate a public (\u201cfloating\u201d) IP address to map to it.","title":"Assigning multiple public (floating) IPs to a server"},{"location":"howto/openstack/neutron/multiple-public-ips/#add-an-extra-ip-to-the-port","text":"Assume you already have a network port inside your private network: $ openstack port show 51dae637-ad79-4ba9-9e41-78e5e0f3332c -c fixed_ips +-----------+--------------------------------------------------------------------------+ | Field | Value | +-----------+--------------------------------------------------------------------------+ | fixed_ips | ip_address='10.2.0.58', subnet_id='5efeae9f-06b8-41a5-987f-085e8c7113a6' | +-----------+--------------------------------------------------------------------------+ And you also have a floating IP associated with it: $ openstack floating ip list -c ID -c \"Floating IP Address\" -c \"Fixed IP Address\" -c Port +--------------------------------------+---------------------+------------------+--------------------------------------+ | ID | Floating IP Address | Fixed IP Address | Port | +--------------------------------------+---------------------+------------------+--------------------------------------+ | 989f8a96-4ab4-4190-83e4-25b71d309ea9 | 192.0.2.169 | 10.2.0.58 | 51dae637-ad79-4ba9-9e41-78e5e0f3332c | | c45a5eaf-2f3a-4679-89fe-266a5cbe840a | 198.51.100.12 | None | None | +--------------------------------------+---------------------+------------------+--------------------------------------+ Then what you need to do, is to add extra IP address to your existing port: $ openstack port set --fixed-ip subnet=5efeae9f-06b8-41a5-987f-085e8c7113a6 51dae637-ad79-4ba9-9e41-78e5e0f3332c You can then confirm that the port does have two entries in its fixed_ips list: $ openstack port show 51dae637-ad79-4ba9-9e41-78e5e0f3332c -c fixed_ips +-----------+---------------------------------------------------------------------------+ | Field | Value | +-----------+---------------------------------------------------------------------------+ | fixed_ips | ip_address='10.2.0.228', subnet_id='5efeae9f-06b8-41a5-987f-085e8c7113a6' | | | ip_address='10.2.0.58', subnet_id='5efeae9f-06b8-41a5-987f-085e8c7113a6' | +-----------+---------------------------------------------------------------------------+ Don\u2019t forget to configure new IP as an alias to the interface inside your VM! When you have an IP address on your port that is not yet assigned to any floating IP, you can assign it to the new floating IP. Proceed with: $ openstack floating ip set c45a5eaf-2f3a-4679-89fe-266a5cbe840a --port 51dae637-ad79-4ba9-9e41-78e5e0f3332c --fixed-ip-address 10.2.0.228 Then, list the floating (public) IP addresses, together with their fixed (private) counterparts: $ openstack floating ip list -c ID -c \"Floating IP Address\" -c \"Fixed IP Address\" -c Port +--------------------------------------+---------------------+------------------+--------------------------------------+ | ID | Floating IP Address | Fixed IP Address | Port | +--------------------------------------+---------------------+------------------+--------------------------------------+ | 989f8a96-4ab4-4190-83e4-25b71d309ea9 | 192.0.2.169 | 10.2.0.58 | 51dae637-ad79-4ba9-9e41-78e5e0f3332c | | c45a5eaf-2f3a-4679-89fe-266a5cbe840a | 198.51.100.12 | 10.2.0.228 | 51dae637-ad79-4ba9-9e41-78e5e0f3332c | +--------------------------------------+---------------------+------------------+--------------------------------------+ Now your server is accessible through two different public IP addresses.","title":"Add an extra IP to the port"},{"location":"howto/openstack/neutron/new-network-control-panel/","text":"Creating a new network from the Cleura Cloud Control Panel Before creating a server in Cleura Cloud, you need to have a network to make the new server a member of. You may have more than one network per region, so let us now walk through creating a new network using the Cleura Cloud Control Panel. Fire up your favorite web browser, navigate to the Cleura Cloud page, and login into your Cleura account. On the top right-hand side of the Cleura Cloud Control Panel, click the Create button. A new pane will slide into view from the right-hand side of the browser window, titled Create . You will notice several rounded boxes prominently displayed on that pane, each for defining, configuring, and instantiating a different Cleura Cloud object. Go ahead and click the Network box. A new pane titled Create Network will slide over. At the top, type in a name and select one of the available regions for the new network. Expand the Advanced Options section below, make sure Port Security is enabled, and leave the MTU parameter blank. You probably want a full-featured network for your cloud servers, so please activate the Create a complete network containing a subnet and a router option. You will notice that a network address in CIDR notation is pre-configured for your network. You also get a couple of DNS servers, a Gateway, and a DHCP server. Scroll down a little bit if you have to. Assuming you want your cloud servers to reach hosts on the Internet, for External network make sure you select ext-net . Then, click the green Create button to create the new network. In a few seconds, the new network will be readily available. You may see all defined networks, in all supported regions, by selecting Networking > Networks (see the left-hand side pane on the Cleura Cloud Control Panel). For more information regarding a specific network, click the corresponding three-dot icon (right-hand side) and select View details . Then, you can glance over all the details regarding the selected network\u2019s ports, subnets, and routers.","title":"Creating a new network from the Cleura Cloud Control Panel"},{"location":"howto/openstack/neutron/new-network-control-panel/#creating-a-new-network-from-the-cleura-cloud-control-panel","text":"Before creating a server in Cleura Cloud, you need to have a network to make the new server a member of. You may have more than one network per region, so let us now walk through creating a new network using the Cleura Cloud Control Panel. Fire up your favorite web browser, navigate to the Cleura Cloud page, and login into your Cleura account. On the top right-hand side of the Cleura Cloud Control Panel, click the Create button. A new pane will slide into view from the right-hand side of the browser window, titled Create . You will notice several rounded boxes prominently displayed on that pane, each for defining, configuring, and instantiating a different Cleura Cloud object. Go ahead and click the Network box. A new pane titled Create Network will slide over. At the top, type in a name and select one of the available regions for the new network. Expand the Advanced Options section below, make sure Port Security is enabled, and leave the MTU parameter blank. You probably want a full-featured network for your cloud servers, so please activate the Create a complete network containing a subnet and a router option. You will notice that a network address in CIDR notation is pre-configured for your network. You also get a couple of DNS servers, a Gateway, and a DHCP server. Scroll down a little bit if you have to. Assuming you want your cloud servers to reach hosts on the Internet, for External network make sure you select ext-net . Then, click the green Create button to create the new network. In a few seconds, the new network will be readily available. You may see all defined networks, in all supported regions, by selecting Networking > Networks (see the left-hand side pane on the Cleura Cloud Control Panel). For more information regarding a specific network, click the corresponding three-dot icon (right-hand side) and select View details . Then, you can glance over all the details regarding the selected network\u2019s ports, subnets, and routers.","title":"Creating a new network from the Cleura Cloud Control Panel"},{"location":"howto/openstack/nova/config-drive/","text":"Launching an instance with a configuration drive Background: OpenStack metadata discovery OpenStack Compute uses metadata to inject custom configurations to instances on boot. You can add custom scripts, install packages, and add SSH keys to the instances using metadata. By default, metadata discovery in Cleura Cloud uses an HTTP data source that booting instances connect to. Sometimes this is undesirable or \u2014 for specific instance/networking configurations \u2014 unreliable. Under those circumstances, you can use an alternate configuration source. Store metadata on a configuration drive A configuration drive (config drive) is a read-only virtual drive that is attached to an instance during boot. The instance can then mount the drive and read files from it. Configuration drives are used as a data source for cloud-init . Enable the configuration drive on server creation ( openstack CLI) To enable the configuration drive, you need to pass the parameter --use-config-drive to the openstack server create command. In the following example, replace the image, flavor, keypair, and network reference, as well as the instance name, to match your desired configuration. openstack server create \\ --use-config-drive \\ --image \"Ubuntu 20.04 Focal Fossa\" \\ --flavor b.1c2gb \\ --keypair mykey --nic net-id = 3a747038-ee59-404c-973d-5f795e8ebb73 \\ myinstance Once the instance launches, you can monitor its configuration process by monitoring the instance console log: openstack console log show myinstance","title":"Launching an instance with a configuration drive"},{"location":"howto/openstack/nova/config-drive/#launching-an-instance-with-a-configuration-drive","text":"","title":"Launching an instance with a configuration drive"},{"location":"howto/openstack/nova/config-drive/#background-openstack-metadata-discovery","text":"OpenStack Compute uses metadata to inject custom configurations to instances on boot. You can add custom scripts, install packages, and add SSH keys to the instances using metadata. By default, metadata discovery in Cleura Cloud uses an HTTP data source that booting instances connect to. Sometimes this is undesirable or \u2014 for specific instance/networking configurations \u2014 unreliable. Under those circumstances, you can use an alternate configuration source.","title":"Background: OpenStack metadata discovery"},{"location":"howto/openstack/nova/config-drive/#store-metadata-on-a-configuration-drive","text":"A configuration drive (config drive) is a read-only virtual drive that is attached to an instance during boot. The instance can then mount the drive and read files from it. Configuration drives are used as a data source for cloud-init .","title":"Store metadata on a configuration drive"},{"location":"howto/openstack/nova/config-drive/#enable-the-configuration-drive-on-server-creation-openstack-cli","text":"To enable the configuration drive, you need to pass the parameter --use-config-drive to the openstack server create command. In the following example, replace the image, flavor, keypair, and network reference, as well as the instance name, to match your desired configuration. openstack server create \\ --use-config-drive \\ --image \"Ubuntu 20.04 Focal Fossa\" \\ --flavor b.1c2gb \\ --keypair mykey --nic net-id = 3a747038-ee59-404c-973d-5f795e8ebb73 \\ myinstance Once the instance launches, you can monitor its configuration process by monitoring the instance console log: openstack console log show myinstance","title":"Enable the configuration drive on server creation (openstack\u00a0CLI)"},{"location":"howto/openstack/octavia/tls-lb/","text":"HTTPS-terminating load balancers In Cleura\u2019s load balancing service, OpenStack Octavia , you can configure load balancers so that they manage HTTPS termination. That is to say that the load balancer encrypts and decrypts HTTPS traffic, and forwards HTTP to and from a backend web server. To do so, the load balancer must have access to encryption credentials (such as certificates and private keys), which it stores in Barbican. PKCS #12 Certificate Bundles The PKCS #12 archive format includes SSL certificates, certificate chains, and private keys all in one bundle. Most certificate providers give you the option of downloading certificate credentials using the PKCS #12 format. In case your certificate provider has made your certificate chain and key available separately, using the PEM format, you can easily convert it to PKCS #12 using the following openssl command: openssl pkcs12 -export -inkey key.pem -in fullchain.pem -out bundle.p12 When prompted for an export password, use a blank one. Creating Barbican secrets from PKCS #12 bundles To create a secret from a stored PKCS #12 bundle, you need pass in the contents of the bundle, pre-encoded with Base64 , as the secret\u2019s payload. openstack secret store \\ --name = 'tls_secret1' \\ -t 'application/octet-stream' \\ -e 'base64' \\ --payload = \" $( base64 < server.p12 ) \" +---------------+---------------------------------------------------------------------------------+ | Field | Value | +---------------+---------------------------------------------------------------------------------+ | Secret href | https://kna1.citycloud.com:9311/v1/secrets/69bd82f5-60c9-4764-99ec-7a3dff05d2aa | | Name | tls_secret1 | | Created | None | | Status | None | | Content types | {'default': 'application/octet-stream'} | | Algorithm | aes | | Bit length | 256 | | Secret type | opaque | | Mode | cbc | | Expiration | None | +---------------+---------------------------------------------------------------------------------+ Creating HTTPS-enabled load balancer listeners Once you have created your secret containing your certificate data, you can create a load balancer listener with the following properties: It uses the TERMINATED_HTTPS protocol, It sets its \u201cdefault TLS container\u201d to the Barbican secret containing the PKCS #12 bundle, It listens on the standard HTTPS port, 443. You create such a listener with the following command: openstack loadbalancer listener create \\ --protocol-port 443 \\ --protocol TERMINATED_HTTPS \\ --name listener1 \\ --default-tls-container-ref = https://kna1.citycloud.com:9311/v1/secrets/dacfbec1-fbed-403f-a4dc-303e28942dae \\ <loadbalancer-name-or-id> +-----------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+ | Field | Value | +-----------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+ | admin_state_up | True | | connection_limit | -1 | | created_at | 2021-01-20T11:51:46 | | default_pool_id | None | | default_tls_container_ref | https://kna1.citycloud.com:9311/v1/secrets/dacfbec1-fbed-403f-a4dc-303e28942dae | | description | | | id | 4ec6b23d-d08a-4de0-9e12-54ac690ee1ec | | insert_headers | None | | l7policies | | | loadbalancers | 2c2a0760-c3a8-48d2-bdd0-288c3d33a43f | | name | listener1 | | operating_status | OFFLINE | | project_id | 4a9484063d4c40d29301ad745c0e2c69 | | protocol | TERMINATED_HTTPS | | protocol_port | 443 | | provisioning_status | PENDING_CREATE | | sni_container_refs | [] | | timeout_client_data | 50000 | | timeout_member_connect | 5000 | | timeout_member_data | 50000 | | timeout_tcp_inspect | 0 | | updated_at | None | | client_ca_tls_container_ref | None | | client_authentication | NONE | | client_crl_container_ref | None | | allowed_cidrs | None | | tls_ciphers | TLS_AES_256_GCM_SHA384:TLS_CHACHA20_POLY1305_SHA256:TLS_AES_128_GCM_SHA256:DHE-RSA-AES256-GCM-SHA384:DHE-RSA-AES128-GCM-SHA256:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-RSA-AES128-GCM-SHA256:DHE-RSA-AES256-SHA256:DHE-RSA-AES128-SHA256:ECDHE-RSA-AES256-SHA384:ECDHE-RSA-AES128-SHA256 | | tls_versions | | +-----------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+ Updating the TLS certificate for a HTTPS listener When the certificate associated with a TERMINATED_HTTPS listener is about to expire, you will need to replace it. You can do this online, with no user-noticeable interruption to your service. Create a new PKCS#12 bundle from the updated key, certificate, and CA certificate. Create a new Barbican secret from the bundle. List the listener(s) associated with your load balancer: openstack loadbalancer listener list \\ --loadbalancer <loadbalancer-name-or-id> For all listeners using the TERMINATED_HTTPS protocol, run the following command: openstack loadbalancer listener set \\ --default-tls-container-ref = https://kna1.citycloud.com:9311/v1/secrets/e2d8acc1-c6b9-4c01-9373-cc167b075c25 \\ <listener-name-or-id> Once all your load balancer listeners have completed the update, you may proceed to delete the old, now-unused secret: openstack secret delete \\ https://kna1.citycloud.com:9311/v1/secrets/dacfbec1-fbed-403f-a4dc-303e28942dae","title":"HTTPS-terminating load balancers"},{"location":"howto/openstack/octavia/tls-lb/#https-terminating-load-balancers","text":"In Cleura\u2019s load balancing service, OpenStack Octavia , you can configure load balancers so that they manage HTTPS termination. That is to say that the load balancer encrypts and decrypts HTTPS traffic, and forwards HTTP to and from a backend web server. To do so, the load balancer must have access to encryption credentials (such as certificates and private keys), which it stores in Barbican.","title":"HTTPS-terminating load balancers"},{"location":"howto/openstack/octavia/tls-lb/#pkcs-12-certificate-bundles","text":"The PKCS #12 archive format includes SSL certificates, certificate chains, and private keys all in one bundle. Most certificate providers give you the option of downloading certificate credentials using the PKCS #12 format. In case your certificate provider has made your certificate chain and key available separately, using the PEM format, you can easily convert it to PKCS #12 using the following openssl command: openssl pkcs12 -export -inkey key.pem -in fullchain.pem -out bundle.p12 When prompted for an export password, use a blank one.","title":"PKCS #12 Certificate Bundles"},{"location":"howto/openstack/octavia/tls-lb/#creating-barbican-secrets-from-pkcs-12-bundles","text":"To create a secret from a stored PKCS #12 bundle, you need pass in the contents of the bundle, pre-encoded with Base64 , as the secret\u2019s payload. openstack secret store \\ --name = 'tls_secret1' \\ -t 'application/octet-stream' \\ -e 'base64' \\ --payload = \" $( base64 < server.p12 ) \" +---------------+---------------------------------------------------------------------------------+ | Field | Value | +---------------+---------------------------------------------------------------------------------+ | Secret href | https://kna1.citycloud.com:9311/v1/secrets/69bd82f5-60c9-4764-99ec-7a3dff05d2aa | | Name | tls_secret1 | | Created | None | | Status | None | | Content types | {'default': 'application/octet-stream'} | | Algorithm | aes | | Bit length | 256 | | Secret type | opaque | | Mode | cbc | | Expiration | None | +---------------+---------------------------------------------------------------------------------+","title":"Creating Barbican secrets from PKCS #12 bundles"},{"location":"howto/openstack/octavia/tls-lb/#creating-https-enabled-load-balancer-listeners","text":"Once you have created your secret containing your certificate data, you can create a load balancer listener with the following properties: It uses the TERMINATED_HTTPS protocol, It sets its \u201cdefault TLS container\u201d to the Barbican secret containing the PKCS #12 bundle, It listens on the standard HTTPS port, 443. You create such a listener with the following command: openstack loadbalancer listener create \\ --protocol-port 443 \\ --protocol TERMINATED_HTTPS \\ --name listener1 \\ --default-tls-container-ref = https://kna1.citycloud.com:9311/v1/secrets/dacfbec1-fbed-403f-a4dc-303e28942dae \\ <loadbalancer-name-or-id> +-----------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+ | Field | Value | +-----------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+ | admin_state_up | True | | connection_limit | -1 | | created_at | 2021-01-20T11:51:46 | | default_pool_id | None | | default_tls_container_ref | https://kna1.citycloud.com:9311/v1/secrets/dacfbec1-fbed-403f-a4dc-303e28942dae | | description | | | id | 4ec6b23d-d08a-4de0-9e12-54ac690ee1ec | | insert_headers | None | | l7policies | | | loadbalancers | 2c2a0760-c3a8-48d2-bdd0-288c3d33a43f | | name | listener1 | | operating_status | OFFLINE | | project_id | 4a9484063d4c40d29301ad745c0e2c69 | | protocol | TERMINATED_HTTPS | | protocol_port | 443 | | provisioning_status | PENDING_CREATE | | sni_container_refs | [] | | timeout_client_data | 50000 | | timeout_member_connect | 5000 | | timeout_member_data | 50000 | | timeout_tcp_inspect | 0 | | updated_at | None | | client_ca_tls_container_ref | None | | client_authentication | NONE | | client_crl_container_ref | None | | allowed_cidrs | None | | tls_ciphers | TLS_AES_256_GCM_SHA384:TLS_CHACHA20_POLY1305_SHA256:TLS_AES_128_GCM_SHA256:DHE-RSA-AES256-GCM-SHA384:DHE-RSA-AES128-GCM-SHA256:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-RSA-AES128-GCM-SHA256:DHE-RSA-AES256-SHA256:DHE-RSA-AES128-SHA256:ECDHE-RSA-AES256-SHA384:ECDHE-RSA-AES128-SHA256 | | tls_versions | | +-----------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+","title":"Creating HTTPS-enabled load balancer listeners"},{"location":"howto/openstack/octavia/tls-lb/#updating-the-tls-certificate-for-a-https-listener","text":"When the certificate associated with a TERMINATED_HTTPS listener is about to expire, you will need to replace it. You can do this online, with no user-noticeable interruption to your service. Create a new PKCS#12 bundle from the updated key, certificate, and CA certificate. Create a new Barbican secret from the bundle. List the listener(s) associated with your load balancer: openstack loadbalancer listener list \\ --loadbalancer <loadbalancer-name-or-id> For all listeners using the TERMINATED_HTTPS protocol, run the following command: openstack loadbalancer listener set \\ --default-tls-container-ref = https://kna1.citycloud.com:9311/v1/secrets/e2d8acc1-c6b9-4c01-9373-cc167b075c25 \\ <listener-name-or-id> Once all your load balancer listeners have completed the update, you may proceed to delete the old, now-unused secret: openstack secret delete \\ https://kna1.citycloud.com:9311/v1/secrets/dacfbec1-fbed-403f-a4dc-303e28942dae","title":"Updating the TLS certificate for a HTTPS listener"},{"location":"reference/","text":"Reference This is our reference section. It serves to provide general reference information about Cleura services. Feature and service availability Our Feature Support Matrix lists cloud features and their availability across Cleura regions. Our API Service Version Matrix lists the open source software versions running in our Cleura regions.","title":"Reference"},{"location":"reference/#reference","text":"This is our reference section. It serves to provide general reference information about Cleura services.","title":"Reference"},{"location":"reference/#feature-and-service-availability","text":"Our Feature Support Matrix lists cloud features and their availability across Cleura regions. Our API Service Version Matrix lists the open source software versions running in our Cleura regions.","title":"Feature and service availability"},{"location":"reference/features/","text":"Feature support matrix Services in Cleura Cloud constantly evolve, and we gradually add features to regions as they become available and mature. This page lists the cloud features available in each Cleura Cloud region. Public Cloud : features supported in our Cleura Public Cloud regions. Compliant Cloud : features supported in our Cleura Compliant Cloud regions.","title":"Feature support matrix"},{"location":"reference/features/#feature-support-matrix","text":"Services in Cleura Cloud constantly evolve, and we gradually add features to regions as they become available and mature. This page lists the cloud features available in each Cleura Cloud region. Public Cloud : features supported in our Cleura Public Cloud regions. Compliant Cloud : features supported in our Cleura Compliant Cloud regions.","title":"Feature support matrix"},{"location":"reference/features/compliant/","text":"Compliant Cloud Feature is in production and fully supported Feature is in deployment, not yet supported Feature is deprecated, being phased out Feature is not available Virtualization Sto1HS Sto2HS Dedicated CPU Virtual GPU Block storage Sto1HS Sto2HS Highly available storage High-performance local storage Object storage Sto1HS Sto2HS S3 API S3 SSE-C Swift API Networking (Layer 2/3) Sto1HS Sto2HS IPv4 (with NAT) IPv6 VPN (IPsec with PSK) Load Balancers Sto1HS Sto2HS Transport layer (TCP/UDP) Application layer (HTTP) Application layer (HTTPS, with secrets management for TLS certificates)","title":"Compliant Cloud"},{"location":"reference/features/compliant/#compliant-cloud","text":"Feature is in production and fully supported Feature is in deployment, not yet supported Feature is deprecated, being phased out Feature is not available","title":"Compliant Cloud"},{"location":"reference/features/compliant/#virtualization","text":"Sto1HS Sto2HS Dedicated CPU Virtual GPU","title":"Virtualization"},{"location":"reference/features/compliant/#block-storage","text":"Sto1HS Sto2HS Highly available storage High-performance local storage","title":"Block storage"},{"location":"reference/features/compliant/#object-storage","text":"Sto1HS Sto2HS S3 API S3 SSE-C Swift API","title":"Object storage"},{"location":"reference/features/compliant/#networking-layer-23","text":"Sto1HS Sto2HS IPv4 (with NAT) IPv6 VPN (IPsec with PSK)","title":"Networking (Layer 2/3)"},{"location":"reference/features/compliant/#load-balancers","text":"Sto1HS Sto2HS Transport layer (TCP/UDP) Application layer (HTTP) Application layer (HTTPS, with secrets management for TLS certificates)","title":"Load Balancers"},{"location":"reference/features/public/","text":"Public Cloud Feature is in production and fully supported Feature is in deployment, not yet supported Feature is deprecated, being phased out Feature is not available Virtualization Kna1 Sto2 Fra1 Dx1 Tky1 Dedicated CPU Virtual GPU Block storage Kna1 Sto2 Fra1 Dx1 Tky1 Highly available storage High-performance local storage Object storage Kna1 Sto2 Fra1 Dx1 Tky1 S3 API S3 SSE-C Swift API Networking (Layer 2/3) Kna1 Sto2 Fra1 Dx1 Tky1 IPv4 (with NAT) IPv6 VPN (IPsec with PSK) Load Balancers Kna1 Sto2 Fra1 Dx1 Tky1 Transport layer (TCP/UDP) Application layer (HTTP) Application layer (HTTPS, with secrets management for TLS certificates) Kubernetes management Kna1 Sto2 Fra1 Dx1 Tky1 OpenStack Magnum Gardener","title":"Public Cloud"},{"location":"reference/features/public/#public-cloud","text":"Feature is in production and fully supported Feature is in deployment, not yet supported Feature is deprecated, being phased out Feature is not available","title":"Public Cloud"},{"location":"reference/features/public/#virtualization","text":"Kna1 Sto2 Fra1 Dx1 Tky1 Dedicated CPU Virtual GPU","title":"Virtualization"},{"location":"reference/features/public/#block-storage","text":"Kna1 Sto2 Fra1 Dx1 Tky1 Highly available storage High-performance local storage","title":"Block storage"},{"location":"reference/features/public/#object-storage","text":"Kna1 Sto2 Fra1 Dx1 Tky1 S3 API S3 SSE-C Swift API","title":"Object storage"},{"location":"reference/features/public/#networking-layer-23","text":"Kna1 Sto2 Fra1 Dx1 Tky1 IPv4 (with NAT) IPv6 VPN (IPsec with PSK)","title":"Networking (Layer 2/3)"},{"location":"reference/features/public/#load-balancers","text":"Kna1 Sto2 Fra1 Dx1 Tky1 Transport layer (TCP/UDP) Application layer (HTTP) Application layer (HTTPS, with secrets management for TLS certificates)","title":"Load Balancers"},{"location":"reference/features/public/#kubernetes-management","text":"Kna1 Sto2 Fra1 Dx1 Tky1 OpenStack Magnum Gardener","title":"Kubernetes management"},{"location":"reference/versions/","text":"Service version matrix Services in Cleura Cloud are updated on a regular basis and on a rolling schedule. This section lists the cloud API service versions available in each Cleura Cloud region. Public Cloud : versions running in our Cleura Public Cloud regions. Compliant Cloud : versions running in our Cleura Compliant Cloud regions. OpenStack Services OpenStack releases are named, in alphabetical order, and occur on a six-month release schedule. In Cleura Public Cloud we upgrade OpenStack releases annually; this means that we deploy every other OpenStack release and skip the intervening one. Cleura Cloud currently runs OpenStack Victoria and Xena . Ceph Services Ceph major releases are also named, in alphabetical order, and occur on a roughly annual schedule. Cleura Cloud currently runs Ceph Nautilus and Pacific .","title":"Service version matrix"},{"location":"reference/versions/#service-version-matrix","text":"Services in Cleura Cloud are updated on a regular basis and on a rolling schedule. This section lists the cloud API service versions available in each Cleura Cloud region. Public Cloud : versions running in our Cleura Public Cloud regions. Compliant Cloud : versions running in our Cleura Compliant Cloud regions.","title":"Service version matrix"},{"location":"reference/versions/#openstack-services","text":"OpenStack releases are named, in alphabetical order, and occur on a six-month release schedule. In Cleura Public Cloud we upgrade OpenStack releases annually; this means that we deploy every other OpenStack release and skip the intervening one. Cleura Cloud currently runs OpenStack Victoria and Xena .","title":"OpenStack Services"},{"location":"reference/versions/#ceph-services","text":"Ceph major releases are also named, in alphabetical order, and occur on a roughly annual schedule. Cleura Cloud currently runs Ceph Nautilus and Pacific .","title":"Ceph Services"},{"location":"reference/versions/compliant/","text":"Compliant Cloud OpenStack Services Sto1HS Sto2HS Barbican (secret storage) Xena Xena Cinder (block storage) Xena Xena Glance (image management) Xena Xena Heat (orchestration) Xena Xena Keystone (identity management) Xena Xena Magnum (container management) Xena Xena Neutron (networking) Xena Xena Nova (server virtualization) Xena Xena Octavia (load balancing) Xena Xena Ceph Services Sto1HS Sto2HS Block storage (for OpenStack) Pacific Pacific Object storage (Swift API) Pacific Pacific Object storage (S3 API) Pacific Pacific","title":"Compliant Cloud"},{"location":"reference/versions/compliant/#compliant-cloud","text":"","title":"Compliant Cloud"},{"location":"reference/versions/compliant/#openstack-services","text":"Sto1HS Sto2HS Barbican (secret storage) Xena Xena Cinder (block storage) Xena Xena Glance (image management) Xena Xena Heat (orchestration) Xena Xena Keystone (identity management) Xena Xena Magnum (container management) Xena Xena Neutron (networking) Xena Xena Nova (server virtualization) Xena Xena Octavia (load balancing) Xena Xena","title":"OpenStack Services"},{"location":"reference/versions/compliant/#ceph-services","text":"Sto1HS Sto2HS Block storage (for OpenStack) Pacific Pacific Object storage (Swift API) Pacific Pacific Object storage (S3 API) Pacific Pacific","title":"Ceph Services"},{"location":"reference/versions/public/","text":"Public Cloud OpenStack Services Kna1 Sto2 Fra1 Dx1 Tky1 Barbican (secret storage) Xena Xena Xena Xena Xena Cinder (block storage) Xena Xena Xena Xena Xena Glance (image management) Xena Xena Xena Xena Xena Heat (orchestration) Xena Xena Xena Xena Xena Keystone (identity management) Xena Xena Xena Xena Xena Magnum (container management) Xena Xena Xena Xena Xena Neutron (networking) Xena Xena Xena Xena Xena Nova (server virtualization) Xena Xena Xena Xena Xena Octavia (load balancing) Xena Xena Xena Xena Xena Ceph Services Kna1 Sto2 Fra1 Dx1 Tky1 Block storage (for OpenStack) Pacific Pacific Pacific Pacific Pacific Object storage (Swift API) Pacific Pacific Pacific Object storage (S3 API) Pacific Pacific Pacific","title":"Public Cloud"},{"location":"reference/versions/public/#public-cloud","text":"","title":"Public Cloud"},{"location":"reference/versions/public/#openstack-services","text":"Kna1 Sto2 Fra1 Dx1 Tky1 Barbican (secret storage) Xena Xena Xena Xena Xena Cinder (block storage) Xena Xena Xena Xena Xena Glance (image management) Xena Xena Xena Xena Xena Heat (orchestration) Xena Xena Xena Xena Xena Keystone (identity management) Xena Xena Xena Xena Xena Magnum (container management) Xena Xena Xena Xena Xena Neutron (networking) Xena Xena Xena Xena Xena Nova (server virtualization) Xena Xena Xena Xena Xena Octavia (load balancing) Xena Xena Xena Xena Xena","title":"OpenStack Services"},{"location":"reference/versions/public/#ceph-services","text":"Kna1 Sto2 Fra1 Dx1 Tky1 Block storage (for OpenStack) Pacific Pacific Pacific Pacific Pacific Object storage (Swift API) Pacific Pacific Pacific Object storage (S3 API) Pacific Pacific Pacific","title":"Ceph Services"},{"location":"tutorials/","text":"About our tutorials Our tutorials are gentle introductions to Cleura. They generally require very little prior knowledge and assume only that you have access to a browser, or to a terminal. We group these into two major categories: Browser-based tutorials get you started on Cleura using the Cleura Cloud Control Panel . Terminal-based tutorials introduce you to command-line interfaces (CLIs) and their interaction with Cleura\u2019s web-based Application Programming Interfaces (APIs). This section does not include detailed walkthroughs of specific technical tasks. For those, please see our How-To Guides section. If you find our tutorials helpful, you might also be interested in our self-paced online training courses, available from our course booking site .","title":"About our tutorials"},{"location":"tutorials/#about-our-tutorials","text":"Our tutorials are gentle introductions to Cleura. They generally require very little prior knowledge and assume only that you have access to a browser, or to a terminal. We group these into two major categories: Browser-based tutorials get you started on Cleura using the Cleura Cloud Control Panel . Terminal-based tutorials introduce you to command-line interfaces (CLIs) and their interaction with Cleura\u2019s web-based Application Programming Interfaces (APIs). This section does not include detailed walkthroughs of specific technical tasks. For those, please see our How-To Guides section. If you find our tutorials helpful, you might also be interested in our self-paced online training courses, available from our course booking site .","title":"About our tutorials"}]}